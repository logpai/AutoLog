Log,LoggingLevel,Method
Cannot determine the size of the physical memory for FreeBSD host (using \'sysctl hw.physmem\').,error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForFreeBSD()>
Cannot determine the size of the physical memory for FreeBSD host (using \'sysctl hw.physmem\'),error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForFreeBSD()>
Initial resource allocation timeout triggered: Creating ExecutionGraph with available resources.,debug,<org.apache.flink.runtime.scheduler.adaptive.WaitingForResources: void resourceTimeout()>
Error while shutting down an iterative operator.,error,<org.apache.flink.runtime.iterative.task.AbstractIterativeTask: void closeLocalStrategiesAndCaches()>
Error while shutting down an iterative operator.,error,<org.apache.flink.runtime.iterative.task.AbstractIterativeTask: void closeLocalStrategiesAndCaches()>
"The configuration option <*> required for local execution is not set, setting it to <*>.",info,"<org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils: void setConfigOptionToDefaultIfNotSet(org.apache.flink.configuration.Configuration,org.apache.flink.configuration.ConfigOption,java.lang.Object,java.lang.String)>"
Closing <*>.,info,<org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver: void close()>
Initialized <*> in \'<*>\' with <*>.,info,"<org.apache.flink.runtime.util.ZooKeeperUtils: org.apache.flink.runtime.checkpoint.CompletedCheckpointStore createCompletedCheckpoints(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.configuration.Configuration,int,org.apache.flink.runtime.state.SharedStateRegistryFactory,java.util.concurrent.Executor,java.util.concurrent.Executor,org.apache.flink.runtime.jobgraph.RestoreMode)>"
Failed to notify job graph listener onAddedJobGraph event for <*>,error,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void onAddedJobGraph(org.apache.flink.api.common.JobID)>
"<*>,  No retries left., ",error,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey moveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,byte[],org.apache.flink.runtime.blob.BlobKey$BlobType)>"
"Trying to find a unique key for BLOB of job <*> (retry <*>, last tried <*>)",debug,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey moveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,byte[],org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Successful registration at resource manager <*> under registration id <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection: void onRegistrationSuccess(org.apache.flink.runtime.taskexecutor.TaskExecutorRegistrationSuccess)>
Register slots <*> from TaskManager <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: void registerSlots(java.util.Collection,org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,long)>"
"<*>\'s leader retrieval listener reported a new leader for job <*>. However, the service is no longer running.",debug,"<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
"New leader information for job <*>. Address: <*>, leader id: <*>.",debug,"<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
Ongoing attempt to connect to leader of job <*>. Ignoring duplicate leader information.,debug,"<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
Finished to build heap keyed state-backend.,info,"<org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder: void restoreState(java.util.Map,java.util.Map,org.apache.flink.runtime.state.heap.InternalKeyContext,org.apache.flink.runtime.state.heap.StateTableFactory)>"
Start registering input and output.,debug,<org.apache.flink.runtime.operators.BatchTask: void invoke()>
Finished registering input and output.,debug,<org.apache.flink.runtime.operators.BatchTask: void invoke()>
Start task code.,debug,<org.apache.flink.runtime.operators.BatchTask: void invoke()>
Task cancelled before task code was started.,debug,<org.apache.flink.runtime.operators.BatchTask: void invoke()>
Finished task code.,debug,<org.apache.flink.runtime.operators.BatchTask: void invoke()>
Task code cancelled.,debug,<org.apache.flink.runtime.operators.BatchTask: void invoke()>
Shutting down,info,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStore: void shutdown(org.apache.flink.api.common.JobStatus,org.apache.flink.runtime.checkpoint.CheckpointsCleaner)>"
Fail to remove checkpoint during shutdown.,warn,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStore: void shutdown(org.apache.flink.api.common.JobStatus,org.apache.flink.runtime.checkpoint.CheckpointsCleaner)>"
Suspending,info,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStore: void shutdown(org.apache.flink.api.common.JobStatus,org.apache.flink.runtime.checkpoint.CheckpointsCleaner)>"
Unknown message received: <*>,warn,"<org.apache.flink.runtime.rest.handler.PipelineErrorHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest)>"
Managed memory consumer weight for <*> is configured to . Jobs containing this type of managed memory consumers may fail due to not being able to allocate managed memory.,debug,<org.apache.flink.runtime.util.config.memory.ManagedMemoryUtils: java.util.Map getManagedMemoryUseCaseWeightsFromConfig(org.apache.flink.configuration.Configuration)>
Managed memory consumer weight for <*> is not configured. Jobs containing this type of managed memory consumers may fail due to not being able to allocate managed memory.,debug,<org.apache.flink.runtime.util.config.memory.ManagedMemoryUtils: java.util.Map getManagedMemoryUseCaseWeightsFromConfig(org.apache.flink.configuration.Configuration)>
Stopping the checkpoint services with state <*>.,debug,<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: void stopCheckpointServicesSafely(org.apache.flink.api.common.JobStatus)>
Failed to stop checkpoint services.,warn,<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: void stopCheckpointServicesSafely(org.apache.flink.api.common.JobStatus)>
Cannot create JSON plan for job,warn,"<org.apache.flink.runtime.scheduler.adaptivebatch.AdaptiveBatchScheduler: void changeJobVertexParallelism(org.apache.flink.runtime.executiongraph.ExecutionJobVertex,int)>"
Stopping all currently running jobs of dispatcher <*>.,info,<org.apache.flink.runtime.dispatcher.Dispatcher: void terminateRunningJobs()>
Free reserved slot <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: org.apache.flink.runtime.util.ResourceCounter freeReservedSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,java.lang.Throwable,long)>"
"No hostname could be resolved for the IP address <*>, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.",warn,<org.apache.flink.runtime.taskmanager.TaskManagerLocation: java.lang.String getHostName(java.net.InetAddress)>
Request new allocated batch slot with slot request id <*> and resource profile <*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: java.util.concurrent.CompletableFuture requestNewAllocatedBatchSlot(org.apache.flink.runtime.jobmaster.SlotRequestId,org.apache.flink.runtime.clusterframework.types.ResourceProfile,java.util.Collection)>"
Log file environment variable \'<*>\' is not set.,warn,<org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation: org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation find(org.apache.flink.configuration.Configuration)>
JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable \'<*>\' or configuration key \'<*>\'.,warn,<org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation: org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation find(org.apache.flink.configuration.Configuration)>
Determined location of main cluster component log file: <*>,info,<org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation: org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation find(org.apache.flink.configuration.Configuration)>
Determined location of main cluster component stdout file: <*>,info,<org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation: org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation find(org.apache.flink.configuration.Configuration)>
read at <*> from <*>,debug,<org.apache.flink.runtime.state.changelog.StateChangelogHandleStreamHandleReader$1: void advance()>
Could not properly discard completed checkpoint <*>.,warn,"<org.apache.flink.runtime.checkpoint.CheckpointsCleaner: void lambda$cleanup$1(org.apache.flink.util.function.RunnableWithException,org.apache.flink.runtime.checkpoint.Checkpoint,java.lang.Runnable)>"
Job <*> has been removed from the <*> by another process.,debug,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: void handleRemovedJobGraph(org.apache.flink.api.common.JobID)>
"Join Driver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.JoinDriver: void prepare()>
Writing <*> to myid file in \'dataDir\'.,info,"<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void writeMyIdToDataDir(java.util.Properties,int)>"
"Buffer debloater init settings: gateIndex=<*>, targetTotalBufferSize=<*>, maxBufferSize=<*>, minBufferSize=<*>, bufferDebloatThresholdPercentages=<*>, numberOfSamples=<*>",debug,"<org.apache.flink.runtime.throughput.BufferDebloater: void <init>(int,long,int,int,int,long)>"
Config key <*> is deprecated; use <*> instead.,warn,<org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerConfiguration: org.apache.flink.api.common.time.Time getSlotRequestTimeout(org.apache.flink.configuration.Configuration)>
Cannot reconnect to job <*> because it is not registered.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService: void reconnect(org.apache.flink.api.common.JobID)>
Fetching metrics failed.,debug,"<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void lambda$queryMetrics$5(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult,java.lang.Throwable)>"
"hasLeadership is called after the service is stopped, returning false.",debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: boolean hasLeadership(java.util.UUID)>
Put a large record ( > into the sort buffer,debug,<org.apache.flink.runtime.operators.sort.NormalizedKeySorter: boolean write(java.lang.Object)>
Triggering checkpoint <*> for <*> (<*>) was rejected by the mailbox,debug,"<org.apache.flink.runtime.taskmanager.Task: void triggerCheckpointBarrier(long,long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
Encountered error while triggering checkpoint <*> for <*> (<*>) while being not in state running.,debug,"<org.apache.flink.runtime.taskmanager.Task: void triggerCheckpointBarrier(long,long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
Declining checkpoint request for non-running task <*> (<*>).,debug,"<org.apache.flink.runtime.taskmanager.Task: void triggerCheckpointBarrier(long,long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
"The handler of the request complete callback threw an exception, <*>_, ",error,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$ReaderThread: void shutdown()>
checkpoint request time in queue: <*>,info,<org.apache.flink.runtime.checkpoint.CheckpointRequestDecider: void logInQueueTime(org.apache.flink.runtime.checkpoint.CheckpointCoordinator$CheckpointTriggerRequest)>
unable to uninstall a security module,warn,<org.apache.flink.runtime.security.SecurityUtils: void uninstall()>
A problem occurred during asynchronous disposal of a shared state object: <*>,warn,<org.apache.flink.runtime.state.SharedStateRegistryImpl$AsyncDisposalRunnable: void run()>
Unexpected error when accessing file handle limit,warn,<org.apache.flink.runtime.util.EnvironmentInformation: long getOpenFileHandlesLimit()>
Exception while triggering checkpoint for job <*>.,error,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator$ScheduledTrigger: void run()>
The execution has no slot assigned. This indicates that the execution is no longer running.,debug,"<org.apache.flink.runtime.executiongraph.Execution: java.util.concurrent.CompletableFuture triggerCheckpointHelper(long,long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
Stopping ZooKeeperJobGraphStoreWatcher ,info,<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher: void stop()>
Using failover strategy <*> for <*> (<*>).,info,"<org.apache.flink.runtime.scheduler.DefaultScheduler: void <init>(org.slf4j.Logger,org.apache.flink.runtime.jobgraph.JobGraph,java.util.concurrent.Executor,org.apache.flink.configuration.Configuration,java.util.function.Consumer,org.apache.flink.util.concurrent.ScheduledExecutor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointRecoveryFactory,org.apache.flink.runtime.metrics.groups.JobManagerJobMetricGroup,org.apache.flink.runtime.scheduler.strategy.SchedulingStrategyFactory,org.apache.flink.runtime.executiongraph.failover.flip1.FailoverStrategy$Factory,org.apache.flink.runtime.executiongraph.failover.flip1.RestartBackoffTimeStrategy,org.apache.flink.runtime.scheduler.ExecutionVertexOperations,org.apache.flink.runtime.scheduler.ExecutionVertexVersioner,org.apache.flink.runtime.scheduler.ExecutionSlotAllocatorFactory,long,org.apache.flink.runtime.concurrent.ComponentMainThreadExecutor,org.apache.flink.runtime.executiongraph.JobStatusListener,org.apache.flink.runtime.scheduler.ExecutionGraphFactory,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.scheduler.VertexParallelismStore)>"
Unable to close checkpointStream after a failure,warn,<org.apache.flink.runtime.checkpoint.channel.ChannelStateCheckpointWriter: void fail(java.lang.Throwable)>
Leader information for <*> has changed to <*>.,debug,"<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: org.apache.flink.runtime.leaderelection.LeaderInformation tryReadingLeaderInformation(org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.ChildData,java.lang.String)>"
Could not read leader information for <*>. Rewriting the information.,debug,"<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: org.apache.flink.runtime.leaderelection.LeaderInformation tryReadingLeaderInformation(org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.ChildData,java.lang.String)>"
"ReduceCombineDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.ReduceCombineDriver: void prepare()>
Starting execution of job \'<*>\' (<*>) under job master id <*>.,info,<org.apache.flink.runtime.jobmaster.JobMaster: void startJobExecution()>
The failing attempt <*> belongs to an already not running task thus won\'t fail the job,debug,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void failGlobalIfExecutionIsStillRunning(java.lang.Throwable,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
Rescaling maximum parallelism for JobVertex <*> from <*> to <*>,debug,"<org.apache.flink.runtime.checkpoint.StateAssignmentOperation: void checkParallelismPreconditions(org.apache.flink.runtime.checkpoint.OperatorState,org.apache.flink.runtime.executiongraph.ExecutionJobVertex)>"
"No metrics reporter configured, no metrics will be exposed/reported.",info,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void <init>(org.apache.flink.runtime.metrics.MetricRegistryConfiguration,java.util.Collection,java.util.concurrent.ScheduledExecutorService)>"
Periodically reporting metrics in intervals of <*> for reporter <*> of type <*>.,info,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void <init>(org.apache.flink.runtime.metrics.MetricRegistryConfiguration,java.util.Collection,java.util.concurrent.ScheduledExecutorService)>"
Reporting metrics for reporter <*> of type <*>.,info,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void <init>(org.apache.flink.runtime.metrics.MetricRegistryConfiguration,java.util.Collection,java.util.concurrent.ScheduledExecutorService)>"
"Failed to parse delimiter \'<*>\' for reporter \'<*>\', using global delimiter \'<*>\'.",warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void <init>(org.apache.flink.runtime.metrics.MetricRegistryConfiguration,java.util.Collection,java.util.concurrent.ScheduledExecutorService)>"
Could not instantiate metrics reporter <*>. Metrics might not be exposed/reported.,error,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void <init>(org.apache.flink.runtime.metrics.MetricRegistryConfiguration,java.util.Collection,java.util.concurrent.ScheduledExecutorService)>"
Error in the task canceler for task <*>.,error,<org.apache.flink.runtime.taskmanager.Task$TaskInterrupter: void run()>
Can not find Execution for attempt <*>.,debug,"<org.apache.flink.runtime.scheduler.ExecutionGraphHandler: org.apache.flink.runtime.jobmaster.SerializedInputSplit requestNextInputSplit(org.apache.flink.runtime.jobgraph.JobVertexID,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
Send next input split <*>.,debug,"<org.apache.flink.runtime.scheduler.ExecutionGraphHandler: org.apache.flink.runtime.jobmaster.SerializedInputSplit requestNextInputSplit(org.apache.flink.runtime.jobgraph.JobVertexID,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
No more input splits available,debug,"<org.apache.flink.runtime.scheduler.ExecutionGraphHandler: org.apache.flink.runtime.jobmaster.SerializedInputSplit requestNextInputSplit(org.apache.flink.runtime.jobgraph.JobVertexID,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
<*>: Releasing <*>.,debug,<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: void close()>
<*>: Error during release of channel resources: <*>.,warn,<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: void close()>
Terminating the leadership runner for job <*>.,debug,<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: java.util.concurrent.CompletableFuture closeAsync()>
Confirm leader session ID <*> for leader <*>.,debug,"<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void confirmLeadership(java.util.UUID,java.lang.String)>"
"Ignoring the leader session Id <*> confirmation, since the LeaderElectionService has already been stopped.",debug,"<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void confirmLeadership(java.util.UUID,java.lang.String)>"
"Receive an old confirmation call of leader session ID <*>, current issued session ID is <*>",debug,"<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void confirmLeadership(java.util.UUID,java.lang.String)>"
The leader session ID <*> was confirmed even though the corresponding JobManager was not elected as the leader.,warn,"<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void confirmLeadership(java.util.UUID,java.lang.String)>"
Not shutting down cluster after someone retrieved the job result.,info,"<org.apache.flink.runtime.dispatcher.MiniDispatcher: java.util.concurrent.CompletableFuture requestJobResult(org.apache.flink.api.common.JobID,org.apache.flink.api.common.time.Time)>"
Request for <*> already exists,debug,<org.apache.flink.runtime.scheduler.SharedSlot: java.util.concurrent.CompletableFuture allocateLogicalSlot(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID)>
Resource manager service is not running. Ignore revoking leadership.,info,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: void lambda$revokeLeadership$3()>
Resource manager service is revoked leadership with session id <*>.,info,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: void lambda$revokeLeadership$3()>
Could not close the state stream for <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointMetadataOutputStream: void close()>
Suspending the slot manager.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void suspend()>
Skipped checkpoint state for operator <*>.,info,"<org.apache.flink.runtime.checkpoint.StateAssignmentOperation: void checkStateMappingCompleteness(boolean,java.util.Map,java.util.Set)>"
Source <*> received split request from parallel task <*>,info,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$handleEventFromOperator$2(org.apache.flink.runtime.operators.coordination.OperatorEvent,int)>"
Source <*> received custom event from parallel task <*>: <*>,debug,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$handleEventFromOperator$2(org.apache.flink.runtime.operators.coordination.OperatorEvent,int)>"
Source <*> registering reader for parallel task <*> @ <*>,info,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$handleEventFromOperator$2(org.apache.flink.runtime.operators.coordination.OperatorEvent,int)>"
"MapPartitionDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.MapPartitionDriver: void prepare()>
"Name collision: Adding a metric subgroup with the same name as an existing metric: \', name, \'. Metric might not get properly reported. , <*>, ",warn,"<org.apache.flink.runtime.metrics.groups.AbstractMetricGroup: org.apache.flink.runtime.metrics.groups.AbstractMetricGroup addGroup(java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup$ChildType)>"
Triggering checkpoint <*> (type=<*>) @ <*> for job <*>.,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: org.apache.flink.runtime.checkpoint.PendingCheckpoint createPendingCheckpoint(long,org.apache.flink.runtime.checkpoint.CheckpointProperties,org.apache.flink.runtime.checkpoint.CheckpointPlan,boolean,long,java.util.concurrent.CompletableFuture)>"
Reserve free slot with allocation id <*>.,debug,<org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool: org.apache.flink.runtime.jobmaster.slotpool.AllocatedSlot reserveFreeSlot(org.apache.flink.runtime.clusterframework.types.AllocationID)>
startPersisting,logEvent,"<org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister: void startPersisting(long,java.util.List)>"
"Ignoring slot allocation update from task executor <*> for slot <*> and job <*>, because the allocation was already completed or cancelled.",debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: java.lang.Void lambda$allocateSlot$5(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.slotmanager.TaskManagerSlotInformation,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Completed allocation of slot <*> for job <*>.,trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: java.lang.Void lambda$allocateSlot$5(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.slotmanager.TaskManagerSlotInformation,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
"Tried allocating slot <*> for job <*>, but it was already allocated for job <*>.",debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: java.lang.Void lambda$allocateSlot$5(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.slotmanager.TaskManagerSlotInformation,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Slot allocation for slot <*> for job <*> failed.,warn,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: java.lang.Void lambda$allocateSlot$5(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.slotmanager.TaskManagerSlotInformation,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Successfully deleted allocation state metadata file <*>.,debug,<org.apache.flink.runtime.taskexecutor.slot.FileSlotAllocationSnapshotPersistenceService: void deleteAllocationSnapshot(int)>
Cannot delete the local allocations state file <*>.,warn,<org.apache.flink.runtime.taskexecutor.slot.FileSlotAllocationSnapshotPersistenceService: void deleteAllocationSnapshot(int)>
Caught exception,error,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void exceptionCaught(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,java.lang.Throwable)>"
The derived JVM Overhead size (<*>) does not match the configured or default JVM Overhead fraction (<*>) from the configured Total Process Memory size (<*>). The derived JVM OVerhead size will be used.,info,"<org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils: void sanityCheckJvmOverhead(org.apache.flink.configuration.Configuration,org.apache.flink.configuration.MemorySize,org.apache.flink.configuration.MemorySize)>"
<*> obtained the leadership.,debug,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void isLeader()>
,checkLimitAndMoveFile,"<org.apache.flink.runtime.blob.PermanentBlobCache: byte[] readFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.PermanentBlobCache: byte[] readFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
Failed to copy from blob store. Downloading from BLOB server instead.,info,"<org.apache.flink.runtime.blob.PermanentBlobCache: byte[] readFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
,checkLimitAndMoveFile,"<org.apache.flink.runtime.blob.PermanentBlobCache: byte[] readFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.PermanentBlobCache: byte[] readFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.PermanentBlobCache: byte[] readFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
"Unhandled error in curator framework, error message: <*>",error,"<org.apache.flink.runtime.util.ZooKeeperUtils: void lambda$startCuratorFramework$0(org.apache.flink.runtime.rpc.FatalErrorHandler,java.lang.String,java.lang.Throwable)>"
Job <*> reached terminal state <*>.,info,<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: void onFinished(org.apache.flink.runtime.executiongraph.ArchivedExecutionGraph)>
Received <*> event (path: <*>),debug,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
Received <*> event,debug,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
Received CHILD_ADDED event notification for job <*>,debug,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
Received CHILD_REMOVED event notification for job <*>,debug,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
ZooKeeper connection SUSPENDING. Changes to the submitted job graphs are not monitored (temporarily).,warn,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
ZooKeeper connection LOST. Changes to the submitted job graphs are not monitored (permanently).,warn,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
ZooKeeper connection RECONNECTED. Changes to the submitted job graphs are monitored again.,info,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
JobGraphsPathCacheListener initialized,info,"<org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStoreWatcher$JobGraphsPathCacheListener: void childEvent(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,org.apache.flink.shaded.curator5.org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent)>"
The metric <*> is not numeric and can\'t be aggregated.,warn,"<org.apache.flink.runtime.rest.handler.job.metrics.AbstractAggregatingMetricsHandler: org.apache.flink.runtime.rest.messages.job.metrics.AggregatedMetricsResponseBody getAggregatedMetricValues(java.util.Collection,java.util.List,org.apache.flink.runtime.rest.handler.job.metrics.AbstractAggregatingMetricsHandler$MetricAccumulatorFactory)>"
There is no SharedSlot for ExecutionSlotSharingGroup of ExecutionVertexID <*>,debug,"<org.apache.flink.runtime.scheduler.SlotSharingExecutionSlotAllocator: void cancelLogicalSlotRequest(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,java.lang.Throwable)>"
Failed to deserialize final accumulator results.,error,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: java.util.Map deserializeAccumulators(org.apache.flink.runtime.executiongraph.TaskExecutionStateTransition)>
State backend loader loads <*> to delegate <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend fromApplicationOrConfigOrDefault(org.apache.flink.runtime.state.StateBackend,org.apache.flink.util.TernaryBoolean,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
State backend loader loads the state backend as <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend fromApplicationOrConfigOrDefault(org.apache.flink.runtime.state.StateBackend,org.apache.flink.util.TernaryBoolean,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Create metrics info for TaskManager <*>.,debug,"<org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler: org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerDetailsInfo lambda$handleRequest$0(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.resourcemanager.TaskManagerInfoWithSlots)>"
No metrics for TaskManager <*>.,debug,"<org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler: org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerDetailsInfo lambda$handleRequest$0(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.resourcemanager.TaskManagerInfoWithSlots)>"
Cannot determine code revision: Unable to read version property file.: <*>,info,<org.apache.flink.runtime.util.EnvironmentInformation$Versions: void <init>()>
Error while shutting down checkpoint services.,error,<org.apache.flink.runtime.scheduler.SchedulerBase: void shutDownCheckpointServices(org.apache.flink.api.common.JobStatus)>
"Created a new <*> for spilling of task related data to disk (joins, sorting, ...). Used directories:\n\t<*>",info,<org.apache.flink.runtime.io.disk.iomanager.IOManager: void <init>(java.lang.String[])>
Failed to offload value for job <*> to BLOB store.,warn,"<org.apache.flink.runtime.blob.BlobWriter: org.apache.flink.types.Either tryOffload(org.apache.flink.util.SerializedValue,org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobWriter)>"
The task slot <*> is not present anymore and will be ignored in calculating the amount of used memory.,debug,<org.apache.flink.runtime.metrics.util.MetricUtils: long getUsedManagedMemory(org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable)>
Registration at <*> (<*>) attempt <*> timed out after <*> ms,debug,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$3(int,long,org.apache.flink.runtime.rpc.RpcGateway,java.lang.Void,java.lang.Throwable)>"
Registration at <*> failed due to an error,error,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$3(int,long,org.apache.flink.runtime.rpc.RpcGateway,java.lang.Void,java.lang.Throwable)>"
Pausing and re-attempting registration in <*> ms,info,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$3(int,long,org.apache.flink.runtime.rpc.RpcGateway,java.lang.Void,java.lang.Throwable)>"
Received wrong AcknowledgeCheckpoint message for job <*> from <*> : <*>,error,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
Received acknowledge message for checkpoint <*> from task <*> of job <*> at <*>.,debug,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
"Received a duplicate acknowledge message for checkpoint <*>, task <*>, job <*>, location <*>.",debug,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
"Could not acknowledge the checkpoint <*> for task <*> of job <*> at <*>, because the task\'s execution attempt id was unknown. Discarding the state handle to avoid lingering state.",warn,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
"Could not acknowledge the checkpoint <*> for task <*> of job <*> at <*>, because the pending checkpoint had been discarded. Discarding the state handle tp avoid lingering state.",warn,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
Received late message for now expired checkpoint attempt <*> from task <*> of job <*> at <*>.,warn,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
Received message for an unknown checkpoint <*> from task <*> of job <*> at <*>.,debug,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean receiveAcknowledgeMessage(org.apache.flink.runtime.messages.checkpoint.AcknowledgeCheckpoint,java.lang.String)>"
"WARNING: Thread \'<*>\' produced an uncaught exception. If you want to fail on uncaught exceptions, then configure <*> accordingly",error,"<org.apache.flink.runtime.util.ClusterUncaughtExceptionHandler: void uncaughtException(java.lang.Thread,java.lang.Throwable)>"
"<*> finishing input data, checkpoint <*>",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void finishInput(long)>
"Shutting down cluster after job with state <*>, jobCancelled: <*>, executionMode: <*>",info,"<org.apache.flink.runtime.dispatcher.MiniDispatcher: void runPostJobGloballyTerminated(org.apache.flink.api.common.JobID,org.apache.flink.api.common.JobStatus)>"
Reaching max start worker failure rate: <*>,warn,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: boolean recordStartWorkerFailure()>
Memory statistics not available,warn,<org.apache.flink.runtime.io.network.netty.NettyBufferPool: void <init>(int)>
Cannot determine the size of the physical memory for Windows host (using \'wmic memorychip\'),error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForWindows()>
Exception when deleting local recovery subtask base directory <*> in subtask (<*> - <*> - <*>),warn,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void lambda$dispose$3(java.util.Collection)>
Collecting stats sample <*> of task <*>,debug,"<org.apache.flink.runtime.webmonitor.stats.TaskStatsRequestCoordinator: void handleSuccessfulResponse(int,org.apache.flink.runtime.executiongraph.ExecutionAttemptID,java.lang.Object)>"
Received late stats sample <*> of task <*>,debug,"<org.apache.flink.runtime.webmonitor.stats.TaskStatsRequestCoordinator: void handleSuccessfulResponse(int,org.apache.flink.runtime.executiongraph.ExecutionAttemptID,java.lang.Object)>"
Finished restoring from state handle: <*>.,info,<org.apache.flink.runtime.state.restore.FullSnapshotRestoreOperation$KeyGroupsIterator: void close()>
The configured or derived JVM heap memory size (<*>) is less than its recommended minimum value (<*>),warn,<org.apache.flink.runtime.util.config.memory.jobmanager.JobManagerFlinkMemoryUtils: void verifyJvmHeapSize(org.apache.flink.configuration.MemorySize)>
Registering task executor <*> under <*> at the slot manager.,info,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Task executor <*> was already registered.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
"Releasing task manager <*>. The max total resource limitation <<*>, <*>> is reached.",info,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Error while waiting for this thread to die.,debug,<org.apache.flink.runtime.blob.BlobServer: void close()>
Shutting down connection <*>.,debug,<org.apache.flink.runtime.blob.BlobServer: void close()>
Stopped BLOB server at <*>:<*>,info,<org.apache.flink.runtime.blob.BlobServer: void close()>
Could not notify partition data available to JobManager.,error,"<org.apache.flink.runtime.taskexecutor.rpc.RpcResultPartitionConsumableNotifier: void lambda$notifyPartitionConsumable$0(org.apache.flink.runtime.taskmanager.TaskActions,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Operator <*> has remote state <*> from job manager and local state alternatives <*> from local state store <*>.,debug,<org.apache.flink.runtime.state.TaskStateManagerImpl: org.apache.flink.runtime.checkpoint.PrioritizedOperatorSubtaskState prioritizedOperatorState(org.apache.flink.runtime.jobgraph.OperatorID)>
process <*>,trace,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcherImpl: void dispatch(org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest)>
Failed to create new internal coordinator due to ,error,"<org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$DeferrableCoordinator: void createNewInternalCoordinator(org.apache.flink.runtime.operators.coordination.OperatorCoordinator$Context,org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$Provider)>"
Received response <*>.,debug,<org.apache.flink.runtime.rest.RestClient$ClientHandler: void readRawResponse(org.apache.flink.shaded.netty4.io.netty.handler.codec.http.FullHttpResponse)>
Response was not valid JSON.,error,<org.apache.flink.runtime.rest.RestClient$ClientHandler: void readRawResponse(org.apache.flink.shaded.netty4.io.netty.handler.codec.http.FullHttpResponse)>
Unexpected plain-text response: <*>,error,<org.apache.flink.runtime.rest.RestClient$ClientHandler: void readRawResponse(org.apache.flink.shaded.netty4.io.netty.handler.codec.http.FullHttpResponse)>
Response could not be read.,error,<org.apache.flink.runtime.rest.RestClient$ClientHandler: void readRawResponse(org.apache.flink.shaded.netty4.io.netty.handler.codec.http.FullHttpResponse)>
Cannot find a factory for changelog storage with name \'<*>\'.,warn,"<org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader: org.apache.flink.runtime.state.changelog.StateChangelogStorage load(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
Creating a changelog storage with name \'<*>\'.,info,"<org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader: org.apache.flink.runtime.state.changelog.StateChangelogStorage load(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
"Could not load Queryable State Client Proxy. Probable reason: flink-queryable-state-runtime is not in the classpath. To enable Queryable State, please move the flink-queryable-state-runtime jar from the opt to the lib folder. Cause: , <*>, ",debug,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateClientProxy createKvStateClientProxy(java.lang.String,java.util.Iterator,int,int,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
"Could not load Queryable State Client Proxy. Probable reason: flink-queryable-state-runtime is not in the classpath. To enable Queryable State, please move the flink-queryable-state-runtime jar from the opt to the lib folder.",info,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateClientProxy createKvStateClientProxy(java.lang.String,java.util.Iterator,int,int,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
Queryable State Client Proxy could not be created: ,error,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateClientProxy createKvStateClientProxy(java.lang.String,java.util.Iterator,int,int,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
Failed to instantiate the Queryable State Client Proxy.,error,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateClientProxy createKvStateClientProxy(java.lang.String,java.util.Iterator,int,int,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
Using configured hostname/address for TaskManager: <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: java.lang.String determineTaskManagerBindAddress(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.rpc.RpcSystemUtils)>"
Registered new shared state <*> under key <*>.,trace,"<org.apache.flink.runtime.state.SharedStateRegistryImpl: org.apache.flink.runtime.state.StreamStateHandle registerReference(org.apache.flink.runtime.state.SharedStateRegistryKey,org.apache.flink.runtime.state.StreamStateHandle,long)>"
Identified duplicate state registration under key <*>. New state <*> was determined to be an unnecessary copy of existing state <*> and will be dropped.,trace,"<org.apache.flink.runtime.state.SharedStateRegistryImpl: org.apache.flink.runtime.state.StreamStateHandle registerReference(org.apache.flink.runtime.state.SharedStateRegistryKey,org.apache.flink.runtime.state.StreamStateHandle,long)>"
Updating last checkpoint for <*> from <*> to <*>,trace,"<org.apache.flink.runtime.state.SharedStateRegistryImpl: org.apache.flink.runtime.state.StreamStateHandle registerReference(org.apache.flink.runtime.state.SharedStateRegistryKey,org.apache.flink.runtime.state.StreamStateHandle,long)>"
Matching resource requirements against available resources.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void checkResourceRequirements()>
Could not fulfill resource requirements of job <*>.,warn,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void checkResourceRequirements()>
Close and clean up all data for <*>.,info,<org.apache.flink.runtime.highavailability.AbstractHaServices: void closeAndCleanupAllData()>
Cannot delete HA blobs because we failed to delete the pointers in the HA store.,info,<org.apache.flink.runtime.highavailability.AbstractHaServices: void closeAndCleanupAllData()>
Finished cleaning up the high availability data.,info,<org.apache.flink.runtime.highavailability.AbstractHaServices: void closeAndCleanupAllData()>
"The derived from fraction <*> (<*>) is greater than its max value <*>, max value will be used instead",info,"<org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils: org.apache.flink.configuration.MemorySize capToMinMax(java.lang.String,org.apache.flink.configuration.MemorySize,org.apache.flink.runtime.util.config.memory.RangeFraction)>"
"The derived from fraction <*> (<*>) is less than its min value <*>, min value will be used instead",info,"<org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils: org.apache.flink.configuration.MemorySize capToMinMax(java.lang.String,org.apache.flink.configuration.MemorySize,org.apache.flink.runtime.util.config.memory.RangeFraction)>"
Uncaught Exception in Source Coordinator Executor,error,<org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext: java.lang.Object lambda$callInCoordinatorThread$8(java.util.concurrent.Callable)>
Stopping dispatcher <*>.,info,<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture onStop()>
,loginUserFromKeytab,<org.apache.flink.runtime.security.modules.HadoopModule: void install()>
Could not find method implementations in the shaded jar.,warn,<org.apache.flink.runtime.security.modules.HadoopModule: void install()>
Hadoop user set to <*>,info,<org.apache.flink.runtime.security.modules.HadoopModule: void install()>
Kerberos security is enabled and credentials are <*>.,info,<org.apache.flink.runtime.security.modules.HadoopModule: void install()>
Unable to set the Hadoop login user,<init>,<org.apache.flink.runtime.security.modules.HadoopModule: void install()>
Could not upload file <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture putTransientBlobStream(java.io.InputStream,java.lang.String)>"
"SynchronousChainedCombineDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.chaining.SynchronousChainedCombineDriver: void openTask()>
"FlatMapDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.FlatMapDriver: void prepare()>
Requested log list from unregistered TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture requestTaskManagerLogList(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.api.common.time.Time)>"
Disconnect job manager <*>@<*> for job <*> from the resource manager.,info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void closeJobManagerConnection(org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.ResourceManager$ResourceRequirementHandling,java.lang.Exception)>"
There was no registered job manager for job <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void closeJobManagerConnection(org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.ResourceManager$ResourceRequirementHandling,java.lang.Exception)>"
Exception when opening secondary/local checkpoint output stream. Continue only with the primary stream.,warn,"<org.apache.flink.runtime.state.CheckpointStreamWithResultProvider: org.apache.flink.runtime.state.CheckpointStreamWithResultProvider createDuplicatingStream(long,org.apache.flink.runtime.state.CheckpointedStateScope,org.apache.flink.runtime.state.CheckpointStreamFactory,org.apache.flink.runtime.state.LocalRecoveryDirectoryProvider)>"
,info,"<org.apache.flink.runtime.io.network.netty.NettyConfig: void <init>(java.net.InetAddress,int,int,int,org.apache.flink.configuration.Configuration)>"
<*>: Released <*>.,debug,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: void release()>
Ignoring offered slots from unknown task manager <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolService: java.util.Collection offerSlots(org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,java.util.Collection)>"
Initialization of the JobMasterService for job <*> under leader id <*> failed.,debug,"<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: void lambda$new$0(org.apache.flink.api.common.JobID,java.util.UUID,java.util.function.Function,org.apache.flink.runtime.jobmaster.JobMasterService,java.lang.Throwable)>"
Triggering stop-with-savepoint for job <*>.,info,"<org.apache.flink.runtime.scheduler.SchedulerBase: java.util.concurrent.CompletableFuture stopWithSavepoint(java.lang.String,boolean,org.apache.flink.core.execution.SavepointFormatType)>"
,<init>,"<org.apache.flink.runtime.scheduler.SchedulerBase: java.util.concurrent.CompletableFuture stopWithSavepoint(java.lang.String,boolean,org.apache.flink.core.execution.SavepointFormatType)>"
Releasing job graph <*> from <*>.,debug,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void lambda$localCleanupAsync$1(org.apache.flink.api.common.JobID)>
Released job graph <*> from <*>.,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void lambda$localCleanupAsync$1(org.apache.flink.api.common.JobID)>
Creating FileSystem stream leak safety net for task <*>,debug,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Loading JAR files for task <*>.,info,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Registering task at network: <*>.,debug,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Obtaining local cache file for \'<*>\'.,info,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Freeing task resources for <*> (<*>).,info,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Ensuring all FileSystem streams are closed for task <*>,debug,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Error during metrics de-registration of task <*> (<*>).,error,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Unexpected state in task <*> (<*>) during an exception: <*>.,error,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Freeing task resources for <*> (<*>).,info,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Ensuring all FileSystem streams are closed for task <*>,debug,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Error during metrics de-registration of task <*> (<*>).,error,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Freeing task resources for <*> (<*>).,info,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Ensuring all FileSystem streams are closed for task <*>,debug,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Error during metrics de-registration of task <*> (<*>).,error,<org.apache.flink.runtime.taskmanager.Task: void doRun()>
Uncaught exception in the SplitEnumerator for Source <*> while <*>. Triggering job failover.,error,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$runInEventLoop$9(org.apache.flink.util.function.ThrowingRunnable,java.lang.String,java.lang.Object[])>"
Could not find leader election event handler for componentId <*>. Ignoring the unregister call.,debug,<org.apache.flink.runtime.leaderelection.DefaultMultipleComponentLeaderElectionService: void unregisterLeaderElectionEventHandler(java.lang.String)>
Invalid value <*> specified for integer range. Not a number.,warn,<org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler: java.lang.Iterable getIntegerRangeFromString(java.util.Collection)>
Error notifying leader listener about new leader,warn,<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall: void run()>
Unsupported aggregation specified: <*>,warn,<org.apache.flink.runtime.rest.handler.job.metrics.AbstractAggregatingMetricsHandler: org.apache.flink.runtime.rest.messages.job.metrics.AggregatedMetricsResponseBody lambda$handleRequest$0(org.apache.flink.runtime.rest.handler.HandlerRequest)>
Could not retrieve metrics.,warn,<org.apache.flink.runtime.rest.handler.job.metrics.AbstractAggregatingMetricsHandler: org.apache.flink.runtime.rest.messages.job.metrics.AggregatedMetricsResponseBody lambda$handleRequest$0(org.apache.flink.runtime.rest.handler.HandlerRequest)>
Requesting subpartition <*> of <*>.,debug,"<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: org.apache.flink.runtime.io.network.partition.ResultSubpartitionView createSubpartitionView(org.apache.flink.runtime.io.network.partition.ResultPartitionID,int,org.apache.flink.runtime.io.network.partition.BufferAvailabilityListener)>"
<*>,info,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void sendEventToSync(org.apache.flink.runtime.iterative.event.WorkerDoneEvent)>
Closing the slot manager.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void close()>
Checkpoint storage is set to \'<*>\': (checkpoints \<*>\),info,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage createFileSystemCheckpointStorage(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
Received abort information for checkpoint <*> in subtask (<*> - <*> - <*>). Starting to prune history.,debug,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void abortCheckpoint(long)>
java.security.auth.login.config,setProperty,<org.apache.flink.runtime.security.modules.JaasModule: void install()>
Jaas file will be created as <*>.,info,<org.apache.flink.runtime.security.modules.JaasModule: void install()>
"\'<*>\' is not specified, use the configured deprecated task manager heap value (<*>) for it.",info,"<org.apache.flink.runtime.util.config.memory.MemoryBackwardsCompatibilityUtils: org.apache.flink.configuration.Configuration lambda$getConfWithLegacyHeapSizeMappedToNewConfigOption$0(org.apache.flink.configuration.Configuration,org.apache.flink.configuration.ConfigOption,org.apache.flink.configuration.MemorySize)>"
"Could not allocate <*> more slots. The number of registered and pending slots is <*>, while the maximum is <*>.",warn,<org.apache.flink.runtime.resourcemanager.slotmanager.TaskExecutorManager: java.util.Optional allocateWorker(org.apache.flink.runtime.clusterframework.types.ResourceProfile)>
Notify checkpoint <*>} <*> for <*> (<*>) was rejected by the mailbox.,debug,"<org.apache.flink.runtime.taskmanager.Task: void notifyCheckpoint(long,long,org.apache.flink.runtime.taskmanager.Task$NotifyCheckpointOperation)>"
Ignoring checkpoint <*> notification for non-running task <*>.,info,"<org.apache.flink.runtime.taskmanager.Task: void notifyCheckpoint(long,long,org.apache.flink.runtime.taskmanager.Task$NotifyCheckpointOperation)>"
Successfully created the JobMasterService for job <*> under leader id <*>.,debug,<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: void registerJobMasterServiceFutures(org.apache.flink.runtime.jobmaster.JobMasterService)>
Retrieved new target address <*> for akka URL <*>.,debug,"<org.apache.flink.runtime.net.ConnectionUtils$LeaderConnectingAddressListener: java.net.InetAddress findConnectingAddress(java.time.Duration,java.time.Duration)>"
Trying to connect to address <*>,info,"<org.apache.flink.runtime.net.ConnectionUtils$LeaderConnectingAddressListener: java.net.InetAddress findConnectingAddress(java.time.Duration,java.time.Duration)>"
Could not connect to <*>. Selecting a local address using heuristics.,warn,"<org.apache.flink.runtime.net.ConnectionUtils$LeaderConnectingAddressListener: java.net.InetAddress findConnectingAddress(java.time.Duration,java.time.Duration)>"
Could not find any IPv address that is not loopback or link-local. Using localhost address.,warn,"<org.apache.flink.runtime.net.ConnectionUtils$LeaderConnectingAddressListener: java.net.InetAddress findConnectingAddress(java.time.Duration,java.time.Duration)>"
Triggering <*>savepoint for job <*>.,info,"<org.apache.flink.runtime.scheduler.adaptive.StateWithExecutionGraph: java.util.concurrent.CompletableFuture triggerSavepoint(java.lang.String,boolean,org.apache.flink.core.execution.SavepointFormatType)>"
Activate slot <*>.,info,<org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl: boolean markExistingSlotActive(org.apache.flink.runtime.taskexecutor.slot.TaskSlot)>
Failed to process pending calls <*> on coordinator.,error,<org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$DeferrableCoordinator: void processPendingCalls()>
Job <*> no longer has a job leader.,debug,"<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService$JobLeaderIdListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
Job <*> has a new job leader <*>@<*>.,debug,"<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService$JobLeaderIdListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
Job <*> has a new job leader <*>@<*>.,debug,"<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService$JobLeaderIdListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
A leader id change <*>@<*> has been detected after the listener has been stopped.,debug,"<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService$JobLeaderIdListener: void notifyLeaderAddress(java.lang.String,java.util.UUID)>"
Starting rest endpoint.,info,<org.apache.flink.runtime.rest.RestServerEndpoint: void start()>
Binding rest endpoint to <*>:<*>.,debug,<org.apache.flink.runtime.rest.RestServerEndpoint: void start()>
Rest endpoint listening at <*>:<*>,info,<org.apache.flink.runtime.rest.RestServerEndpoint: void start()>
removed file cache directory <*>,info,<org.apache.flink.runtime.filecache.FileCache: void shutdown()>
File cache could not properly clean up storage directory: <*>,error,<org.apache.flink.runtime.filecache.FileCache: void shutdown()>
Worker <*> is registered.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void onWorkerRegistered(org.apache.flink.runtime.clusterframework.types.ResourceIDRetrievable)>
Worker <*> with resource spec <*> was requested in current attempt. Current pending count after registering: <*>.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void onWorkerRegistered(org.apache.flink.runtime.clusterframework.types.ResourceIDRetrievable)>
Job has entered globally terminal state without waiting for all job vertices to reach final state.,warn,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void allVerticesInTerminalState()>
,<init>,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: org.apache.flink.runtime.io.network.partition.ResultSubpartitionView$AvailabilityWithBacklog getAvailabilityAndBacklog(int)>
<*> was revoked the leadership with leader id <*>. Stopping the <*>.,info,<org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner: void lambda$revokeLeadership$3()>
Could not delete the checkpoint stream file <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory$FsCheckpointStateOutputStream: org.apache.flink.runtime.state.StreamStateHandle closeAndGetHandle()>
StateChangelogStorageLoader initialized with shortcut names {<*>}.,info,<org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader: void initialize(org.apache.flink.core.plugin.PluginManager)>
"The resource configuration option <*> is set but it will have no effect for local execution, only the following options matter for the resource configuration: <*>",warn,"<org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils: void warnOptionHasNoEffectIfSet(org.apache.flink.configuration.Configuration,org.apache.flink.configuration.ConfigOption)>"
Failed to connect to <*>. Giving up.,warn,<org.apache.flink.runtime.io.network.netty.PartitionRequestClientFactory: org.apache.flink.runtime.io.network.netty.NettyPartitionRequestClient connectWithRetries(org.apache.flink.runtime.io.network.ConnectionID)>
Failed <*> times to connect to <*>. Retrying.,warn,<org.apache.flink.runtime.io.network.netty.PartitionRequestClientFactory: org.apache.flink.runtime.io.network.netty.NettyPartitionRequestClient connectWithRetries(org.apache.flink.runtime.io.network.ConnectionID)>
Ignoring old (but still present) network buffer configuration via <*>.,info,<org.apache.flink.runtime.taskmanager.NettyShuffleEnvironmentConfiguration: void logIfIgnoringOldConfigs(org.apache.flink.configuration.Configuration)>
Freeing slot <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void freeSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID)>"
Trying to free a slot <*> which has not been allocated. Ignoring this message.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void freeSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID)>"
created <*> for task=<*> subtask=<*>,debug,"<org.apache.flink.runtime.checkpoint.TaskStateAssignment: org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor log(org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor,int)>"
Could not close the state stream for <*>.,warn,<org.apache.flink.runtime.state.filesystem.FileBasedStateOutputStream: void close()>
There are no longer partitions being tracked for dataset <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl: void lambda$checkForFullyLostDatasets$7(org.apache.flink.runtime.jobgraph.IntermediateDataSetID)>
Upload directory <*> does not exist. ,info,"<org.apache.flink.runtime.rest.RestServerEndpoint: void createUploadDir(java.nio.file.Path,org.slf4j.Logger,boolean)>"
Upload directory <*> has been deleted externally. Previously uploaded files are no longer available.,warn,"<org.apache.flink.runtime.rest.RestServerEndpoint: void createUploadDir(java.nio.file.Path,org.slf4j.Logger,boolean)>"
"Task FINISHED, but concurrently went to state , <*>, ",debug,"<org.apache.flink.runtime.executiongraph.Execution: void markFinished(java.util.Map,org.apache.flink.runtime.executiongraph.IOMetrics)>"
"complete output, input completed: <*>",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateCheckpointWriter: void completeOutput()>
Duplicate class configuration detected for reporter <*>.,warn,"<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Set findEnabledReportersInConfiguration(org.apache.flink.configuration.Configuration,java.lang.String)>"
"Excluding reporter <*>, not configured in reporter list (<*>).",info,"<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Set findEnabledReportersInConfiguration(org.apache.flink.configuration.Configuration,java.lang.String)>"
Add task manager <*> with total resource <*> and default slot resource <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void addTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
ALIVE,<init>,<org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot$State: void <clinit>()>
RELEASING,<init>,<org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot$State: void <clinit>()>
RELEASED,<init>,<org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot$State: void <clinit>()>
The reporter configuration of <*> is out-dated (but still supported). Please configure a factory class instead: \'<*><*>.<*>: <*>\' to ensure that the configuration continues to work with future versions.,info,"<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Optional loadViaReflection(java.lang.String,java.lang.String,org.apache.flink.configuration.Configuration,java.util.Map)>"
"CoGroupDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.CoGroupDriver: void prepare()>
Dispatcher is unable to cancel job <*>: not found,debug,"<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture cancelJob(org.apache.flink.api.common.JobID,org.apache.flink.api.common.time.Time)>"
Key group <*> doesn\'t belong to this backend with key group range: <*>,debug,"<org.apache.flink.runtime.state.heap.HeapRestoreOperation: void readStateHandleStateData(org.apache.flink.core.fs.FSDataInputStream,org.apache.flink.core.memory.DataInputViewStreamWrapper,org.apache.flink.runtime.state.KeyGroupRangeOffsets,java.util.Map,int,int,boolean)>"
Distributing maxAllowedWatermark=<*> to subTaskIds=<*>,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void announceCombinedWatermark()>
Could not properly fail task.,error,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void unregisterTaskAndNotifyFinalState(org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
Un-registering task and sending final execution state <*> to JobManager for task <*> <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void unregisterTaskAndNotifyFinalState(org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
Cannot find task with ID <*> to unregister.,error,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void unregisterTaskAndNotifyFinalState(org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
Received an invalid timeout for allocation id <*> with ticket <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void timeoutSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,java.util.UUID)>"
Ignore forwarding \'<*>\' because the leadership runner is no longer the valid leader for <*>.,trace,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void lambda$forwardIfValidLeader$15(java.util.UUID,java.util.concurrent.CompletableFuture,java.lang.String,java.lang.Object,java.lang.Throwable)>"
The operator name <*> exceeded the <*> characters length limit and was truncated.,warn,"<org.apache.flink.runtime.metrics.groups.TaskMetricGroup: org.apache.flink.runtime.metrics.groups.InternalOperatorMetricGroup getOrAddOperator(org.apache.flink.runtime.jobgraph.OperatorID,java.lang.String)>"
Requested path <*> points outside the root directory.,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void checkFileValidity(java.io.File,java.io.File,org.slf4j.Logger)>"
Requested path <*> cannot be found.,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void checkFileValidity(java.io.File,java.io.File,org.slf4j.Logger)>"
Requested path <*> does not point to a file.,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void checkFileValidity(java.io.File,java.io.File,org.slf4j.Logger)>"
Failed to retrieve information of external resource <*>.,warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: org.apache.flink.runtime.externalresource.ExternalResourceInfoProvider createStaticExternalResourceInfoProvider(java.util.Map,java.util.Map)>"
Could not found legal amount configuration for <*>.,warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: org.apache.flink.runtime.externalresource.ExternalResourceInfoProvider createStaticExternalResourceInfoProvider(java.util.Map,java.util.Map)>"
Could not create object name <*>.,warn,<org.apache.flink.runtime.metrics.util.MetricUtils: void instantiateMemoryMetrics(org.apache.flink.metrics.MetricGroup)>
Could not create object name <*>.,warn,<org.apache.flink.runtime.metrics.util.MetricUtils: void instantiateMemoryMetrics(org.apache.flink.metrics.MetricGroup)>
Cannot delete closed and discarded state stream for <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory$FsCheckpointStateOutputStream: void close()>
Could not close the state stream for <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory$FsCheckpointStateOutputStream: void close()>
Cannot delete closed and discarded state stream for <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory$FsCheckpointStateOutputStream: void close()>
Cannot delete closed and discarded state stream for <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory$FsCheckpointStateOutputStream: void close()>
Unregistering task executor <*> from the slot manager.,info,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean unregisterTaskManager(org.apache.flink.runtime.instance.InstanceID,java.lang.Exception)>"
There is no task executor registered with instance ID <*>. Ignoring this message.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean unregisterTaskManager(org.apache.flink.runtime.instance.InstanceID,java.lang.Exception)>"
Add pending task manager <*>.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void addPendingTaskManager(org.apache.flink.runtime.resourcemanager.slotmanager.PendingTaskManager)>
stopPersisting,logEvent,<org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister: void stopPersisting(long)>
"Adaptive Scheduler configured, but Batch job detected. Changing scheduler type to NG / DefaultScheduler.",info,"<org.apache.flink.runtime.jobmaster.DefaultSlotPoolServiceSchedulerFactory: org.apache.flink.runtime.jobmaster.DefaultSlotPoolServiceSchedulerFactory fromConfiguration(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.jobgraph.JobType)>"
"Spilling Resettable Iterator closing. Stored , <*>,  records., ",debug,<org.apache.flink.runtime.operators.resettable.SpillingResettableIterator: java.util.List close()>
"Ignore a partition producer state notification for task <*>, because it\'s not running.",debug,<org.apache.flink.runtime.io.network.partition.consumer.RemoteChannelStateChecker: boolean isProducerReadyOrAbortConsumption(org.apache.flink.runtime.io.network.partition.PartitionProducerStateProvider$ResponseHandle)>
Cannot determine user/group information using Hadoop utils. Hadoop classes not loaded or compatible,debug,<org.apache.flink.runtime.util.EnvironmentInformation: java.lang.String getHadoopUser()>
Error while accessing user/group information via Hadoop utils.,warn,<org.apache.flink.runtime.util.EnvironmentInformation: java.lang.String getHadoopUser()>
Fatal error occurred in TaskExecutor <*>.,error,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void onFatalError(java.lang.Throwable)>
Initializing cluster services.,info,"<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void initializeServices(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Initialize cluster entrypoint <*> with resource id <*>.,debug,"<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void initializeServices(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Using working directory: <*>.,info,"<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void initializeServices(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Registering IncrementalRemoteKeyedStateHandle for checkpoint <*> from backend with id <*>.,trace,"<org.apache.flink.runtime.state.IncrementalRemoteKeyedStateHandle: void registerSharedStates(org.apache.flink.runtime.state.SharedStateRegistry,long)>"
Internal server error. Could not map response to JSON.,error,"<org.apache.flink.runtime.rest.handler.util.HandlerUtils: java.util.concurrent.CompletableFuture sendResponse(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,org.apache.flink.runtime.rest.messages.ResponseBody,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpResponseStatus,java.util.Map)>"
Cannot deregister application. Resource manager service is not available.,warn,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: java.util.concurrent.CompletableFuture deregisterWithoutLeaderRm()>
Stop-with-savepoint transitioned from <*> to <*> on execution termination handling for job <*> with some executions being in an not-finished state: <*>,warn,<org.apache.flink.runtime.scheduler.stopwithsavepoint.StopWithSavepointTerminationHandlerImpl: void handleAnyExecutionNotFinished(java.util.Set)>
A slot was added with an already tracked slot ID <*>. Removing previous entry.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker: void addSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.api.common.JobID)>"
Received error from LeaderRetrievalService.,error,<org.apache.flink.runtime.webmonitor.retriever.LeaderRetriever: void handleError(java.lang.Exception)>
"The handler instance for <*> had already been closed, but another attempt at closing it was made.",warn,<org.apache.flink.runtime.rest.handler.AbstractHandler: java.util.concurrent.CompletableFuture closeAsync()>
"channel state write completed, checkpointId: <*>, handles: <*>",debug,"<org.apache.flink.runtime.checkpoint.channel.ChannelStateCheckpointWriter: void complete(org.apache.flink.runtime.state.StreamStateHandle,java.util.concurrent.CompletableFuture,java.util.Map,org.apache.flink.runtime.checkpoint.channel.ChannelStateCheckpointWriter$HandleFactory)>"
Could not delete the checkpoint stream file <*>.,warn,<org.apache.flink.runtime.state.filesystem.FileBasedStateOutputStream: org.apache.flink.runtime.state.filesystem.FileStateHandle closeAndGetHandle()>
Allocated slot for <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void allocateSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Could not allocate slot for <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void allocateSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
"The slot , slotId,  has already been allocated for a different job., ",info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void allocateSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Error while notifying JobStatusListener,warn,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void notifyJobStatusChange(org.apache.flink.api.common.JobStatus)>
Ignoring attempted registration of a metric due to being null for name <*>.,warn,"<org.apache.flink.runtime.metrics.groups.AbstractMetricGroup: void addMetric(java.lang.String,org.apache.flink.metrics.Metric)>"
"Name collision: Adding a metric with the same name as a metric subgroup: \', name, \'. Metric might not get properly reported. , <*>, ",warn,"<org.apache.flink.runtime.metrics.groups.AbstractMetricGroup: void addMetric(java.lang.String,org.apache.flink.metrics.Metric)>"
"Name collision: Group already contains a Metric with the name \', name, \'. Metric will not be reported., <*>, ",warn,"<org.apache.flink.runtime.metrics.groups.AbstractMetricGroup: void addMetric(java.lang.String,org.apache.flink.metrics.Metric)>"
Starting to restore from state handle: <*>.,info,"<org.apache.flink.runtime.state.restore.FullSnapshotRestoreOperation$KeyGroupsIterator: void <init>(org.apache.flink.runtime.state.KeyGroupRange,org.apache.flink.runtime.state.KeyGroupsStateHandle,org.apache.flink.core.fs.FSDataInputStream,org.apache.flink.runtime.state.StreamCompressionDecorator)>"
Releasing job resources for job <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void releaseJobResources(org.apache.flink.api.common.JobID,java.lang.Exception)>"
Shutting down task stats request coordinator.,info,<org.apache.flink.runtime.webmonitor.stats.TaskStatsRequestCoordinator: void shutDown()>
Could not properly suspend the execution graph.,debug,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void lambda$suspend$3(java.lang.Void,java.lang.Throwable)>"
Job <*> has been suspended.,info,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void lambda$suspend$3(java.lang.Void,java.lang.Throwable)>"
Preferring <*> (InetAddress.getLocalHost()) for local bind point over previous candidate <*>,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress tryLocalHostBeforeReturning(java.net.InetAddress,java.net.SocketAddress,boolean)>"
Closing InPlaceMutableHashTable and releasing resources.,debug,<org.apache.flink.runtime.operators.hash.InPlaceMutableHashTable: void close()>
"<*> <*>, lastSeenBarrier = <*> (<*>) @ <*>",debug,"<org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister: void logEvent(java.lang.String,long)>"
"Not all slot managed memory is freed at <*>. This usually indicates memory leak. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java u or higher if running on an old Java version.",warn,<org.apache.flink.runtime.taskexecutor.slot.TaskSlot: void lambda$verifyAllManagedMemoryIsReleasedAfter$1()>
"<*> aborting, checkpoint <*>",debug,"<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void abort(long,java.lang.Throwable,boolean)>"
"PUT BLOB buffer (, len,  bytes) to , <*>, ., ",debug,"<org.apache.flink.runtime.blob.BlobClient: org.apache.flink.runtime.blob.BlobKey putBuffer(org.apache.flink.api.common.JobID,byte[],int,int,org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Job <*> lost excess resource <*>.,trace,<org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker: void notifyLostResource(org.apache.flink.runtime.clusterframework.types.ResourceProfile)>
Start <*> with local state root directories <*>.,debug,"<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: void <init>(boolean,org.apache.flink.util.Reference,java.util.concurrent.Executor)>"
Starting Dispatcher REST endpoint.,debug,"<org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory: org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent create(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.clusterframework.types.ResourceID,java.util.concurrent.Executor,org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.blob.BlobServer,org.apache.flink.runtime.heartbeat.HeartbeatServices,org.apache.flink.runtime.metrics.MetricRegistry,org.apache.flink.runtime.dispatcher.ExecutionGraphInfoStore,org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceRetriever,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Starting Dispatcher.,debug,"<org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory: org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent create(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.clusterframework.types.ResourceID,java.util.concurrent.Executor,org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.blob.BlobServer,org.apache.flink.runtime.heartbeat.HeartbeatServices,org.apache.flink.runtime.metrics.MetricRegistry,org.apache.flink.runtime.dispatcher.ExecutionGraphInfoStore,org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceRetriever,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Starting ResourceManagerService.,debug,"<org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory: org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent create(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.clusterframework.types.ResourceID,java.util.concurrent.Executor,org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.blob.BlobServer,org.apache.flink.runtime.heartbeat.HeartbeatServices,org.apache.flink.runtime.metrics.MetricRegistry,org.apache.flink.runtime.dispatcher.ExecutionGraphInfoStore,org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceRetriever,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
"Received non-SSL request, redirecting to <*><*>",trace,"<org.apache.flink.runtime.net.RedirectingSslHandler$NonSslHandler: void channelRead(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,java.lang.Object)>"
Allocated <*>,debug,"<org.apache.flink.runtime.scheduler.SharedSlot: org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot lambda$allocateNonExistentLogicalSlot$1(java.lang.String,org.apache.flink.runtime.jobmaster.SlotRequestId,org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlot)>"
Attempting to cancel task <*> (<*>).,info,<org.apache.flink.runtime.taskmanager.Task: void cancelExecution()>
Select best slot for profile <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.PreviousAllocationSlotSelectionStrategy: java.util.Optional selectBestSlotForProfile(java.util.Collection,org.apache.flink.runtime.clusterframework.types.SlotProfile)>"
Could not delete file from local file cache.,error,<org.apache.flink.runtime.filecache.FileCache$DeleteProcess: void run()>
Starting allocation of slot <*> for job <*> with resource profile <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void allocateSlot(org.apache.flink.runtime.resourcemanager.slotmanager.TaskManagerSlotInformation,org.apache.flink.api.common.JobID,java.lang.String,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Loaded task state snapshot for checkpoint <*> successfully from disk.,debug,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: org.apache.flink.runtime.checkpoint.TaskStateSnapshot tryLoadTaskStateSnapshotFromDisk(long)>
Could not read task state snapshot file <*> for checkpoint <*>. Deleting the corresponding local state.,debug,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: org.apache.flink.runtime.checkpoint.TaskStateSnapshot tryLoadTaskStateSnapshotFromDisk(long)>
Unable to determine the canonical hostname. Input split assignment (such as for HDFS files) may be non-local when the canonical hostname is missing.,warn,<org.apache.flink.runtime.taskmanager.TaskManagerLocation: java.lang.String getFqdnHostName(java.net.InetAddress)>
getCanonicalHostName() Exception:,debug,<org.apache.flink.runtime.taskmanager.TaskManagerLocation: java.lang.String getFqdnHostName(java.net.InetAddress)>
Exception while deleting local state directory for allocation id <*>.,warn,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: void cleanupAllocationBaseDirs(org.apache.flink.runtime.clusterframework.types.AllocationID)>
An exception occurred during the metrics setup.,warn,<org.apache.flink.runtime.operators.DataSourceTask: void invoke()>
"DataSourceTask object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.DataSourceTask: void invoke()>
,<init>,<org.apache.flink.runtime.io.network.netty.NettyMessage$BacklogAnnouncement: org.apache.flink.runtime.io.network.netty.NettyMessage$BacklogAnnouncement readFrom(org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf)>
The \'<*>\' metrics will not be exposed because no pool named \'Metaspace\' could be found. This might be caused by the used JVM.,info,<org.apache.flink.runtime.metrics.util.MetricUtils: void instantiateMetaspaceMemoryMetrics(org.apache.flink.metrics.MetricGroup)>
More than one memory pool named \'Metaspace\' is present. Only the first pool was used for instantiating the \'<*>\' metrics.,debug,<org.apache.flink.runtime.metrics.util.MetricUtils: void instantiateMetaspaceMemoryMetrics(org.apache.flink.metrics.MetricGroup)>
Could not find driver class name for <*>. Please make sure <*> is configured.,warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map externalResourceDriversFromConfig(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Add external resources driver for <*>.,info,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map externalResourceDriversFromConfig(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Could not instantiate driver with factory <*> for <*>. <*>,warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map externalResourceDriversFromConfig(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Could not find factory class <*> for <*>.,warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map externalResourceDriversFromConfig(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Failed to read shuffle data.,debug,"<org.apache.flink.runtime.io.network.partition.SortMergeResultPartitionReadScheduler: java.util.Set readData(java.util.Queue,java.util.Queue)>"
Terminating the JobMasterService process for job <*> under leader id <*>.,debug,<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: java.util.concurrent.CompletableFuture closeAsync()>
<*>: Initialized <*>,debug,"<org.apache.flink.runtime.io.network.partition.ResultPartitionFactory: org.apache.flink.runtime.io.network.partition.ResultPartition create(java.lang.String,int,org.apache.flink.runtime.io.network.partition.ResultPartitionID,org.apache.flink.runtime.io.network.partition.ResultPartitionType,int,int,org.apache.flink.util.function.SupplierWithException)>"
"Could not create the HistoryServer\'s URL from protocol: <*>, hostname: <*> and port: <*>.",debug,<org.apache.flink.runtime.webmonitor.history.HistoryServerUtils: java.util.Optional getHistoryServerURL(org.apache.flink.configuration.Configuration)>
Not hostname has been specified for the HistoryServer. This indicates that it has not been started.,debug,<org.apache.flink.runtime.webmonitor.history.HistoryServerUtils: java.util.Optional getHistoryServerURL(org.apache.flink.configuration.Configuration)>
"Received , messageType,  message for job <*> with no CheckpointCoordinator, ",error,"<org.apache.flink.runtime.scheduler.ExecutionGraphHandler: void processCheckpointCoordinatorMessage(java.lang.String,org.apache.flink.util.function.ThrowingConsumer)>"
"Received , messageType,  message for job <*> with no CheckpointCoordinator, ",debug,"<org.apache.flink.runtime.scheduler.ExecutionGraphHandler: void processCheckpointCoordinatorMessage(java.lang.String,org.apache.flink.util.function.ThrowingConsumer)>"
Requested thread dump from unregistered TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture requestThreadDump(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.api.common.time.Time)>"
Job <*> is already marked as clean but clean up was triggered again.,warn,"<org.apache.flink.runtime.dispatcher.Dispatcher: void lambda$registerGloballyTerminatedJobInJobResultStore$30(org.apache.flink.api.common.JobID,org.apache.flink.runtime.executiongraph.ArchivedExecutionGraph,java.util.concurrent.CompletableFuture)>"
Job <*> has been registered for cleanup in the JobResultStore after reaching a terminal state.,info,"<org.apache.flink.runtime.dispatcher.Dispatcher: void lambda$registerGloballyTerminatedJobInJobResultStore$30(org.apache.flink.api.common.JobID,org.apache.flink.runtime.executiongraph.ArchivedExecutionGraph,java.util.concurrent.CompletableFuture)>"
Terminating TaskManagerRunner with exit code <*>.,error,<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: void runTaskManagerProcessSecurely(org.apache.flink.configuration.Configuration)>
Terminating TaskManagerRunner with exit code <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: void runTaskManagerProcessSecurely(org.apache.flink.configuration.Configuration)>
"<*> (<*>, synchronous part) in thread <*> took <*> ms.",logCompletedInternal,"<org.apache.flink.runtime.state.SnapshotStrategyRunner: java.util.concurrent.RunnableFuture snapshot(long,long,org.apache.flink.runtime.state.CheckpointStreamFactory,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
Shutting down the network environment and its components.,info,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Shutting down network connection manager,debug,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Cannot shut down the network connection manager.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Shutting down intermediate result partition manager,debug,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Cannot shut down the result partition manager.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Could not destroy all buffer pools.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Network buffer pool did not shut down properly.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Cannot close the file channel manager properly.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Cannot shut down batch shuffle read buffer pool properly.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Cannot shut down batch shuffle read IO executor properly.,warn,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: void close()>
Error retrieving a value from a buffer.,error,<org.apache.flink.runtime.operators.sort.CombineValueIterator: java.lang.Object next()>
Initiating in memory merge.,debug,"<org.apache.flink.runtime.operators.sort.SpillingThread: void mergeInMemory(java.util.Queue,org.apache.flink.util.MutableObjectIterator)>"
Releasing unused sort-buffer memory.,debug,"<org.apache.flink.runtime.operators.sort.SpillingThread: void mergeInMemory(java.util.Queue,org.apache.flink.util.MutableObjectIterator)>"
Stop-with-savepoint transitioned from <*> to <*> on execution termination handling with all executions being finished for job <*>.,debug,<org.apache.flink.runtime.scheduler.stopwithsavepoint.StopWithSavepointTerminationHandlerImpl: void handleExecutionsFinished()>
Loaded channel outbound factory: <*>,info,"<org.apache.flink.runtime.rest.RestClient: void <init>(org.apache.flink.configuration.Configuration,java.util.concurrent.Executor)>"
Could not load channel outbound factory.,error,"<org.apache.flink.runtime.rest.RestClient: void <init>(org.apache.flink.configuration.Configuration,java.util.concurrent.Executor)>"
Rest client endpoint started.,debug,"<org.apache.flink.runtime.rest.RestClient: void <init>(org.apache.flink.configuration.Configuration,java.util.concurrent.Executor)>"
unregistering <*>,debug,<org.apache.flink.runtime.io.network.TaskEventDispatcher: void unregisterPartition(org.apache.flink.runtime.io.network.partition.ResultPartitionID)>
Close ResourceManager connection <*>.,debug,"<org.apache.flink.runtime.jobmaster.JobMaster: void dissolveResourceManagerConnection(org.apache.flink.runtime.jobmaster.EstablishedResourceManagerConnection,java.lang.Exception)>"
Close ResourceManager connection <*>: <*>,info,"<org.apache.flink.runtime.jobmaster.JobMaster: void dissolveResourceManagerConnection(org.apache.flink.runtime.jobmaster.EstablishedResourceManagerConnection,java.lang.Exception)>"
Triggering stop-with-savepoint for job <*>.,info,"<org.apache.flink.runtime.scheduler.adaptive.Executing: java.util.concurrent.CompletableFuture stopWithSavepoint(java.lang.String,boolean,org.apache.flink.core.execution.SavepointFormatType)>"
PipelinedSubpartition#addRecovered,traceRecover,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: void addRecovered(org.apache.flink.runtime.io.network.buffer.BufferConsumer)>
Cancelling hash table operations.,debug,<org.apache.flink.runtime.operators.hash.CompactingHashTable: void abort()>
Found corrupted blob <*> under <*>. Deleting this blob.,info,"<org.apache.flink.runtime.blob.BlobUtils: void checkAndDeleteCorruptedBlobs(java.nio.file.Path,org.slf4j.Logger)>"
Could not delete the blob <*>.,debug,"<org.apache.flink.runtime.blob.BlobUtils: void checkAndDeleteCorruptedBlobs(java.nio.file.Path,org.slf4j.Logger)>"
Spilling Resettable Iterator opened.,debug,<org.apache.flink.runtime.operators.resettable.SpillingResettableIterator: void open()>
Closing hash table and releasing resources.,debug,<org.apache.flink.runtime.operators.hash.CompactingHashTable: void close()>
<*>,debug,"<org.apache.flink.runtime.operators.BatchTask: void readAndSetBroadcastInput(int,java.lang.String,org.apache.flink.runtime.operators.util.DistributedRuntimeUDFContext,int)>"
An exception happened while flushing the outputs,error,<org.apache.flink.runtime.io.network.api.writer.RecordWriter: void notifyFlusherException(java.lang.Throwable)>
Connecting to ResourceManager <*>,info,<org.apache.flink.runtime.jobmaster.JobMaster: void connectToResourceManager()>
Cannot reconnect because the JobManagerLeaderListener has already been stopped.,debug,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void reconnect()>
Cannot reconnect to an unknown JobMaster.,debug,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void reconnect()>
Archive local failure causing attempt <*> to fail: <*>,debug,<org.apache.flink.runtime.scheduler.SchedulerBase: void archiveFromFailureHandlingResult(org.apache.flink.runtime.scheduler.exceptionhistory.FailureHandlingResultSnapshot)>
created <*> for task=<*> subtask=<*> partition=<*>,debug,"<org.apache.flink.runtime.checkpoint.TaskStateAssignment: org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor$InflightDataGateOrPartitionRescalingDescriptor log(org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor$InflightDataGateOrPartitionRescalingDescriptor,int,int)>"
Could not properly remove the job <*> from the job leader id service.,warn,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void removeJob(org.apache.flink.api.common.JobID,java.lang.Exception)>"
Unable to instantiate security module factory <*>,error,<org.apache.flink.runtime.security.SecurityUtils: void installModules(org.apache.flink.runtime.security.SecurityConfiguration)>
GET BLOB <*>/<*> from <*>.,debug,"<org.apache.flink.runtime.blob.BlobClient: java.io.InputStream getInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
"Slot with allocationId <*> already exist, with resource profile <*>, job id <*> and index <*>. The required index is <*>.",info,"<org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl: boolean isDuplicatedSlot(org.apache.flink.runtime.taskexecutor.slot.TaskSlot,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.ResourceProfile,int)>"
Decline checkpoint <*> by task <*> of job <*> at <*>.,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void receiveDeclineMessage(org.apache.flink.runtime.messages.checkpoint.DeclineCheckpoint,java.lang.String)>"
Received another decline message for now expired checkpoint attempt <*> from task <*> of job <*> at <*> : <*>,debug,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void receiveDeclineMessage(org.apache.flink.runtime.messages.checkpoint.DeclineCheckpoint,java.lang.String)>"
Received decline message for unknown (too old?) checkpoint attempt <*> from task <*> of job <*> at <*> : <*>,debug,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void receiveDeclineMessage(org.apache.flink.runtime.messages.checkpoint.DeclineCheckpoint,java.lang.String)>"
Received heartbeat request from <*>.,debug,"<org.apache.flink.runtime.heartbeat.HeartbeatManagerImpl: java.util.concurrent.CompletableFuture requestHeartbeat(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.Object)>"
Job manager <*>@<*> was already registered.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse registerJobMasterInternal(org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.api.common.JobID,java.lang.String,org.apache.flink.runtime.clusterframework.types.ResourceID)>"
Registered job manager <*>@<*> for job <*>.,info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse registerJobMasterInternal(org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.api.common.JobID,java.lang.String,org.apache.flink.runtime.clusterframework.types.ResourceID)>"
Triggering thread info request <*>,debug,"<org.apache.flink.runtime.webmonitor.threadinfo.ThreadInfoRequestCoordinator: java.util.concurrent.CompletableFuture triggerThreadInfoRequest(java.util.Map,int,java.time.Duration,int)>"
"Completed checkpoint <*> for job <*> (<*> bytes, checkpointDuration=<*> ms, finalizationTime=<*> ms).",info,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void logCheckpointInfo(org.apache.flink.runtime.checkpoint.CompletedCheckpoint)>
,debug,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void logCheckpointInfo(org.apache.flink.runtime.checkpoint.CompletedCheckpoint)>
Install default filesystem.,info,"<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void configureFileSystems(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Register new TaskExecutor <*>.,debug,<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolService: boolean registerTaskManager(org.apache.flink.runtime.clusterframework.types.ResourceID)>
JobManager for job <*> with leader id <*> lost leadership.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl: void jobManagerLostLeadership(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.JobMasterId)>"
Block Resettable Iterator closed.,debug,<org.apache.flink.runtime.operators.resettable.AbstractBlockResettableIterator: void close()>
"Batch shuffle IO buffer pool initialized: numBuffers=<*>, bufferSize=<*>.",info,<org.apache.flink.runtime.io.disk.BatchShuffleReadBufferPool: void initialize()>
<*> (<*>) switched from <*> to <*>.,info,"<org.apache.flink.runtime.executiongraph.Execution: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
<*> (<*>) switched from <*> to <*> on <*>.,info,"<org.apache.flink.runtime.executiongraph.Execution: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
Error while notifying execution graph of execution state transition.,error,"<org.apache.flink.runtime.executiongraph.Execution: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
IOManager failed to delete temporary file <*>,warn,<org.apache.flink.runtime.io.disk.iomanager.IOManager: void deleteChannel(org.apache.flink.runtime.io.disk.iomanager.FileIOChannel$ID)>
Stop-with-savepoint transitioned from <*> to <*> on savepoint creation failure handling for job <*>.,debug,<org.apache.flink.runtime.scheduler.stopwithsavepoint.StopWithSavepointTerminationHandlerImpl: void handleSavepointCreationFailure(java.lang.Throwable)>
Starting Flink Mini Cluster,info,<org.apache.flink.runtime.minicluster.MiniCluster: void start()>
Using configuration <*>,debug,<org.apache.flink.runtime.minicluster.MiniCluster: void start()>
Starting Metrics Registry,info,<org.apache.flink.runtime.minicluster.MiniCluster: void start()>
Starting RPC Service(s),info,<org.apache.flink.runtime.minicluster.MiniCluster: void start()>
Flink Mini Cluster started successfully,info,<org.apache.flink.runtime.minicluster.MiniCluster: void start()>
Error while request key-value state location,info,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture requestKvStateLocation(org.apache.flink.api.common.JobID,java.lang.String)>"
"IO Thread \', <*>, \' terminated due to an exception. Shutting down I/O Manager., ",error,"<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync: void uncaughtException(java.lang.Thread,java.lang.Throwable)>"
IOManagerAsync did not shut down properly.,warn,"<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync: void uncaughtException(java.lang.Thread,java.lang.Throwable)>"
Restarting job.,info,"<org.apache.flink.runtime.scheduler.adaptive.FailureResultUtil: void restartOrFail(org.apache.flink.runtime.scheduler.adaptive.FailureResult,org.apache.flink.runtime.scheduler.adaptive.StateTransitions$ToRestarting,org.apache.flink.runtime.scheduler.adaptive.StateWithExecutionGraph)>"
Failing job.,info,"<org.apache.flink.runtime.scheduler.adaptive.FailureResultUtil: void restartOrFail(org.apache.flink.runtime.scheduler.adaptive.FailureResult,org.apache.flink.runtime.scheduler.adaptive.StateTransitions$ToRestarting,org.apache.flink.runtime.scheduler.adaptive.StateWithExecutionGraph)>"
<*> <*> took unexpected long (<*> ms) indicating that the checkpoint storage is overloaded.,debug,"<org.apache.flink.runtime.io.network.logger.NetworkActionsLogger: void lambda$measureIO$0(long,java.lang.String,java.lang.Object)>"
Mark heartbeat target <*> as unreachable because <*> consecutive heartbeat RPCs have failed.,debug,<org.apache.flink.runtime.heartbeat.HeartbeatMonitorImpl: void reportHeartbeatRpcFailure()>
Cancel <*> from <*>,debug,"<org.apache.flink.runtime.scheduler.SharedSlot: void cancelLogicalSlotRequest(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,java.lang.Throwable)>"
No SlotExecutionVertexAssignment for logical <*> from physical <*>},debug,"<org.apache.flink.runtime.scheduler.SharedSlot: void cancelLogicalSlotRequest(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,java.lang.Throwable)>"
Stopped TaskExecutor <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void handleOnStopException(java.lang.Throwable,java.lang.Throwable)>"
Attempted released of unknown data set <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl: java.util.concurrent.CompletableFuture releaseClusterPartitions(org.apache.flink.runtime.jobgraph.IntermediateDataSetID)>
Releasing cluster partitions for data set <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl: java.util.concurrent.CompletableFuture releaseClusterPartitions(org.apache.flink.runtime.jobgraph.IntermediateDataSetID)>
"Spilling Resettable Iterator closing. Stored , <*>,  records., ",debug,<org.apache.flink.runtime.operators.resettable.SpillingResettableMutableObjectIterator: java.util.List close()>
Downloading <*>/<*> from <*>,info,"<org.apache.flink.runtime.blob.BlobClient: void downloadFromBlobServer(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,java.net.InetSocketAddress,org.apache.flink.configuration.Configuration,int)>"
"<*>,  Retrying..., ",error,"<org.apache.flink.runtime.blob.BlobClient: void downloadFromBlobServer(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,java.net.InetSocketAddress,org.apache.flink.configuration.Configuration,int)>"
"<*>,  Retrying..., ",error,"<org.apache.flink.runtime.blob.BlobClient: void downloadFromBlobServer(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,java.net.InetSocketAddress,org.apache.flink.configuration.Configuration,int)>"
"<*>,  No retries left., ",error,"<org.apache.flink.runtime.blob.BlobClient: void downloadFromBlobServer(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,java.net.InetSocketAddress,org.apache.flink.configuration.Configuration,int)>"
Downloading <*>/<*> from <*> (retry <*>),info,"<org.apache.flink.runtime.blob.BlobClient: void downloadFromBlobServer(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,java.net.InetSocketAddress,org.apache.flink.configuration.Configuration,int)>"
Could not properly discard state object of checkpoint <*> belonging to task <*> of job <*>.,warn,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator$1: void run()>
Failed to register at job  manager <*> for job <*>.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection: void lambda$onRegistrationFailure$4(java.lang.Throwable)>
Batch jobs do not support local recovery. Falling back for request slot matching strategy to <*>.,warn,"<org.apache.flink.runtime.jobmaster.DefaultSlotPoolServiceSchedulerFactory: org.apache.flink.runtime.jobmaster.slotpool.RequestSlotMatchingStrategy getRequestSlotMatchingStrategy(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.jobgraph.JobType)>"
<*> discarding <*> drained requests,info,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestExecutorImpl: void cleanupRequests()>
Could not start MetricDumpActor. No metrics will be submitted to the WebInterface.,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void startQueryService(org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.clusterframework.types.ResourceID)>"
"Trying to connect to , targetAddress, ",info,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findConnectingAddress(java.net.InetSocketAddress,long,long)>"
Could not connect. Waiting for <*> msecs before next attempt,info,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findConnectingAddress(java.net.InetSocketAddress,long,long)>"
Could not connect. Waiting for <*> msecs before next attempt,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findConnectingAddress(java.net.InetSocketAddress,long,long)>"
Could not connect to <*>. Selecting a local address using heuristics.,warn,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findConnectingAddress(java.net.InetSocketAddress,long,long)>"
Could not find any IPv address that is not loopback or link-local. Using localhost address.,warn,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findConnectingAddress(java.net.InetSocketAddress,long,long)>"
Shutting down rest endpoint.,debug,<org.apache.flink.runtime.rest.RestClient: java.util.concurrent.CompletableFuture shutdownInternally(org.apache.flink.api.common.time.Time)>
Initialized MemoryManager with total memory size <*> and page size <*>.,debug,"<org.apache.flink.runtime.memory.MemoryManager: void <init>(long,int)>"
Access to physical memory size: com.sun.management.OperatingSystemMXBean incompatibly changed.,warn,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemory()>
Cannot determine size of physical memory for unknown operating system,error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemory()>
"Unrecognized OS: , <*>, ",error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemory()>
<*>/<*> finished recovering input.,debug,<org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel: void finishReadRecoveredState()>
"Unexpected dirty JobResultStore entry: Job \'<*>\' is listed as dirty, isn\'t part of this single-job cluster, though.",warn,"<org.apache.flink.runtime.dispatcher.runner.JobDispatcherLeaderProcessFactoryFactory: java.util.Optional extractDirtyJobResult(java.util.Collection,org.apache.flink.runtime.jobgraph.JobGraph)>"
Starting job <*> from savepoint <*> (<*>),info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean restoreSavepoint(org.apache.flink.runtime.jobgraph.SavepointRestoreSettings,java.util.Map,java.lang.ClassLoader)>"
Reset the checkpoint ID of job <*> to <*>.,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: boolean restoreSavepoint(org.apache.flink.runtime.jobgraph.SavepointRestoreSettings,java.util.Map,java.lang.ClassLoader)>"
Taking a state snapshot on operator <*> for checkpoint <*>,debug,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$checkpointCoordinator$6(long,java.util.concurrent.CompletableFuture)>"
Closing <*>.,info,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void close()>
Releasing state changelog storage under job id <*>.,debug,<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: void releaseStateChangelogStorageForJob(org.apache.flink.api.common.JobID)>
Could not store completed job <*>(<*>).,info,<org.apache.flink.runtime.dispatcher.Dispatcher: void writeToExecutionGraphInfoStore(org.apache.flink.runtime.scheduler.ExecutionGraphInfo)>
The slot with index <*> is already assigned to another allocation with id <*>.,info,"<org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl: boolean allocateSlot(int,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.api.common.time.Time)>"
"Cannot allocate the requested resources. Trying to allocate <*>, while the currently remaining available resources are <*>, total is <*>.",info,"<org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl: boolean allocateSlot(int,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.api.common.time.Time)>"
Connecting to ResourceManager <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void connectToResourceManager()>
Received accumulator result for unknown execution <*>.,debug,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void updateAccumulators(org.apache.flink.runtime.accumulators.AccumulatorSnapshot)>
Cannot update accumulators for job <*>.,error,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void updateAccumulators(org.apache.flink.runtime.accumulators.AccumulatorSnapshot)>
"Invalid metric dump category: , $i, ",debug,<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricStore: void add(org.apache.flink.runtime.metrics.dump.MetricDump)>
Malformed metric dump.,debug,<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricStore: void add(org.apache.flink.runtime.metrics.dump.MetricDump)>
Unexpected null keyed state handle of materialized part when deserializing changelog state-backend handle,warn,"<org.apache.flink.runtime.checkpoint.metadata.MetadataV2V3SerializerBase: org.apache.flink.runtime.state.KeyedStateHandle deserializeKeyedStateHandle(java.io.DataInputStream,org.apache.flink.runtime.checkpoint.metadata.MetadataV2V3SerializerBase$DeserializationContext)>"
,<init>,"<org.apache.flink.runtime.checkpoint.metadata.MetadataV2V3SerializerBase: org.apache.flink.runtime.state.KeyedStateHandle deserializeKeyedStateHandle(java.io.DataInputStream,org.apache.flink.runtime.checkpoint.metadata.MetadataV2V3SerializerBase$DeserializationContext)>"
Shutting down the kvState service and its components.,info,<org.apache.flink.runtime.taskexecutor.KvStateService: void shutdown()>
Shutting down Queryable State Client Proxy.,debug,<org.apache.flink.runtime.taskexecutor.KvStateService: void shutdown()>
Cannot shut down Queryable State Client Proxy.,warn,<org.apache.flink.runtime.taskexecutor.KvStateService: void shutdown()>
Shutting down Queryable State Data Server.,debug,<org.apache.flink.runtime.taskexecutor.KvStateService: void shutdown()>
Cannot shut down Queryable State Data Server.,warn,<org.apache.flink.runtime.taskexecutor.KvStateService: void shutdown()>
Successful shutdown (took <*> ms).,info,<org.apache.flink.runtime.io.network.netty.NettyServer: void shutdown()>
,moveTempFileToStore,"<org.apache.flink.runtime.blob.BlobServer: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Cannot decide whether state backend uses managed memory. Will reserve managed memory by default.,warn,"<org.apache.flink.runtime.state.StateBackendLoader: boolean stateBackendFromApplicationOrConfigOrDefaultUseManagedMemory(org.apache.flink.configuration.Configuration,java.util.Optional,java.lang.ClassLoader)>"
"JobManager successfully registered at ResourceManager, leader id: <*>.",info,<org.apache.flink.runtime.jobmaster.JobMaster: void establishResourceManagerConnection(org.apache.flink.runtime.jobmaster.JobMasterRegistrationSuccess)>
Ignoring resource manager connection to <*> because it\'s duplicated or outdated.,debug,<org.apache.flink.runtime.jobmaster.JobMaster: void establishResourceManagerConnection(org.apache.flink.runtime.jobmaster.JobMasterRegistrationSuccess)>
Create new JobMasterServiceProcess because we were granted leadership under <*>.,debug,<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void createNewJobMasterServiceProcess(java.util.UUID)>
Registration of job manager <*>@<*> failed.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse lambda$registerJobMaster$3(org.apache.flink.runtime.jobmaster.JobMasterId,java.lang.String,org.apache.flink.runtime.registration.RegistrationResponse,java.lang.Throwable)>"
Registration of job manager <*>@<*> failed.,info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse lambda$registerJobMaster$3(org.apache.flink.runtime.jobmaster.JobMasterId,java.lang.String,org.apache.flink.runtime.registration.RegistrationResponse,java.lang.Throwable)>"
"Checkpoint <*> size: <*>Kb, duration: <*>ms",trace,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void reportCompletedCheckpoint(org.apache.flink.runtime.checkpoint.CompletedCheckpoint)>
The setting for \'<*> : <*>\' is invalid. Using default value of <*>,warn,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStoreUtils: int getMaximumNumberOfRetainedCheckpoints(org.apache.flink.configuration.Configuration,org.slf4j.Logger)>"
Deploying <*> (attempt #<*>) with attempt id <*> and vertex id <*> to <*> with allocation id <*>,info,<org.apache.flink.runtime.executiongraph.Execution: void deploy()>
MemoryStateBackend has been deprecated. Please use \'hashmap\' state backend instead with JobManagerCheckpointStorage for equivalent functionality,warn,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadStateBackendFromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
State backend is set to job manager <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadStateBackendFromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
<*> state backend has been deprecated. Please use \'hashmap\' state backend instead.,warn,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadStateBackendFromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
State backend is set to heap memory <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadStateBackendFromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
Loading state backend via factory <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadStateBackendFromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
"Trying to cancel job <*> with savepoint, but no savepoint directory configured.",info,"<org.apache.flink.runtime.scheduler.stopwithsavepoint.StopWithSavepointTerminationManager: void checkSavepointActionPreconditions(org.apache.flink.runtime.checkpoint.CheckpointCoordinator,java.lang.String,org.apache.flink.api.common.JobID,org.slf4j.Logger)>"
"Reactive mode is configured for an unsupported cluster type. At the moment, reactive mode is only supported by standalone application clusters (bin/standalone-job.sh).",error,<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void <init>(org.apache.flink.configuration.Configuration)>
Releasing all broadcast variables.,debug,<org.apache.flink.runtime.operators.BatchTask: void closeLocalStrategiesAndCaches()>
"Error closing local strategy for input , i_, ",error,<org.apache.flink.runtime.operators.BatchTask: void closeLocalStrategiesAndCaches()>
"Error closing temp barrier for input , i_, ",error,<org.apache.flink.runtime.operators.BatchTask: void closeLocalStrategiesAndCaches()>
"Error closing cache for input , i_, ",error,<org.apache.flink.runtime.operators.BatchTask: void closeLocalStrategiesAndCaches()>
Idle slots have been returned; new total acquired resources: <*>,debug,<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: void releaseIdleSlots(long)>
Cleanup on error failed.,error,<org.apache.flink.runtime.operators.DataSinkTask: void cancel()>
znode <*> has been deleted,debug,"<org.apache.flink.runtime.util.ZooKeeperUtils: void deleteZNode(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,java.lang.String)>"
Retrying to delete znode because of other concurrent delete operation.,debug,"<org.apache.flink.runtime.util.ZooKeeperUtils: void deleteZNode(org.apache.flink.shaded.curator5.org.apache.curator.framework.CuratorFramework,java.lang.String)>"
"The handler of the request complete callback threw an exception, <*>_, ",error,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$WriterThread: void shutdown()>
"Caught an IOException when creating spill file: , directory, . Attempt , attempt_, ",warn,<org.apache.flink.runtime.io.network.api.serialization.SpanningWrapper: java.nio.channels.FileChannel createSpillingChannel()>
Release task <*> network resources (state: <*>).,debug,<org.apache.flink.runtime.taskmanager.Task: void releaseResources()>
Failed to close task state manager for task <*>.,error,<org.apache.flink.runtime.taskmanager.Task: void releaseResources()>
Received PUT call for BLOB of job <*>.,debug,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putInputStream(org.apache.flink.api.common.JobID,java.io.InputStream,org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putInputStream(org.apache.flink.api.common.JobID,java.io.InputStream,org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putInputStream(org.apache.flink.api.common.JobID,java.io.InputStream,org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Encountered obsolete JobManager registration success from <*> with leader session ID <*>.,debug,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection: void lambda$onRegistrationSuccess$1()>
Registration with <*> at <*> was successful.,debug,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$2(org.apache.flink.runtime.rpc.RpcGateway,org.apache.flink.runtime.registration.RegistrationResponse)>"
Registration with <*> at <*> was rejected.,debug,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$2(org.apache.flink.runtime.rpc.RpcGateway,org.apache.flink.runtime.registration.RegistrationResponse)>"
Registration failure at <*> occurred.,info,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$2(org.apache.flink.runtime.rpc.RpcGateway,org.apache.flink.runtime.registration.RegistrationResponse)>"
Received unknown response to registration attempt: <*>,error,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$2(org.apache.flink.runtime.rpc.RpcGateway,org.apache.flink.runtime.registration.RegistrationResponse)>"
Pausing and re-attempting registration in <*> ms,info,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$register$2(org.apache.flink.runtime.rpc.RpcGateway,org.apache.flink.runtime.registration.RegistrationResponse)>"
Starting <*> TaskManager(s),info,<org.apache.flink.runtime.minicluster.MiniCluster: void startTaskManagers()>
Could not determine whether <*> denotes a local path.,warn,"<org.apache.flink.runtime.jobgraph.JobGraphUtils: java.util.Map prepareUserArtifactEntries(java.util.Map,org.apache.flink.api.common.JobID)>"
"<*>,  interrupted while waiting for the writer thread to die, ",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestExecutorImpl: void close()>
"Spilling buffer , <*>, ., ",debug,<org.apache.flink.runtime.operators.sort.SpillingThread: java.util.List startSpilling(java.util.Queue)>
"Spilled buffer , <*>, ., ",debug,<org.apache.flink.runtime.operators.sort.SpillingThread: java.util.List startSpilling(java.util.Queue)>
Spilling done.,debug,<org.apache.flink.runtime.operators.sort.SpillingThread: java.util.List startSpilling(java.util.Queue)>
Releasing sort-buffer memory.,debug,<org.apache.flink.runtime.operators.sort.SpillingThread: java.util.List startSpilling(java.util.Queue)>
Ignore global failure because we already finished the job <*>.,debug,<org.apache.flink.runtime.scheduler.adaptive.Finished: void handleGlobalFailure(java.lang.Throwable)>
"Received request , <*>, , ",trace,"<org.apache.flink.runtime.rest.handler.AbstractHandler: void respondAsLeader(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.rest.handler.router.RoutedRequest,org.apache.flink.runtime.webmonitor.RestfulGateway)>"
The handler instance for <*> had already been closed.,debug,"<org.apache.flink.runtime.rest.handler.AbstractHandler: void respondAsLeader(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.rest.handler.router.RoutedRequest,org.apache.flink.runtime.webmonitor.RestfulGateway)>"
Implementation error: Received a request that wasn\'t a FullHttpRequest.,error,"<org.apache.flink.runtime.rest.handler.AbstractHandler: void respondAsLeader(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.rest.handler.router.RoutedRequest,org.apache.flink.runtime.webmonitor.RestfulGateway)>"
Starting request processing.,trace,"<org.apache.flink.runtime.rest.handler.AbstractHandler: void respondAsLeader(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.rest.handler.router.RoutedRequest,org.apache.flink.runtime.webmonitor.RestfulGateway)>"
Could not get all ZooKeeper children. Node <*> contained corrupted data. Ignoring this node.,warn,<org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore: java.util.List getAllAndLock(org.apache.flink.util.function.FunctionWithException)>
Complete slot allocation with allocationId <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void addAllocatedSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Register new allocated slot with allocationId <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void addAllocatedSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
<*>: Releasing <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartition: void release(java.lang.Throwable)>
Added <*> to <*> without any older checkpoint to subsume.,debug,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStore: org.apache.flink.runtime.checkpoint.CompletedCheckpoint addCheckpointAndSubsumeOldestOne(org.apache.flink.runtime.checkpoint.CompletedCheckpoint,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,java.lang.Runnable)>"
Added <*> to <*> and subsume <*>.,debug,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStore: org.apache.flink.runtime.checkpoint.CompletedCheckpoint addCheckpointAndSubsumeOldestOne(org.apache.flink.runtime.checkpoint.CompletedCheckpoint,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,java.lang.Runnable)>"
Job <*> acquired excess resource <*>.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker: void notifyAcquiredResource(org.apache.flink.runtime.clusterframework.types.ResourceProfile)>
Checkpointing has not been enabled.,<init>,<org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler: org.apache.flink.runtime.rest.messages.checkpoints.CheckpointingStatistics createCheckpointingStatistics(org.apache.flink.runtime.executiongraph.AccessExecutionGraph)>
FileChannelManager removed spill file directory <*>,info,<org.apache.flink.runtime.io.disk.FileChannelManagerImpl: void lambda$getFileCloser$0(java.io.File)>
<*>,debug,"<org.apache.flink.runtime.operators.BatchTask: void releaseBroadcastVariables(java.lang.String,int,org.apache.flink.runtime.operators.util.DistributedRuntimeUDFContext)>"
Received file upload request for file <*>,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture requestFileUploadByFilePath(java.lang.String,java.lang.String)>"
The file <*> is unavailable on the TaskExecutor <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture requestFileUploadByFilePath(java.lang.String,java.lang.String)>"
Failed to flush the current sort buffer.,error,<org.apache.flink.runtime.io.network.partition.SortMergeResultPartition: void flushAll()>
Could not archive completed job <*>(<*>) to the history server.,info,"<org.apache.flink.runtime.dispatcher.Dispatcher: org.apache.flink.runtime.messages.Acknowledge lambda$archiveExecutionGraphToHistoryServer$32(org.apache.flink.runtime.scheduler.ExecutionGraphInfo,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Query metrics for <*>.,debug,<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void queryMetrics(org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceGateway)>
Error during partition cleanup.,error,<org.apache.flink.runtime.operators.hash.MutableHashTable: void clearPartitions()>
Transport type \'auto\': using EPOLL.,info,"<org.apache.flink.runtime.io.network.netty.NettyServer: int init(org.apache.flink.runtime.io.network.netty.NettyBufferPool,java.util.function.Function)>"
Transport type \'auto\': using NIO.,info,"<org.apache.flink.runtime.io.network.netty.NettyServer: int init(org.apache.flink.runtime.io.network.netty.NettyBufferPool,java.util.function.Function)>"
Successful initialization (took <*> ms). Listening on SocketAddress <*>.,info,"<org.apache.flink.runtime.io.network.netty.NettyServer: int init(org.apache.flink.runtime.io.network.netty.NettyBufferPool,java.util.function.Function)>"
"Cannot fail slot , allocationId,  because the TaskManager , taskManagerId,  is unknown., ",warn,"<org.apache.flink.runtime.jobmaster.JobMaster: void failSlot(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.clusterframework.types.AllocationID,java.lang.Exception)>"
"Cannot create recoverable writer due to <*>, will use the ordinary writer.",info,"<org.apache.flink.runtime.state.filesystem.FsCheckpointMetadataOutputStream: org.apache.flink.runtime.state.filesystem.MetadataOutputStreamWrapper getOutputStreamWrapper(org.apache.flink.core.fs.FileSystem,org.apache.flink.core.fs.Path)>"
Job <*> has been added to the <*> by another process.,debug,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: void handleAddedJobGraph(org.apache.flink.api.common.JobID)>
<*> starting checkpoint <*> (<*>),debug,"<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void start(long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
Exception while handling result from async call in <*>. Triggering job failover.,error,<org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext: void handleUncaughtExceptionFromAsyncCall(java.lang.Throwable)>
The derived Network Memory size (<*>) does not match the configured Network Memory fraction (<*>) from the configured Total Flink Memory size (<*>). The derived Network Memory size will be used.,info,"<org.apache.flink.runtime.util.config.memory.taskmanager.TaskExecutorFlinkMemoryUtils: void sanityCheckNetworkMemory(org.apache.flink.configuration.Configuration,org.apache.flink.configuration.MemorySize,org.apache.flink.configuration.MemorySize)>"
Request upload of file <*> from TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture requestTaskManagerFileUploadByName(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.String,org.apache.flink.api.common.time.Time)>"
Request upload of file <*> from unregistered TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture requestTaskManagerFileUploadByName(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.String,org.apache.flink.api.common.time.Time)>"
Failed to gather a thread info sample for <*>,debug,"<org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker$ThreadInfoSampleCompletionCallback: void accept(org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoStats,java.lang.Throwable)>"
Error during stats completion.,error,"<org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker$ThreadInfoSampleCompletionCallback: void accept(org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoStats,java.lang.Throwable)>"
"Could not submit task because there is no JobManager associated for the job , jobId, , ",debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: org.apache.flink.runtime.taskexecutor.exceptions.TaskSubmissionException lambda$submitTask$3(org.apache.flink.api.common.JobID)>
Obsolete JobManager registration failure from <*> with leader session ID <*>.,debug,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection: void lambda$onRegistrationFailure$5(java.lang.Throwable)>
Shutting down TaskExecutorStateChangelogStoragesManager.,info,<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: void shutdown()>
Enabled external resources: <*>,info,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: org.apache.flink.runtime.externalresource.ExternalResourceInfoProvider createStaticExternalResourceInfoProviderFromConfig(org.apache.flink.configuration.Configuration,org.apache.flink.core.plugin.PluginManager)>"
Fail to subsume the old checkpoint.,warn,"<org.apache.flink.runtime.checkpoint.CheckpointSubsumeHelper: java.util.Optional subsume(java.util.Deque,int,org.apache.flink.runtime.checkpoint.CheckpointSubsumeHelper$SubsumeAction)>"
Skipping savepoint state for operator <*>.,info,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.checkpoint.CompletedCheckpoint loadAndValidateCheckpoint(org.apache.flink.api.common.JobID,java.util.Map,org.apache.flink.runtime.state.CompletedCheckpointStorageLocation,java.lang.ClassLoader,boolean,org.apache.flink.runtime.checkpoint.CheckpointProperties,org.apache.flink.runtime.jobgraph.RestoreMode)>"
Skipping empty savepoint state for operator <*>.,info,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.checkpoint.CompletedCheckpoint loadAndValidateCheckpoint(org.apache.flink.api.common.JobID,java.util.Map,org.apache.flink.runtime.state.CompletedCheckpointStorageLocation,java.lang.ClassLoader,boolean,org.apache.flink.runtime.checkpoint.CheckpointProperties,org.apache.flink.runtime.jobgraph.RestoreMode)>"
LocalInputChannel#getNextBuffer,traceInput,<org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel: java.util.Optional getNextBuffer()>
Error while responding to the http request.,error,"<org.apache.flink.runtime.rest.handler.LeaderRetrievalHandler: void lambda$channelRead0$0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.rest.handler.router.RoutedRequest,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,org.apache.flink.runtime.webmonitor.RestfulGateway)>"
Starting the resource manager.,info,<org.apache.flink.runtime.resourcemanager.ResourceManager: void onStart()>
Get the latest completed checkpoints failed,warn,<org.apache.flink.runtime.checkpoint.CompletedCheckpointStore: long getLatestCheckpointId()>
Stopping DefaultJobGraphStore.,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void stop()>
Trying to recover job with job id <*>.,info,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: java.util.Optional tryRecoverJob(org.apache.flink.api.common.JobID)>
"Skipping recovery of job with job id <*>, because it already finished in a previous execution",info,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: java.util.Optional tryRecoverJob(org.apache.flink.api.common.JobID)>
"Worker <*> did not register in <*>, will stop it and request a new one if needed.",warn,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void lambda$scheduleWorkerRegistrationTimeoutCheck$2(org.apache.flink.runtime.clusterframework.types.ResourceID)>
Could not connect to ResourceManager right now.,debug,<org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler: org.apache.flink.runtime.rest.handler.RestHandlerException lambda$loadTaskManagerFile$2()>
"The cleanup of job <*> failed. The job\'s artifacts in the different directories (\'<*>\', \'<*>\', \'<*>\') and its JobResultStore entry in \'<*>\' (in HA mode) should be checked for manual cleanup.",warn,"<org.apache.flink.runtime.dispatcher.Dispatcher: java.lang.Void logCleanupErrorWarning(org.apache.flink.api.common.JobID,java.lang.Throwable)>"
TaskManager #<*> failed.,error,<org.apache.flink.runtime.minicluster.MiniCluster$TerminatingFatalErrorHandler: void onFatalError(java.lang.Throwable)>
"Unsupported ACL option: , <*>,  provided, ",error,<org.apache.flink.runtime.util.ZooKeeperUtils$ZkClientACLMode: org.apache.flink.runtime.util.ZooKeeperUtils$ZkClientACLMode fromConfig(org.apache.flink.configuration.Configuration)>
Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.,info,<org.apache.flink.runtime.security.modules.HadoopModuleFactory: org.apache.flink.runtime.security.modules.SecurityModule createModule(org.apache.flink.runtime.security.SecurityConfiguration)>
Cannot create Hadoop Security Module.,error,<org.apache.flink.runtime.security.modules.HadoopModuleFactory: org.apache.flink.runtime.security.modules.SecurityModule createModule(org.apache.flink.runtime.security.SecurityConfiguration)>
Trying to register multiple checkpoint hooks with the name: <*>,warn,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void enableCheckpointing(org.apache.flink.runtime.jobgraph.tasks.CheckpointCoordinatorConfiguration,java.util.List,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.state.StateBackend,org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.runtime.checkpoint.CheckpointStatsTracker,org.apache.flink.runtime.checkpoint.CheckpointsCleaner)>"
Loading missing file from classloader: <*>,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
Unable to load requested file <*> from classloader,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
error while responding,error,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
Unable to load requested file <*> from classloader,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
Unable to load requested file <*> from classloader,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
"Responding \'NOT MODIFIED\' for file \', <*>, , ",debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
"Responding with file \', <*>, , ",debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
Could not find file <*>.,debug,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
Failed to serve file.,error,"<org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler: void respondToRequest(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest,java.lang.String)>"
Fatal error occurred in the cluster entrypoint.,error,<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void onFatalError(java.lang.Throwable)>
Error closing the solution set hash table after unsuccessful creation.,error,<org.apache.flink.runtime.iterative.task.IterationHeadTask: org.apache.flink.runtime.operators.hash.CompactingHashTable initCompactingHashTable()>
Error freeing memory after error during solution set hash table creation.,error,<org.apache.flink.runtime.iterative.task.IterationHeadTask: org.apache.flink.runtime.operators.hash.CompactingHashTable initCompactingHashTable()>
"Outer Join Driver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.AbstractOuterJoinDriver: void prepare()>
Requesting paths for query services failed.,debug,"<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void lambda$fetchMetrics$1(java.util.Collection,java.lang.Throwable)>"
"ChainedReduceCombineDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.chaining.ChainedReduceCombineDriver: void openTask()>
Triggering <*>savepoint for job <*>.,info,"<org.apache.flink.runtime.scheduler.SchedulerBase: java.util.concurrent.CompletableFuture triggerSavepoint(java.lang.String,boolean,org.apache.flink.core.execution.SavepointFormatType)>"
Cleanup didn\'t succeed after job submission failed for job <*>.,warn,"<org.apache.flink.runtime.dispatcher.Dispatcher: org.apache.flink.runtime.messages.Acknowledge lambda$handleTermination$3(org.apache.flink.api.common.JobID,java.lang.Throwable,java.lang.Void,java.lang.Throwable)>"
Failed to submit job <*>.,error,"<org.apache.flink.runtime.dispatcher.Dispatcher: org.apache.flink.runtime.messages.Acknowledge lambda$handleTermination$3(org.apache.flink.api.common.JobID,java.lang.Throwable,java.lang.Void,java.lang.Throwable)>"
Initiating tracking of resources for job <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker: org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker lambda$getOrCreateTracker$0(org.apache.flink.api.common.JobID,org.apache.flink.api.common.JobID)>"
The amount of the <*> should be configured. Will ignore that resource.,warn,<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map getExternalResourceAmountMap(org.apache.flink.configuration.Configuration)>
The amount of the <*> should be positive while finding <*>. Will ignore that resource.,warn,<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map getExternalResourceAmountMap(org.apache.flink.configuration.Configuration)>
Could not obtain the current leader.,warn,<org.apache.flink.runtime.webmonitor.retriever.LeaderGatewayRetriever: java.util.concurrent.CompletableFuture getFuture()>
Error while retrieving the leader gateway. Retrying to connect to <*>.,warn,<org.apache.flink.runtime.webmonitor.retriever.LeaderGatewayRetriever: java.util.concurrent.CompletableFuture getFuture()>
Error while retrieving the leader gateway. Retrying to connect to <*>.,warn,<org.apache.flink.runtime.webmonitor.retriever.LeaderGatewayRetriever: java.util.concurrent.CompletableFuture getFuture()>
Stopping <*>.,info,<org.apache.flink.runtime.dispatcher.runner.AbstractDispatcherLeaderProcess: void closeInternal()>
Using restart back off time strategy <*> for <*> (<*>).,info,"<org.apache.flink.runtime.scheduler.adaptive.AdaptiveSchedulerFactory: org.apache.flink.runtime.scheduler.SchedulerNG createInstance(org.slf4j.Logger,org.apache.flink.runtime.jobgraph.JobGraph,java.util.concurrent.Executor,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.jobmaster.slotpool.SlotPoolService,java.util.concurrent.ScheduledExecutorService,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CheckpointRecoveryFactory,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.apache.flink.runtime.metrics.groups.JobManagerJobMetricGroup,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.jobmaster.ExecutionDeploymentTracker,long,org.apache.flink.runtime.concurrent.ComponentMainThreadExecutor,org.apache.flink.runtime.rpc.FatalErrorHandler,org.apache.flink.runtime.executiongraph.JobStatusListener)>"
<*> loop terminated,debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestExecutorImpl: void run()>
<*>: Requesting REMOTE subpartition <*> of partition <*>. <*>,debug,<org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel: void requestSubpartition()>
Performing merge of <*> sorted streams.,debug,"<org.apache.flink.runtime.operators.sort.SpillingThread: org.apache.flink.runtime.operators.sort.MergeIterator getMergingIterator(java.util.List,java.util.List,java.util.List,org.apache.flink.util.MutableObjectIterator)>"
Received slot report from instance <*>: <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Received slot report for unknown task manager with instance id <*>. Ignoring this report.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Detected concurrent file modifications. This should only happen if multipleBlobServer use the same storage directory.,warn,"<org.apache.flink.runtime.blob.BlobUtils: void internalMoveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,org.slf4j.Logger,org.apache.flink.runtime.blob.BlobStore,org.apache.flink.runtime.blob.BlobUtils$MoveFileOperation)>"
File upload for an existing file with key <*> for job <*>. This may indicate a duplicate upload or a hash collision. Ignoring newest upload.,warn,"<org.apache.flink.runtime.blob.BlobUtils: void internalMoveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,org.slf4j.Logger,org.apache.flink.runtime.blob.BlobStore,org.apache.flink.runtime.blob.BlobUtils$MoveFileOperation)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobUtils: void internalMoveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,org.slf4j.Logger,org.apache.flink.runtime.blob.BlobStore,org.apache.flink.runtime.blob.BlobUtils$MoveFileOperation)>"
Could not delete the storage file <*>.,warn,"<org.apache.flink.runtime.blob.BlobUtils: void internalMoveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,org.slf4j.Logger,org.apache.flink.runtime.blob.BlobStore,org.apache.flink.runtime.blob.BlobUtils$MoveFileOperation)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobUtils: void internalMoveTempFileToStore(java.io.File,org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,java.io.File,org.slf4j.Logger,org.apache.flink.runtime.blob.BlobStore,org.apache.flink.runtime.blob.BlobUtils$MoveFileOperation)>"
Start <*>.,info,<org.apache.flink.runtime.dispatcher.runner.AbstractDispatcherLeaderProcess: void startInternal()>
Trigger heartbeat request.,debug,<org.apache.flink.runtime.heartbeat.HeartbeatManagerSenderImpl: void run()>
Starting split enumerator for source <*>.,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void start()>
Failed to create Source Enumerator for source <*>,error,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void start()>
"User file cache uses directory , <*>, ",info,"<org.apache.flink.runtime.filecache.FileCache: void <init>(java.lang.String[],org.apache.flink.runtime.blob.PermanentBlobService,java.util.concurrent.ScheduledExecutorService,long)>"
"User file cache cannot create directory , <*>, ",error,"<org.apache.flink.runtime.filecache.FileCache: void <init>(java.lang.String[],org.apache.flink.runtime.blob.PermanentBlobService,java.util.concurrent.ScheduledExecutorService,long)>"
"User file cache cannot remove prior directory , <*>, ",warn,"<org.apache.flink.runtime.filecache.FileCache: void <init>(java.lang.String[],org.apache.flink.runtime.blob.PermanentBlobService,java.util.concurrent.ScheduledExecutorService,long)>"
Ignore JobManager gained leadership message for <*> because we are already connected to it.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void establishJobManagerConnection(org.apache.flink.runtime.taskexecutor.JobTable$Job,org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.runtime.jobmaster.JMTMRegistrationSuccess)>"
Establish JobManager connection for job <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void establishJobManagerConnection(org.apache.flink.runtime.taskexecutor.JobTable$Job,org.apache.flink.runtime.jobmaster.JobMasterGateway,org.apache.flink.runtime.jobmaster.JMTMRegistrationSuccess)>"
<*>,info,<org.apache.flink.runtime.iterative.task.IterationTailTask: void run()>
<*>,info,<org.apache.flink.runtime.iterative.task.IterationTailTask: void run()>
"Duplicate config key <*> occurred for external resources, the one named <*> will overwrite the value.",warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.lang.String lambda$getExternalResourceConfigurationKeys$0(java.lang.String,java.lang.String,java.util.Map,java.lang.String,java.lang.String)>"
"Could not load Queryable State Server. Probable reason: flink-queryable-state-runtime is not in the classpath. To enable Queryable State, please move the flink-queryable-state-runtime jar from the opt to the lib folder. Cause: , <*>, ",debug,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateServer createKvStateServer(java.lang.String,java.util.Iterator,int,int,org.apache.flink.runtime.query.KvStateRegistry,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
"Could not load Queryable State Server. Probable reason: flink-queryable-state-runtime is not in the classpath. To enable Queryable State, please move the flink-queryable-state-runtime jar from the opt to the lib folder.",info,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateServer createKvStateServer(java.lang.String,java.util.Iterator,int,int,org.apache.flink.runtime.query.KvStateRegistry,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
Queryable State Server could not be created: ,error,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateServer createKvStateServer(java.lang.String,java.util.Iterator,int,int,org.apache.flink.runtime.query.KvStateRegistry,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
Failed to instantiate the Queryable State Server.,error,"<org.apache.flink.runtime.query.QueryableStateUtils: org.apache.flink.runtime.query.KvStateServer createKvStateServer(java.lang.String,java.util.Iterator,int,int,org.apache.flink.runtime.query.KvStateRegistry,org.apache.flink.queryablestate.network.stats.KvStateRequestStats)>"
Created <*>,debug,"<org.apache.flink.runtime.io.network.partition.BufferWritingResultPartition: org.apache.flink.runtime.io.network.partition.ResultSubpartitionView createSubpartitionView(int,org.apache.flink.runtime.io.network.partition.BufferAvailabilityListener)>"
Attempting to load configured state backend for savepoint disposal,info,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.StateBackend loadStateBackend(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
"No state backend configured, attempting to dispose savepoint with configured checkpoint storage",debug,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.StateBackend loadStateBackend(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Could not load configured state backend.,info,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.StateBackend loadStateBackend(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Detailed exception:,debug,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.StateBackend loadStateBackend(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Clean up the high availability data for job <*>.,info,<org.apache.flink.runtime.highavailability.AbstractHaServices: void lambda$globalCleanupAsync$0(org.apache.flink.api.common.JobID)>
Finished cleaning up the high availability data for job <*>.,info,<org.apache.flink.runtime.highavailability.AbstractHaServices: void lambda$globalCleanupAsync$0(org.apache.flink.api.common.JobID)>
Recovered <*> workers from previous attempt.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void onPreviousAttemptWorkersRecovered(java.util.Collection)>
Worker <*> recovered from previous attempt.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void onPreviousAttemptWorkersRecovered(java.util.Collection)>
Sending request of class <*> to <*>:<*><*>,debug,"<org.apache.flink.runtime.rest.RestClient: java.util.concurrent.CompletableFuture sendRequest(java.lang.String,int,org.apache.flink.runtime.rest.messages.MessageHeaders,org.apache.flink.runtime.rest.messages.MessageParameters,org.apache.flink.runtime.rest.messages.RequestBody,java.util.Collection,org.apache.flink.runtime.rest.versioning.RestAPIVersion)>"
Cannot determine memory architecture. Using pure file-based shuffle.,warn,<org.apache.flink.runtime.io.network.partition.ResultPartitionFactory: org.apache.flink.runtime.io.network.partition.BoundedBlockingSubpartitionType getBoundedBlockingType()>
Registering task executor <*> under <*> at the slot manager.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Task executor <*> was already registered.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Task executor <*> could not be registered.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Received notification for job <*> having acquired resource <*>.,trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker: void notifyAcquiredResource(org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Savepoint stored in <*>. Now cancelling <*>.,info,"<org.apache.flink.runtime.scheduler.SchedulerBase: java.lang.String lambda$triggerSavepoint$6(boolean,java.lang.String,java.lang.Throwable)>"
Connected to ZooKeeper quorum. Leader election can start.,debug,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
"Connection to ZooKeeper suspended, waiting for reconnection.",warn,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
Connection to ZooKeeper was reconnected. Leader election can be restarted.,info,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
Connection to ZooKeeper lost. The contender no longer participates in the leader election.,warn,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
"<*>\'s leader retrieval listener reported an exception for job <*>. However, the service is no longer running.",debug,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void handleError(java.lang.Exception)>
"<*> adding input data, checkpoint <*>, channel: <*>, startSeqNum: <*>",trace,"<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void addInputData(long,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo,int,org.apache.flink.util.CloseableIterator)>"
Exception while disposing local state store <*>.,warn,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: void doRelease(java.lang.Iterable)>
"<*> finishing output data, checkpoint <*>",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void finishOutput(long)>
Registered <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: void registerResultPartition(org.apache.flink.runtime.io.network.partition.ResultPartition)>
"append, keyGroup=<*>, <*> bytes",trace,"<org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogWriter: void append(int,byte[])>"
Clearing resource requirements of job <*>,info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void processResourceRequirements(org.apache.flink.runtime.slots.ResourceRequirements)>
Received resource requirements from job <*>: <*>,info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void processResourceRequirements(org.apache.flink.runtime.slots.ResourceRequirements)>
Retrieving all stored job ids from <*>.,debug,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: java.util.Collection getJobIds()>
Could not parse job id from <*>. This indicates a malformed name.,warn,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: java.util.Collection getJobIds()>
Retrieved job ids <*> from <*>,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: java.util.Collection getJobIds()>
Write leader information <*> for <*>.,debug,"<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void publishLeaderInformation(java.lang.String,org.apache.flink.runtime.leaderelection.LeaderInformation)>"
Refusing to deploy execution vertex <*> because this deployment was superseded by another deployment,debug,"<org.apache.flink.runtime.scheduler.DefaultScheduler: java.lang.Void lambda$deployOrHandleError$12(org.apache.flink.runtime.scheduler.ExecutionVertexVersion,org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,java.lang.Object,java.lang.Throwable)>"
AllGroupCombine starting.,debug,<org.apache.flink.runtime.operators.AllGroupCombineDriver: void run()>
<*> has failed,warn,<org.apache.flink.runtime.metrics.util.SystemResourcesCounter: void run()>
Shutting down rest endpoint.,info,<org.apache.flink.runtime.rest.RestServerEndpoint: java.util.concurrent.CompletableFuture closeAsync()>
,checkAndDeleteCorruptedBlobs,<org.apache.flink.runtime.blob.BlobServer: void checkStoredBlobsForCorruption()>
Revoke leadership of <*> (<*>@<*>).,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onRevokeLeadership()>
Clearing the leader information on <*>.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onRevokeLeadership()>
Ignoring the revoke leadership notification since the <*> has already been closed.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onRevokeLeadership()>
Resource manager service is not running. Ignore granting leadership with session ID <*>.,info,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: void lambda$grantLeadership$2(java.util.UUID)>
Resource manager service is granted leadership with session id <*>.,info,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: void lambda$grantLeadership$2(java.util.UUID)>
"Error closing block memory iterator: , <*>, ",error,<org.apache.flink.runtime.operators.sort.AbstractMergeIterator: void close()>
RECEIVED SIGNAL <*>: SIG<*>. Shutting down as requested.,info,<org.apache.flink.runtime.util.SignalHandler$Handler: void handle(sun.misc.Signal)>
Refusing to assign slot to execution vertex <*> because this deployment was superseded by another deployment,debug,"<org.apache.flink.runtime.scheduler.DefaultScheduler: org.apache.flink.runtime.jobmaster.LogicalSlot lambda$assignResource$8(org.apache.flink.runtime.scheduler.ExecutionVertexVersion,org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,org.apache.flink.runtime.jobmaster.LogicalSlot,java.lang.Throwable)>"
Ignoring scheduled action because expected state <*> is not the actual state <*>.,debug,"<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: void runIfState(org.apache.flink.runtime.scheduler.adaptive.State,java.lang.Runnable)>"
Could not parse command line arguments <*>.,error,"<org.apache.flink.runtime.entrypoint.ClusterEntrypointUtils: java.lang.Object parseParametersOrExit(java.lang.String[],org.apache.flink.runtime.entrypoint.parser.ParserResultFactory,java.lang.Class)>"
Could not fail task <*>.,error,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void failTask(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,java.lang.Throwable)>"
Cannot find task to fail for execution <*> with exception:,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void failTask(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,java.lang.Throwable)>"
Could not upload file <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: org.apache.flink.runtime.blob.TransientBlobKey lambda$requestFileUploadByFilePath$23(java.lang.String,java.lang.String)>"
The file <*> does not exist on the TaskExecutor <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: org.apache.flink.runtime.blob.TransientBlobKey lambda$requestFileUploadByFilePath$23(java.lang.String,java.lang.String)>"
Spilling sort buffer without large record handling.,debug,"<org.apache.flink.runtime.operators.sort.NormalizedKeySorter: void writeToOutput(org.apache.flink.runtime.io.disk.iomanager.ChannelWriterOutputView,org.apache.flink.runtime.operators.sort.LargeRecordHandler)>"
Spilling sort buffer with large record handling.,debug,"<org.apache.flink.runtime.operators.sort.NormalizedKeySorter: void writeToOutput(org.apache.flink.runtime.io.disk.iomanager.ChannelWriterOutputView,org.apache.flink.runtime.operators.sort.LargeRecordHandler)>"
Spilling large record to large record fetch file.,debug,"<org.apache.flink.runtime.operators.sort.NormalizedKeySorter: void writeToOutput(org.apache.flink.runtime.io.disk.iomanager.ChannelWriterOutputView,org.apache.flink.runtime.operators.sort.LargeRecordHandler)>"
Rejecting TaskManager registration attempt because of wrong job id <*>.,debug,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture registerTaskManager(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.TaskManagerRegistrationInformation,org.apache.flink.api.common.time.Time)>"
Could not accept TaskManager registration.,error,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture registerTaskManager(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.TaskManagerRegistrationInformation,org.apache.flink.api.common.time.Time)>"
Ignoring registration attempt of TaskManager <*> with the same session id <*>.,debug,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture registerTaskManager(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.TaskManagerRegistrationInformation,org.apache.flink.api.common.time.Time)>"
Remove task manager <*>.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void removeTaskManager(org.apache.flink.runtime.instance.InstanceID)>
Using restart back off time strategy <*> for <*> (<*>).,info,"<org.apache.flink.runtime.scheduler.adaptivebatch.AdaptiveBatchSchedulerFactory: org.apache.flink.runtime.scheduler.SchedulerNG createInstance(org.slf4j.Logger,org.apache.flink.runtime.jobgraph.JobGraph,java.util.concurrent.Executor,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.jobmaster.slotpool.SlotPoolService,java.util.concurrent.ScheduledExecutorService,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CheckpointRecoveryFactory,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.apache.flink.runtime.metrics.groups.JobManagerJobMetricGroup,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.jobmaster.ExecutionDeploymentTracker,long,org.apache.flink.runtime.concurrent.ComponentMainThreadExecutor,org.apache.flink.runtime.rpc.FatalErrorHandler,org.apache.flink.runtime.executiongraph.JobStatusListener)>"
Remove cached file for TaskExecutor <*>.,debug,<org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler: void removeBlob(org.apache.flink.shaded.guava30.com.google.common.cache.RemovalNotification)>
Large record did not fit into a fresh sort buffer. Putting into large record store.,debug,"<org.apache.flink.runtime.operators.sort.SorterInputGateway: void writeLarge(java.lang.Object,org.apache.flink.runtime.operators.sort.InMemorySorter)>"
Exception from secondary/local checkpoint stream.,warn,<org.apache.flink.runtime.state.CheckpointStreamWithResultProvider$PrimaryAndSecondaryStream: org.apache.flink.runtime.state.SnapshotResult closeAndFinalizeCheckpointStreamResult()>
Cancelling task <*> after the producer of partition <*> with attempt ID <*> has entered state <*>.,debug,<org.apache.flink.runtime.io.network.partition.consumer.RemoteChannelStateChecker: void abortConsumptionOrIgnoreCheckResult(org.apache.flink.runtime.io.network.partition.PartitionProducerStateProvider$ResponseHandle)>
Trying to recover from a global failure.,info,<org.apache.flink.runtime.scheduler.DefaultScheduler: void handleGlobalFailure(java.lang.Throwable)>
Found registered local state for checkpoint <*> in subtask (<*> - <*> - <*>) : <*>,trace,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: org.apache.flink.runtime.checkpoint.TaskStateSnapshot retrieveLocalState(long)>
Found registered local state for checkpoint <*> in subtask (<*> - <*> - <*>),debug,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: org.apache.flink.runtime.checkpoint.TaskStateSnapshot retrieveLocalState(long)>
Did not find registered local state for checkpoint <*> in subtask (<*> - <*> - <*>),debug,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: org.apache.flink.runtime.checkpoint.TaskStateSnapshot retrieveLocalState(long)>
"Creating spilling resettable iterator with , <*>,  pages of memory., ",debug,"<org.apache.flink.runtime.operators.resettable.SpillingResettableIterator: void <init>(java.util.Iterator,org.apache.flink.api.common.typeutils.TypeSerializer,org.apache.flink.runtime.memory.MemoryManager,org.apache.flink.runtime.io.disk.iomanager.IOManager,java.util.List,boolean)>"
Implementation error: Received a response that wasn\'t a FullHttpResponse.,error,"<org.apache.flink.runtime.rest.RestClient$ClientHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,java.lang.Object)>"
Request <*> file upload from TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture requestTaskManagerFileUploadByType(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.taskexecutor.FileType,org.apache.flink.api.common.time.Time)>"
Request upload of file <*> from unregistered TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture requestTaskManagerFileUploadByType(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.taskexecutor.FileType,org.apache.flink.api.common.time.Time)>"
Failed to notify job graph listener onRemovedJobGraph event for <*>,error,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void onRemovedJobGraph(org.apache.flink.api.common.JobID)>
Leader information was lost: The listener will be notified accordingly.,debug,<org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService: void notifyLeaderAddress(org.apache.flink.runtime.leaderelection.LeaderInformation)>
"New leader information: Leader=<*>, session ID=<*>.",debug,<org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService: void notifyLeaderAddress(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Ignoring notification since the <*> has already been closed.,debug,<org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService: void notifyLeaderAddress(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Deleting <*>.,debug,<org.apache.flink.runtime.blob.FileSystemBlobStore: boolean delete(java.lang.String)>
The given path <*> is not present anymore. No deletion is required.,debug,<org.apache.flink.runtime.blob.FileSystemBlobStore: boolean delete(java.lang.String)>
"Failed to delete blob at , blobPath, ",warn,<org.apache.flink.runtime.blob.FileSystemBlobStore: boolean delete(java.lang.String)>
"Shut down cluster because application is in <*>, diagnostics <*>.",info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture deregisterApplication(org.apache.flink.runtime.clusterframework.ApplicationStatus,java.lang.String)>"
Persist after <*>,debug,<org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogWriter: java.util.concurrent.CompletableFuture persist(org.apache.flink.runtime.state.changelog.SequenceNumber)>
Memory Logger,<init>,"<org.apache.flink.runtime.taskmanager.MemoryLogger: void <init>(org.slf4j.Logger,long,java.util.concurrent.CompletableFuture)>"
Failed to initialize direct buffer pool bean.,warn,"<org.apache.flink.runtime.taskmanager.MemoryLogger: void <init>(org.slf4j.Logger,long,java.util.concurrent.CompletableFuture)>"
Closing the slot manager.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void close()>
Request could not be routed to any handler. Uri:<*> Method:<*>,trace,"<org.apache.flink.runtime.rest.handler.router.RouterHandler: void respondNotFound(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest)>"
Received confirmation for checkpoint <*> in subtask (<*> - <*> - <*>). Starting to prune history.,debug,<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void confirmCheckpoint(long)>
Receive slot request <*> for job <*> from resource manager with leader id <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture requestSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile,java.lang.String,org.apache.flink.runtime.resourcemanager.ResourceManagerId,org.apache.flink.api.common.time.Time)>"
Could not allocate slot for allocation id <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture requestSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile,java.lang.String,org.apache.flink.runtime.resourcemanager.ResourceManagerId,org.apache.flink.api.common.time.Time)>"
Cannot access local server address,error,<org.apache.flink.runtime.rest.RestServerEndpoint: java.net.InetSocketAddress getServerAddress()>
"<*>,  interrupted while waiting for a request (continue waiting), ",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestExecutorImpl: void loop()>
Initializing the large record spilling...,debug,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: long addRecord(java.lang.Object)>
Converting recovered input channels (<*> channels),debug,<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: void convertRecoveredInputChannels()>
Reserving free slot <*> for slot request id <*> and profile <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: java.util.Optional allocateAvailableSlot(org.apache.flink.runtime.jobmaster.SlotRequestId,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
GroupReduceCombineDriver object reuse: <*>.,debug,<org.apache.flink.runtime.operators.GroupReduceCombineDriver: void prepare()>
Starting the slot manager.,info,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: void start(org.apache.flink.runtime.resourcemanager.ResourceManagerId,java.util.concurrent.Executor,org.apache.flink.runtime.resourcemanager.slotmanager.ResourceActions)>"
Removing cache directory <*>,info,<org.apache.flink.runtime.webmonitor.WebMonitorEndpoint: void lambda$shutDownInternal$5(java.io.File)>
Stopping checkpoint coordinator for job <*>.,info,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void shutdown()>
,close,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void shutdown()>
Shutting down,info,"<org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore: void shutdown(org.apache.flink.api.common.JobStatus,org.apache.flink.runtime.checkpoint.CheckpointsCleaner)>"
Checkpoint with ID <*> at \'<*>\' not discarded.,info,"<org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore: void shutdown(org.apache.flink.api.common.JobStatus,org.apache.flink.runtime.checkpoint.CheckpointsCleaner)>"
Ignoring error notification since the service has been stopped.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService$LeaderElectionFatalErrorHandler: void onFatalError(java.lang.Throwable)>
<*>: Received consumed notification for subpartition <*>.,debug,<org.apache.flink.runtime.io.network.partition.PipelinedResultPartition: void decrementNumberOfUsers(int)>
Replacing old registration of TaskExecutor <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse registerTaskExecutorInternal(org.apache.flink.runtime.taskexecutor.TaskExecutorGateway,org.apache.flink.runtime.resourcemanager.TaskExecutorRegistration)>"
Discard registration from TaskExecutor <*> at (<*>) because the framework did not recognize it,warn,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse registerTaskExecutorInternal(org.apache.flink.runtime.taskexecutor.TaskExecutorGateway,org.apache.flink.runtime.resourcemanager.TaskExecutorRegistration)>"
Registering TaskManager with ResourceID <*> (<*>) at ResourceManager,info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse registerTaskExecutorInternal(org.apache.flink.runtime.taskexecutor.TaskExecutorGateway,org.apache.flink.runtime.resourcemanager.TaskExecutorRegistration)>"
Triggering a checkpoint for job <*>.,info,<org.apache.flink.runtime.scheduler.adaptive.StateWithExecutionGraph: java.util.concurrent.CompletableFuture triggerCheckpoint()>
"Creating spilling resettable iterator with , <*>,  pages of memory., ",debug,"<org.apache.flink.runtime.operators.resettable.SpillingResettableMutableObjectIterator: void <init>(org.apache.flink.util.MutableObjectIterator,org.apache.flink.api.common.typeutils.TypeSerializer,org.apache.flink.runtime.memory.MemoryManager,org.apache.flink.runtime.io.disk.iomanager.IOManager,java.util.List,boolean)>"
Fail to get number of queued buffers :,debug,<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: int getNumberOfQueuedBuffers()>
Unregistering task executor <*> from the slot manager.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean unregisterTaskManager(org.apache.flink.runtime.instance.InstanceID,java.lang.Exception)>"
There is no task executor registered with instance ID <*>. Ignoring this message.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean unregisterTaskManager(org.apache.flink.runtime.instance.InstanceID,java.lang.Exception)>"
Closing SourceCoordinator for source <*>.,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void close()>
Source coordinator for source <*> closed.,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void close()>
Sending end-of-superstep to all iteration outputs.,debug,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void sendEndOfSuperstepToAllIterationOutputs()>
Couldn\'t create ArchivedExecutionConfig for job <*> ,error,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: org.apache.flink.api.common.ArchivedExecutionConfig getArchivedExecutionConfig()>
Successful shutdown (took <*> ms).,info,<org.apache.flink.runtime.io.network.netty.NettyClient: void shutdown()>
Recovered slot allocation snapshots <*>.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void tryLoadLocalAllocationSnapshots()>
Cannot reallocate restored slot <*>.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void tryLoadLocalAllocationSnapshots()>
Error while canceling task <*>.,error,<org.apache.flink.runtime.taskmanager.Task: void cancelInvokable(org.apache.flink.runtime.jobgraph.tasks.TaskInvokable)>
Sorting keys for large records.,debug,<org.apache.flink.runtime.operators.sort.SpillingThread: void mergeOnDisk(java.util.List)>
Beginning final merge.,debug,<org.apache.flink.runtime.operators.sort.SpillingThread: void mergeOnDisk(java.util.List)>
Spilling and merging thread done.,debug,<org.apache.flink.runtime.operators.sort.SpillingThread: void mergeOnDisk(java.util.List)>
Received notification for job <*> having new resource requirements <*>.,trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker: void notifyResourceRequirements(org.apache.flink.api.common.JobID,java.util.Collection)>"
Creating highly available BLOB storage directory at <*>,info,"<org.apache.flink.runtime.blob.FileSystemBlobStore: void <init>(org.apache.flink.core.fs.FileSystem,java.lang.String)>"
Created highly available BLOB storage directory at <*>,debug,"<org.apache.flink.runtime.blob.FileSystemBlobStore: void <init>(org.apache.flink.core.fs.FileSystem,java.lang.String)>"
Free slot with allocation id <*> because: <*>,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void freeSlotInternal(org.apache.flink.runtime.clusterframework.types.AllocationID,java.lang.Throwable)>"
Could not free slot for allocation id <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void freeSlotInternal(org.apache.flink.runtime.clusterframework.types.AllocationID,java.lang.Throwable)>"
Ignoring the freeing of slot <*> because the TaskExecutor is shutting down.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void freeSlotInternal(org.apache.flink.runtime.clusterframework.types.AllocationID,java.lang.Throwable)>"
Failed to reset the coordinator to checkpoint and start.,error,"<org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$DeferrableCoordinator: void resetAndStart(long,byte[],boolean)>"
Could not delete file <*>.,debug,<org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore: void deleteExecutionGraphFile(org.apache.flink.api.common.JobID)>
Slot <*> transitioned from <*> to <*> for job <*>.,trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker$MultiSlotStatusUpdateListener: void notifySlotStatusChange(org.apache.flink.runtime.resourcemanager.slotmanager.TaskManagerSlotInformation,org.apache.flink.runtime.resourcemanager.slotmanager.SlotState,org.apache.flink.runtime.resourcemanager.slotmanager.SlotState,org.apache.flink.api.common.JobID)>"
Resetting coordinator to checkpoint.,info,"<org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator: void resetToCheckpoint(long,byte[])>"
Leader node changed while <*> is the leader with session ID <*>. New leader information <*>.,trace,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onLeaderInformationChange(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Writing leader information by <*> since the external storage is empty.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onLeaderInformationChange(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Correcting leader information by <*>.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onLeaderInformationChange(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Ignoring change notification since the <*> has already been closed.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onLeaderInformationChange(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Adding file <*> to request.,trace,"<org.apache.flink.runtime.rest.RestClient: org.apache.flink.runtime.rest.RestClient$Request createRequest(java.lang.String,java.lang.String,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpMethod,org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf,java.util.Collection)>"
Abort checkpoint <*>@<*> for <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture abortCheckpoint(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,long,long,long)>"
"TaskManager received an aborted checkpoint for unknown task , executionAttemptID, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture abortCheckpoint(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,long,long,long)>"
<*> <*> <*> @ <*>,trace,"<org.apache.flink.runtime.io.network.logger.NetworkActionsLogger: void traceRecover(java.lang.String,org.apache.flink.runtime.io.network.buffer.BufferConsumer,java.lang.String,org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo)>"
Starting periodic memory usage logger,info,"<org.apache.flink.runtime.taskmanager.MemoryLogger: void startIfConfigured(org.slf4j.Logger,org.apache.flink.configuration.Configuration,java.util.concurrent.CompletableFuture)>"
Remove job <*> from job leader id monitoring.,debug,<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService: void removeJob(org.apache.flink.api.common.JobID)>
Install security context.,info,<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: org.apache.flink.runtime.security.contexts.SecurityContext installSecurityContext(org.apache.flink.configuration.Configuration)>
Reserve slot <*> for slot request id <*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: void reserveFreeSlot(org.apache.flink.runtime.jobmaster.SlotRequestId,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
"The overall size of BLOBs in the cache exceeds the limit. Limit = <*>, Current: <*>, The size of next BLOB: <*>.",warn,"<org.apache.flink.runtime.blob.BlobCacheSizeTracker: void track(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,long)>"
"Attempt to track a duplicated BLOB. This may indicate a duplicate upload or a hash collision. Ignoring newest upload. JobID = <*>, BlobKey = <*>",warn,"<org.apache.flink.runtime.blob.BlobCacheSizeTracker: void track(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey,long)>"
Error while cancelling checkpoint timeout task,warn,<org.apache.flink.runtime.checkpoint.PendingCheckpoint: void cancelCanceller()>
Ignoring offered slots from unknown task manager <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: java.util.Collection offerSlots(org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,java.util.Collection)>"
Could not find execution graph information file for <*>. Estimating the size instead.,debug,"<org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore: int calculateSize(org.apache.flink.api.common.JobID,org.apache.flink.runtime.scheduler.ExecutionGraphInfo)>"
Will not retry creating worker in <*>.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void tryResetWorkerCreationCoolDown()>
Failing deployments <*> due to no longer being deployed.,debug,"<org.apache.flink.runtime.jobmaster.JobMaster$1: void onMissingDeploymentsOf(java.util.Collection,org.apache.flink.runtime.clusterframework.types.ResourceID)>"
"Offering scale up to scale up controller with currentCumulativeParallelism=<*>, newCumulativeParallelism=<*>",debug,<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: boolean canScaleUp(org.apache.flink.runtime.executiongraph.ExecutionGraph)>
Trying to release more memory <*> than it was reserved <*> so far for the owner <*>,warn,"<org.apache.flink.runtime.memory.MemoryManager: java.lang.Long lambda$releaseMemory$4(long,java.lang.Object,java.lang.Object,java.lang.Long)>"
Shutting down BLOB cache,info,<org.apache.flink.runtime.blob.AbstractBlobCache: void close()>
Fatal error occurred on JobManager.,error,<org.apache.flink.runtime.jobmaster.JobMaster: void handleJobMasterError(java.lang.Throwable)>
"ChainedAllReduceDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.chaining.ChainedAllReduceDriver: void setup(org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable)>
Ignoring invalid file size threshold value (<*>): <*> - using default value <*> instead.,warn,"<org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage: void <init>(org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage,org.apache.flink.configuration.ReadableConfig)>"
Try to register at job manager <*> with leader id <*>.,info,"<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener: void openRpcConnectionTo(java.lang.String,org.apache.flink.runtime.jobmaster.JobMasterId)>"
Unexpected termination of the JobMasterService for job <*> under leader id <*>.,warn,"<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: void lambda$registerJobMasterServiceFutures$1(java.lang.Void,java.lang.Throwable)>"
Combiner starting.,debug,<org.apache.flink.runtime.operators.ReduceCombineDriver: void run()>
Discarding the results produced by task execution <*>.,info,"<org.apache.flink.runtime.executiongraph.Execution: void handlePartitionCleanup(boolean,boolean)>"
Received <*> slot offers from TaskExecutor <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: java.util.Collection offerSlots(java.util.Collection,org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,long)>"
No reporter class nor factory set for reporter <*>. Metrics might not be exposed/reported.,warn,"<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Optional loadReporter(java.lang.String,org.apache.flink.configuration.Configuration,java.util.Map)>"
"AllReduceDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.AllReduceDriver: void prepare()>
Could not properly dispose the private states in the pending checkpoint <*> of job <*>.,warn,<org.apache.flink.runtime.checkpoint.PendingCheckpoint$PendingCheckpointDiscardObject: void discard()>
Cleaning up <*>.,debug,<org.apache.flink.runtime.blob.FileSystemBlobStore: void closeAndCleanupAllData()>
Failed to clean up recovery directory.,error,<org.apache.flink.runtime.blob.FileSystemBlobStore: void closeAndCleanupAllData()>
"Iterator initialized using , numPages,  memory buffers., ",debug,"<org.apache.flink.runtime.operators.resettable.AbstractBlockResettableIterator: void <init>(org.apache.flink.api.common.typeutils.TypeSerializer,org.apache.flink.runtime.memory.MemoryManager,int,org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable)>"
<*>: Created <*> input channels (<*>).,debug,"<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory: void createInputChannels(java.lang.String,org.apache.flink.runtime.deployment.InputGateDeploymentDescriptor,org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate,org.apache.flink.runtime.deployment.SubpartitionIndexRange,org.apache.flink.runtime.io.network.metrics.InputChannelMetrics)>"
Ignoring transition of vertex <*> to <*> while being <*>.,debug,"<org.apache.flink.runtime.executiongraph.Execution: void processFail(java.lang.Throwable,boolean,java.util.Map,org.apache.flink.runtime.executiongraph.IOMetrics,boolean,boolean)>"
Failed to go from <*> to <*> because the ExecutionGraph creation failed.,info,"<org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph: void handleExecutionGraphCreation(org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph$ExecutionGraphWithVertexParallelism,java.lang.Throwable)>"
Successfully reserved and assigned the required slots for the ExecutionGraph.,debug,"<org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph: void handleExecutionGraphCreation(org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph$ExecutionGraphWithVertexParallelism,java.lang.Throwable)>"
,<init>,"<org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph: void handleExecutionGraphCreation(org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph$ExecutionGraphWithVertexParallelism,java.lang.Throwable)>"
Failed to reserve and assign the required slots. Waiting for new resources.,debug,"<org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph: void handleExecutionGraphCreation(org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph$ExecutionGraphWithVertexParallelism,java.lang.Throwable)>"
The JobManager under <*> rejected the registration for job <*>: <*>. Releasing all job related resources.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void handleRejectedJobManagerConnection(org.apache.flink.api.common.JobID,java.lang.String,org.apache.flink.runtime.jobmaster.JMTMRegistrationRejection)>"
An Exception was thrown during error notification of a remote input channel.,warn,<org.apache.flink.runtime.io.network.netty.CreditBasedPartitionRequestClientHandler: void notifyAllChannelsOfErrorAndClose(java.lang.Throwable)>
Discard update for input partitions of task <*>. Task is no longer running.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture updatePartitions(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,java.lang.Iterable,org.apache.flink.api.common.time.Time)>"
Inconsistent execution state after stopping with savepoint. At least one execution is still in one of the following states: <*>.,warn,"<org.apache.flink.runtime.scheduler.stopwithsavepoint.StopWithSavepointTerminationHandlerImpl: void terminateExceptionallyWithGlobalFailover(java.lang.Iterable,java.lang.String)>"
Discard update for input gate partition <*> of result <*> in task <*>. The partition is no longer available.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$updatePartitions$11(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.runtime.executiongraph.PartitionInfo,org.apache.flink.runtime.taskmanager.Task)>"
Could not update input data location for task <*>. Trying to fail task.,error,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$updatePartitions$11(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.runtime.executiongraph.PartitionInfo,org.apache.flink.runtime.taskmanager.Task)>"
Unhandled exception,warn,"<org.apache.flink.runtime.rest.handler.PipelineErrorHandler: void exceptionCaught(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,java.lang.Throwable)>"
"<*> not running, but <*>; not sampling",trace,"<org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker: java.util.Map matchExecutionsWithGateways(org.apache.flink.runtime.executiongraph.AccessExecutionVertex[],org.apache.flink.runtime.resourcemanager.ResourceManagerGateway)>"
ExecutionVertex <*> is currently not assigned,trace,"<org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker: java.util.Map matchExecutionsWithGateways(org.apache.flink.runtime.executiongraph.AccessExecutionVertex[],org.apache.flink.runtime.resourcemanager.ResourceManagerGateway)>"
Fail to get size of queued buffers :,debug,<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: long getSizeOfQueuedBuffers()>
Ignore recovered job <*> because the job is currently being executed.,debug,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: java.lang.Void filterOutDuplicateJobSubmissionException(java.lang.Throwable)>
Releasing <*> partitions because of shutdown.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: void shutdown()>
Successful shutdown.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: void shutdown()>
Successfully written allocation state metadata file <*> for job <*> and allocation <*>.,debug,<org.apache.flink.runtime.taskexecutor.slot.FileSlotAllocationSnapshotPersistenceService: void persistAllocationSnapshot(org.apache.flink.runtime.taskexecutor.slot.SlotAllocationSnapshot)>
<*>: Finished <*>.,debug,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: void finish()>
Loaded channel inbound factory: <*>,info,<org.apache.flink.runtime.rest.RestServerEndpoint: void <init>(org.apache.flink.configuration.Configuration)>
Could not load channel inbound factory.,error,<org.apache.flink.runtime.rest.RestServerEndpoint: void <init>(org.apache.flink.configuration.Configuration)>
Shutting down I/O manager.,debug,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync: void close()>
Clear all pending allocations for job <*>.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void clearPendingAllocationsOfJob(org.apache.flink.api.common.JobID)>
Skip scheduling trigger request because the CheckpointCoordinator is shut down,debug,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: void scheduleTriggerRequest()>
Triggering thread info sample for tasks: <*>,debug,"<org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker: void triggerThreadInfoSampleInternal(org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker$Key,org.apache.flink.runtime.executiongraph.AccessExecutionJobVertex)>"
Release shared slot externally (<*>),debug,<org.apache.flink.runtime.scheduler.SharedSlot: void releaseExternally()>
", <*>,  elements updated in the solutionset in iteration , iteration, , ",info,"<org.apache.flink.runtime.iterative.convergence.WorksetEmptyConvergenceCriterion: boolean isConverged(int,org.apache.flink.types.LongValue)>"
There was no slot registered with slot id <*>.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker: void removeSlot(org.apache.flink.runtime.clusterframework.types.SlotID)>
The connection was unexpectedly closed by the client.,warn,"<org.apache.flink.runtime.rest.handler.AbstractHandler: java.util.concurrent.CompletableFuture handleException(java.lang.Throwable,org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest)>"
Exception occurred in REST handler.,error,"<org.apache.flink.runtime.rest.handler.AbstractHandler: java.util.concurrent.CompletableFuture handleException(java.lang.Throwable,org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest)>"
Exception occurred in REST handler: <*>,error,"<org.apache.flink.runtime.rest.handler.AbstractHandler: java.util.concurrent.CompletableFuture handleException(java.lang.Throwable,org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest)>"
Unhandled exception.,error,"<org.apache.flink.runtime.rest.handler.AbstractHandler: java.util.concurrent.CompletableFuture handleException(java.lang.Throwable,org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpRequest)>"
Triggering Checkpoint <*> for job <*> failed due to <*>,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.lang.Void lambda$triggerCheckpointRequest$10(org.apache.flink.runtime.checkpoint.PendingCheckpoint,java.lang.Throwable)>"
Ignore \'<*>\' because the leadership runner is no longer running.,trace,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void runIfStateRunning(java.lang.Runnable,java.lang.String)>"
Stopping worker <*>.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void internalStopWorker(org.apache.flink.runtime.clusterframework.types.ResourceID)>
Overriding Flink\'s temporary file directories with those specified in the Flink config: <*>,info,"<org.apache.flink.runtime.clusterframework.BootstrapTools: void updateTmpDirectoriesInConfiguration(org.apache.flink.configuration.Configuration,java.lang.String)>"
Setting directories for temporary files to: <*>,info,"<org.apache.flink.runtime.clusterframework.BootstrapTools: void updateTmpDirectoriesInConfiguration(org.apache.flink.configuration.Configuration,java.lang.String)>"
"improper use of releaseJob() without a matching number of registerJob() calls for jobId , jobId, ",warn,<org.apache.flink.runtime.blob.PermanentBlobCache: void releaseJob(org.apache.flink.api.common.JobID)>
Worker <*> is terminated. Diagnostics: <*>,info,"<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void onWorkerTerminated(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.String)>"
"Could not acquire the minimum required resources, failing slot requests. Acquired: <*>. Current slot pool status: <*>",warn,<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: void failPendingRequests(java.util.Collection)>
Trigger checkpoint <*>@<*> for <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture triggerCheckpoint(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,long,long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
"TaskManager received a checkpoint request for unknown task , executionAttemptID, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture triggerCheckpoint(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,long,long,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
Trying to select the network interface and address to use by connecting to the leading JobManager.,info,"<org.apache.flink.runtime.util.LeaderRetrievalUtils: java.net.InetAddress findConnectingAddress(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService,java.time.Duration,org.apache.flink.runtime.rpc.RpcSystemUtils)>"
"TaskManager will try to connect for , timeout,  before falling back to heuristics, ",info,"<org.apache.flink.runtime.util.LeaderRetrievalUtils: java.net.InetAddress findConnectingAddress(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService,java.time.Duration,org.apache.flink.runtime.rpc.RpcSystemUtils)>"
Could not stop the leader retrieval service.,warn,"<org.apache.flink.runtime.util.LeaderRetrievalUtils: java.net.InetAddress findConnectingAddress(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService,java.time.Duration,org.apache.flink.runtime.rpc.RpcSystemUtils)>"
Could not stop the leader retrieval service.,warn,"<org.apache.flink.runtime.util.LeaderRetrievalUtils: java.net.InetAddress findConnectingAddress(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService,java.time.Duration,org.apache.flink.runtime.rpc.RpcSystemUtils)>"
Received slot report from instance <*>: <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Received slot report for unknown task manager with instance id <*>. Ignoring this report.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Cannot determine physical memory of machine for MacOS host,error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForMac()>
"<*>,  was interrupted without shutdown., ",warn,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$WriterThread: void run()>
"I/O writing thread encountered an error, <*>_, ",error,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$WriterThread: void run()>
"The handler of the request-complete-callback threw an exception, <*>_, ",error,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$WriterThread: void run()>
Ignoring action because <*> has already been stopped.,debug,<org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner: void runActionIfRunning(java.lang.Runnable)>
Resource manager service has already started.,debug,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: void start()>
Starting resource manager service.,info,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: void start()>
Evicted result with trigger id <*> because its TTL of <*>s has expired.,info,"<org.apache.flink.runtime.rest.handler.async.CompletedOperationCache: void lambda$new$0(java.time.Duration,org.apache.flink.shaded.guava30.com.google.common.cache.RemovalNotification)>"
Responding with error: <*>.,debug,"<org.apache.flink.runtime.io.network.netty.PartitionRequestServerHandler: void respondWithError(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,java.lang.Throwable,org.apache.flink.runtime.io.network.partition.consumer.InputChannelID)>"
"Could not serialize accumulator , name, , ",error,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: org.apache.flink.util.SerializedValue serializeAccumulator(java.lang.String,org.apache.flink.util.OptionalFailure)>"
Record the pending allocations <*>.,trace,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void replaceAllPendingAllocations(java.util.Map)>
Error while discarding operator states.,warn,<org.apache.flink.runtime.checkpoint.SubtaskState: void discardState()>
PUT BLOB stream to <*>.,debug,"<org.apache.flink.runtime.blob.BlobClient: org.apache.flink.runtime.blob.BlobKey putInputStream(org.apache.flink.api.common.JobID,java.io.InputStream,org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Task \'<*>\' did not react to cancelling signal - <*>; it is stuck for <*> seconds in method:\n <*>,warn,"<org.apache.flink.runtime.taskmanager.Task: void logTaskThreadStackTrace(java.lang.Thread,java.lang.String,long,java.lang.String)>"
Picked <*> randomly from the configured temporary directories to be used as working directory base.,debug,<org.apache.flink.runtime.entrypoint.ClusterEntrypointUtils: java.io.File lambda$generateWorkingDirectoryFile$1(org.apache.flink.configuration.Configuration)>
Marking checkpoint <*> as completed for source <*>.,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$notifyCheckpointComplete$7(long)>
Discarding IncrementalRemoteKeyedStateHandle (registered = <*>) for checkpoint <*> from backend with id <*>.,trace,<org.apache.flink.runtime.state.IncrementalRemoteKeyedStateHandle: void discardState()>
Could not properly discard meta data.,warn,<org.apache.flink.runtime.state.IncrementalRemoteKeyedStateHandle: void discardState()>
Could not properly discard misc file states.,warn,<org.apache.flink.runtime.state.IncrementalRemoteKeyedStateHandle: void discardState()>
Could not properly discard new sst file states.,warn,<org.apache.flink.runtime.state.IncrementalRemoteKeyedStateHandle: void discardState()>
Counters,logDumpSizeWouldExceedLimit,<org.apache.flink.runtime.metrics.dump.MetricQueryService: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult enforceSizeLimit(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Meters,logDumpSizeWouldExceedLimit,<org.apache.flink.runtime.metrics.dump.MetricQueryService: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult enforceSizeLimit(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Gauges,logDumpSizeWouldExceedLimit,<org.apache.flink.runtime.metrics.dump.MetricQueryService: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult enforceSizeLimit(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Histograms,logDumpSizeWouldExceedLimit,<org.apache.flink.runtime.metrics.dump.MetricQueryService: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult enforceSizeLimit(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
"GroupCombineDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.AllGroupCombineDriver: void prepare()>
Cannot determine the size of the physical memory for Linux host (using \'/proc/meminfo\'). Unexpected format.,error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForLinux()>
Cannot determine the size of the physical memory for Linux host (using \'/proc/meminfo\'). Unexpected format.,error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForLinux()>
Cannot determine the size of the physical memory for Linux host (using \'/proc/meminfo\') ,error,<org.apache.flink.runtime.util.Hardware: long getSizeOfPhysicalMemoryForLinux()>
Failed to load web based job submission extension.,debug,<org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint: java.util.Collection initializeWebSubmissionHandlers(java.util.concurrent.CompletableFuture)>
Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.,info,<org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint: java.util.Collection initializeWebSubmissionHandlers(java.util.concurrent.CompletableFuture)>
Web-based job submission is not enabled.,info,<org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint: java.util.Collection initializeWebSubmissionHandlers(java.util.concurrent.CompletableFuture)>
<*> <*> <*> @ <*>,trace,"<org.apache.flink.runtime.io.network.logger.NetworkActionsLogger: void traceRecover(java.lang.String,org.apache.flink.runtime.io.network.buffer.Buffer,java.lang.String,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo)>"
Registered new allocation id <*> for local state stores for job <*>.,debug,"<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: org.apache.flink.runtime.state.TaskLocalStateStore localStateStoreForSubtask(org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.jobgraph.JobVertexID,int)>"
Registered new local state store with configuration <*> for <*> - <*> - <*> under allocation id <*>.,debug,"<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: org.apache.flink.runtime.state.TaskLocalStateStore localStateStoreForSubtask(org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.jobgraph.JobVertexID,int)>"
Found existing local state store for <*> - <*> - <*> under allocation id <*>: <*>,debug,"<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: org.apache.flink.runtime.state.TaskLocalStateStore localStateStoreForSubtask(org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.jobgraph.JobVertexID,int)>"
Job <*> under leader id <*> reached a globally terminal state <*>.,debug,<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: void jobReachedGloballyTerminalState(org.apache.flink.runtime.scheduler.ExecutionGraphInfo)>
Checkpoint storage is set to \'<*>\',info,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage createJobManagerCheckpointStorage(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
Ignoring allocated slot report from job <*> because there is no active leader.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor$JobManagerHeartbeatListener: void lambda$reportPayload$2(org.apache.flink.runtime.jobmaster.AllocatedSlotReport)>
Shutting down cluster because someone retrieved the job result and the status is globally terminal.,info,<org.apache.flink.runtime.dispatcher.MiniDispatcher: void lambda$requestJobResult$1(org.apache.flink.runtime.jobmaster.JobResult)>
Copying from <*> to <*>.,debug,"<org.apache.flink.runtime.blob.FileSystemBlobStore: boolean put(java.io.File,java.lang.String)>"
Internal server error. Could not map error response to JSON.,error,"<org.apache.flink.runtime.rest.handler.util.HandlerUtils: java.util.concurrent.CompletableFuture sendErrorResponse(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,boolean,org.apache.flink.runtime.rest.messages.ErrorResponseBody,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpResponseStatus,java.util.Map)>"
"ReduceDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.ReduceDriver: void prepare()>
Could not instantiate metrics reporter <*>. Metrics might not be exposed/reported.,error,"<org.apache.flink.runtime.metrics.ReporterSetup: java.util.List setupReporters(java.util.Map,java.util.List)>"
Releasing view of subpartition <*> of <*>.,debug,<org.apache.flink.runtime.io.network.partition.PipelinedApproximateSubpartition: void releaseView()>
Transport type \'auto\': using EPOLL.,info,"<org.apache.flink.runtime.io.network.netty.NettyClient: void init(org.apache.flink.runtime.io.network.netty.NettyProtocol,org.apache.flink.runtime.io.network.netty.NettyBufferPool)>"
Transport type \'auto\': using NIO.,info,"<org.apache.flink.runtime.io.network.netty.NettyClient: void init(org.apache.flink.runtime.io.network.netty.NettyProtocol,org.apache.flink.runtime.io.network.netty.NettyBufferPool)>"
Successful initialization (took <*> ms).,info,"<org.apache.flink.runtime.io.network.netty.NettyClient: void init(org.apache.flink.runtime.io.network.netty.NettyProtocol,org.apache.flink.runtime.io.network.netty.NettyBufferPool)>"
Starting <*>.,info,<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void startCluster()>
Remove pending task manager <*>.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: java.util.Map removePendingTaskManager(org.apache.flink.runtime.resourcemanager.slotmanager.PendingTaskManagerId)>
"<*> <*> <*>, seq <*>, <*> @ <*>",trace,"<org.apache.flink.runtime.io.network.logger.NetworkActionsLogger: void traceInput(java.lang.String,org.apache.flink.runtime.io.network.buffer.Buffer,java.lang.String,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo,org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister,int)>"
Stopping DefaultLeaderRetrievalService.,info,<org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService: void stop()>
Cannot invoke VersionInfo.getVersion reflectively.,error,<org.apache.flink.runtime.util.EnvironmentInformation: java.lang.String getHadoopVersionString()>
java.security.auth.login.config,setProperty,<org.apache.flink.runtime.security.modules.JaasModule: void uninstall()>
java.security.auth.login.config,clearProperty,<org.apache.flink.runtime.security.modules.JaasModule: void uninstall()>
Successfully written local task state snapshot file <*> for checkpoint <*>.,debug,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void persistLocalStateMetadata(long,org.apache.flink.runtime.checkpoint.TaskStateSnapshot)>"
Key value state registered for job <*> under name <*>.,debug,"<org.apache.flink.runtime.scheduler.KvStateHandler: void notifyKvStateRegistered(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobgraph.JobVertexID,org.apache.flink.runtime.state.KeyGroupRange,java.lang.String,org.apache.flink.queryablestate.KvStateID,java.net.InetSocketAddress)>"
Declare new resource requirements for job <*>.<*>\trequired resources: <*><*>\tacquired resources: <*>,debug,<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: void declareResourceRequirements()>
<*> lost leadership,info,<org.apache.flink.runtime.webmonitor.WebMonitorEndpoint: void revokeLeadership()>
Restoring SplitEnumerator of source <*> from checkpoint.,info,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void resetToCheckpoint(long,byte[])>"
Releasing slot <*>.,info,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: void releaseSlots(java.lang.Iterable,java.lang.Throwable)>"
Releasing slot <*>.,info,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: void releaseSlots(java.lang.Iterable,java.lang.Throwable)>"
Ignoring error notification since the service has been stopped.,debug,<org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService$LeaderRetrievalFatalErrorHandler: void onFatalError(java.lang.Throwable)>
Canceling left-over deployments <*> on task executor <*>.,debug,"<org.apache.flink.runtime.jobmaster.JobMaster$1: void onUnknownDeploymentsOf(java.util.Collection,org.apache.flink.runtime.clusterframework.types.ResourceID)>"
Registration at <*> attempt <*> (timeout=<*>ms),debug,"<org.apache.flink.runtime.registration.RetryingRegistration: void register(org.apache.flink.runtime.rpc.RpcGateway,int,long)>"
Failed <*>,debug,"<org.apache.flink.runtime.scheduler.SharedSlot: org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot lambda$allocateNonExistentLogicalSlot$2(java.lang.String,org.apache.flink.runtime.jobmaster.SlotRequestId,java.lang.Throwable)>"
Fetching of JobDetails failed.,debug,"<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void lambda$fetchMetrics$0(org.apache.flink.runtime.messages.webmonitor.MultipleJobsDetails,java.lang.Throwable)>"
Closing <*>.,info,<org.apache.flink.runtime.leaderelection.DefaultMultipleComponentLeaderElectionService: void close()>
New partitioned file produced: <*>.,info,<org.apache.flink.runtime.io.network.partition.SortMergeResultPartition: void finish()>
"Allocated <*> MB for network buffer pool (number of memory segments: <*>, bytes per segment: <*>).",info,"<org.apache.flink.runtime.io.network.buffer.NetworkBufferPool: void <init>(int,int,java.time.Duration)>"
Starting to restore from state handle: <*>.,info,<org.apache.flink.runtime.state.heap.HeapRestoreOperation: java.lang.Void restore()>
Finished restoring from state handle: <*>.,info,<org.apache.flink.runtime.state.heap.HeapRestoreOperation: java.lang.Void restore()>
Error while reporting metrics,warn,<org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask: void run()>
Using InetAddress.getLoopbackAddress() immediately for connecting address,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findAddressUsingStrategy(org.apache.flink.runtime.net.ConnectionUtils$AddressDetectionState,java.net.InetSocketAddress,boolean)>"
Could not resolve local hostname to an IP address: <*>,warn,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findAddressUsingStrategy(org.apache.flink.runtime.net.ConnectionUtils$AddressDetectionState,java.net.InetSocketAddress,boolean)>"
Using InetAddress.getLocalHost() immediately for the connecting address,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findAddressUsingStrategy(org.apache.flink.runtime.net.ConnectionUtils$AddressDetectionState,java.net.InetSocketAddress,boolean)>"
Target address <*> and local address <*> share prefix - trying to connect.,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findAddressUsingStrategy(org.apache.flink.runtime.net.ConnectionUtils$AddressDetectionState,java.net.InetSocketAddress,boolean)>"
Trying to connect to <*> from local address <*> with timeout <*>,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findAddressUsingStrategy(org.apache.flink.runtime.net.ConnectionUtils$AddressDetectionState,java.net.InetSocketAddress,boolean)>"
Choosing InetAddress.getLocalHost() address as a heuristic.,debug,"<org.apache.flink.runtime.net.ConnectionUtils: java.net.InetAddress findAddressUsingStrategy(org.apache.flink.runtime.net.ConnectionUtils$AddressDetectionState,java.net.InetSocketAddress,boolean)>"
Could not delete the checkpoint stream file <*>.,warn,<org.apache.flink.runtime.state.filesystem.FsCheckpointMetadataOutputStream: org.apache.flink.runtime.state.filesystem.FsCompletedCheckpointStorageLocation closeAndFinalizeCheckpoint()>
"Cannot unregister metric, because the MetricRegistry has already been shut down.",warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void unregister(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Error while unregistering metric: <*>.,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void unregister(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Error while unregistering metric: <*>.,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void unregister(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Error while unregistering metric: <*>,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void unregister(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
TaskExecutorStateChangelogStoragesManager is already closed and cannot register a new StateChangelogStorage.,<init>,"<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: org.apache.flink.runtime.state.changelog.StateChangelogStorage stateChangelogStorageForJob(org.apache.flink.api.common.JobID,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
Registered new state changelog storage for job <*> : <*>.,debug,"<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: org.apache.flink.runtime.state.changelog.StateChangelogStorage stateChangelogStorageForJob(org.apache.flink.api.common.JobID,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
"Try to registered new state changelog storage for job <*>, but result is null.",info,"<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: org.apache.flink.runtime.state.changelog.StateChangelogStorage stateChangelogStorageForJob(org.apache.flink.api.common.JobID,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
Found existing state changelog storage for job <*>: <*>.,debug,"<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: org.apache.flink.runtime.state.changelog.StateChangelogStorage stateChangelogStorageForJob(org.apache.flink.api.common.JobID,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
Found a previously loaded NULL state changelog storage for job <*>.,debug,"<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: org.apache.flink.runtime.state.changelog.StateChangelogStorage stateChangelogStorageForJob(org.apache.flink.api.common.JobID,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup)>"
Error granting leadership to contender,warn,<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$GrantLeadershipCall: void run()>
Ignoring outdated TaskExecutorGateway connection for <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: org.apache.flink.runtime.registration.RegistrationResponse lambda$registerTaskExecutor$4(org.apache.flink.runtime.resourcemanager.TaskExecutorRegistration,java.util.concurrent.CompletableFuture,org.apache.flink.runtime.taskexecutor.TaskExecutorGateway,java.lang.Throwable)>"
Operator event for <*> - <*>,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture sendOperatorEventToTask(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.runtime.jobgraph.OperatorID,org.apache.flink.util.SerializedValue)>"
"Requesting new worker with resource spec <*>, current pending count: <*>.",info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: void requestNewWorker(org.apache.flink.runtime.resourcemanager.WorkerResourceSpec)>
Submitting job \'<*>\' (<*>).,info,<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture internalSubmitJob(org.apache.flink.runtime.jobgraph.JobGraph)>
Could not retrieve QueryServiceGateway.,debug,"<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void lambda$retrieveAndQueryMetrics$4(org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceGateway,java.lang.Throwable)>"
Released partition <*> produced by <*>.,debug,"<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: void releasePartition(org.apache.flink.runtime.io.network.partition.ResultPartitionID,java.lang.Throwable)>"
An error occurred in the <*> after the listener has been stopped.,debug,<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService$JobLeaderIdListener: void handleError(java.lang.Exception)>
"Sort-merge partition <*> initialized, num sort buffers: <*>, num write buffers: <*>.",info,<org.apache.flink.runtime.io.network.partition.SortMergeResultPartition: void setup()>
"Cancelled execution of snapshot future runnable. Cancellation produced the following exception, which is expected an can be ignored.",debug,<org.apache.flink.runtime.state.StateUtil: org.apache.flink.api.java.tuple.Tuple2 discardStateFuture(java.util.concurrent.Future)>
"Job is trying to leave terminal state , current, ",error,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: boolean transitionState(org.apache.flink.api.common.JobStatus,org.apache.flink.api.common.JobStatus,java.lang.Throwable)>"
Job <*> (<*>) switched from state <*> to <*>.,info,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: boolean transitionState(org.apache.flink.api.common.JobStatus,org.apache.flink.api.common.JobStatus,java.lang.Throwable)>"
"Cannot write record to fresh sort buffer, record is too large. Oversized record count: <*>",debug,<org.apache.flink.runtime.operators.GroupReduceCombineDriver: void sortAndCombineAndRetryWrite(java.lang.Object)>
Web frontend listening at <*>.,info,<org.apache.flink.runtime.webmonitor.WebMonitorEndpoint: void startInternal()>
Periodic checkpoint scheduling could not be stopped due to the CheckpointCoordinator being shutdown.,info,<org.apache.flink.runtime.scheduler.SchedulerBase: void stopCheckpointScheduler()>
Releasing slot <*> of registered TaskExecutor <*> failed. Discarding slot.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: void lambda$releaseSlots$2(org.apache.flink.runtime.jobmaster.slotpool.AllocatedSlot,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Error while registering signal handler,info,<org.apache.flink.runtime.util.SignalHandler: void register(org.slf4j.Logger)>
,info,<org.apache.flink.runtime.util.SignalHandler: void register(org.slf4j.Logger)>
Worker <*> could not be stopped.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void releaseResource(org.apache.flink.runtime.instance.InstanceID,java.lang.Exception)>"
Received request. URL:<*> Method:<*>,trace,"<org.apache.flink.runtime.rest.FileUploadHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)>"
Initializing multipart file upload.,trace,"<org.apache.flink.runtime.rest.FileUploadHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)>"
Received http content.,trace,"<org.apache.flink.runtime.rest.FileUploadHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)>"
Upload of file <*> into destination <*> complete.,trace,"<org.apache.flink.runtime.rest.FileUploadHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)>"
Upload of attribute <*> complete.,trace,"<org.apache.flink.runtime.rest.FileUploadHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)>"
Finalizing multipart file upload.,trace,"<org.apache.flink.runtime.rest.FileUploadHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)>"
"CrossDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.CrossDriver: void prepare()>
The available future is completed exceptionally.,error,<org.apache.flink.runtime.io.network.buffer.LocalBufferPool: org.apache.flink.core.memory.MemorySegment requestMemorySegmentBlocking(int)>
Running class loader shutdown hook: <*>.,debug,<org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager$ResolvedClassLoader: void runReleaseHooks()>
Failed to run release hook \'<*>\' for user code class loader.,warn,<org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager$ResolvedClassLoader: void runReleaseHooks()>
JobMasterService process for job <*> under leader id <*> has been terminated.,debug,"<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: void lambda$closeAsync$3(java.lang.Void,java.lang.Throwable)>"
Establishing Resource Manager connection in Task Executor failed,error,"<org.apache.flink.runtime.taskexecutor.TaskExecutor$ResourceManagerRegistrationListener: void lambda$onRegistrationSuccess$0(org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection,org.apache.flink.runtime.resourcemanager.ResourceManagerGateway,org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.entrypoint.ClusterInformation)>"
Write leader information: <*>.,debug,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void writeLeaderInformation(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Successfully wrote leader information: <*>.,debug,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void writeLeaderInformation(org.apache.flink.runtime.leaderelection.LeaderInformation)>
Memory logger terminated with exception,error,<org.apache.flink.runtime.taskmanager.MemoryLogger: void run()>
InputChannelRecoveredStateHandler#recover,traceRecover,<org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel: void onRecoveredStateBuffer(org.apache.flink.runtime.io.network.buffer.Buffer)>
logging,put,"<org.apache.flink.runtime.clusterframework.BootstrapTools: java.lang.String getTaskManagerShellCommand(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParameters,java.lang.String,java.lang.String,boolean,boolean,boolean,java.lang.Class,java.lang.String)>"
"TaskManager start command: , <*>, ",debug,"<org.apache.flink.runtime.clusterframework.BootstrapTools: java.lang.String getTaskManagerShellCommand(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParameters,java.lang.String,java.lang.String,boolean,boolean,boolean,java.lang.Class,java.lang.String)>"
The execution has no slot assigned. This indicates that the execution is no longer running.,debug,"<org.apache.flink.runtime.executiongraph.Execution: void notifyCheckpointOnComplete(long,long,long)>"
Ignoring invalid file size threshold value (<*>): <*> - using default value <*> instead.,warn,"<org.apache.flink.runtime.state.filesystem.FsStateBackend: void <init>(org.apache.flink.runtime.state.filesystem.FsStateBackend,org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader)>"
Start job leader service.,info,"<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService: void start(java.lang.String,org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.taskexecutor.JobLeaderListener)>"
Trying to retrieve checkpoint <*>.,info,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStoreUtils: org.apache.flink.runtime.checkpoint.CompletedCheckpoint retrieveCompletedCheckpoint(org.apache.flink.runtime.checkpoint.CheckpointStoreUtil,org.apache.flink.api.java.tuple.Tuple2)>"
The size of broadcast data <*> is larger than the expected maximum value <*> (\'<*>\' * <*>). Use <*> as the size of broadcast data to decide the parallelism.,info,<org.apache.flink.runtime.scheduler.adaptivebatch.DefaultVertexParallelismDecider: int calculateParallelism(java.util.List)>
"The size of broadcast data is <*>, the size of non-broadcast data is <*>, the initially decided parallelism is <*>, after normalize is <*>",debug,<org.apache.flink.runtime.scheduler.adaptivebatch.DefaultVertexParallelismDecider: int calculateParallelism(java.util.List)>
The initially normalized parallelism <*> is smaller than the normalized minimum parallelism <*>. Use <*> as the finally decided parallelism.,info,<org.apache.flink.runtime.scheduler.adaptivebatch.DefaultVertexParallelismDecider: int calculateParallelism(java.util.List)>
The initially normalized parallelism <*> is larger than the normalized maximum parallelism <*>. Use <*> as the finally decided parallelism.,info,<org.apache.flink.runtime.scheduler.adaptivebatch.DefaultVertexParallelismDecider: int calculateParallelism(java.util.List)>
"<*> requested write result, checkpoint <*>",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter$ChannelStateWriteResult getAndRemoveWriteResult(long)>
Socket connection closed,debug,<org.apache.flink.runtime.blob.BlobServerConnection: void run()>
Error while executing BLOB connection.,error,<org.apache.flink.runtime.blob.BlobServerConnection: void run()>
Removing registered reader after failure for subtask <*> of source <*>.,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$subtaskFailed$3(int)>
Failed to delete locally cached BLOB <*> at <*>,warn,"<org.apache.flink.runtime.blob.PermanentBlobCache: boolean deleteFile(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Confirm completed checkpoint <*>@<*> and last subsumed checkpoint <*> for <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture confirmCheckpoint(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,long,long,long)>"
"TaskManager received a checkpoint confirmation for unknown task , executionAttemptID, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture confirmCheckpoint(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,long,long,long)>"
Attempting to fail task externally <*> (<*>).,info,<org.apache.flink.runtime.taskmanager.Task: void failExternally(java.lang.Throwable)>
Exception while closing BLOB server connection socket.,debug,"<org.apache.flink.runtime.blob.BlobUtils: void closeSilently(java.net.Socket,org.slf4j.Logger)>"
Failed to transfer file from TaskExecutor <*>.,error,"<org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler: void lambda$respondToRequest$1(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.Void,java.lang.Throwable)>"
Failed to serialize accumulators for task.,warn,<org.apache.flink.runtime.accumulators.AccumulatorRegistry: org.apache.flink.runtime.accumulators.AccumulatorSnapshot getSnapshot()>
Could not read attribute <*>.,warn,<org.apache.flink.runtime.metrics.util.MetricUtils$AttributeGauge: java.lang.Object getValue()>
"Cannot parse report interval from config: , <*>,  - please use values like \' SECONDS\' or \' MILLISECONDS\'. Using default reporting interval., ",error,<org.apache.flink.runtime.metrics.MetricRegistryImpl: java.time.Duration getConfiguredIntervalOrDefault(org.apache.flink.runtime.metrics.ReporterSetup)>
"Built <*> new pipelined regions in <*> ms, total <*> pipelined regions currently.",info,<org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology: void generateNewPipelinedRegions(java.lang.Iterable)>
Remove job <*> from job leader monitoring.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService: void removeJob(org.apache.flink.api.common.JobID)>
Could not properly stop the LeaderRetrievalService for job <*>.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService: void removeJob(org.apache.flink.api.common.JobID)>
Fatal error occurred in ResourceManager.,error,<org.apache.flink.runtime.resourcemanager.ResourceManager: void onFatalError(java.lang.Throwable)>
Disposing savepoint <*>.,info,"<org.apache.flink.runtime.dispatcher.Dispatcher: org.apache.flink.runtime.messages.Acknowledge lambda$disposeSavepoint$8(java.lang.String,java.lang.ClassLoader)>"
Starting DefaultLeaderRetrievalService with <*>.,info,<org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService: void start(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalListener)>
ZNode \'<*>\' is already marked for deletion. Command is ignored.,debug,<org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore: void deleteIfExists(java.lang.String)>
Could not stop the leader retrieval service.,warn,"<org.apache.flink.runtime.util.LeaderRetrievalUtils: org.apache.flink.runtime.util.LeaderConnectionInfo retrieveLeaderConnectionInfo(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService,java.time.Duration)>"
Could not stop the leader retrieval service.,warn,"<org.apache.flink.runtime.util.LeaderRetrievalUtils: org.apache.flink.runtime.util.LeaderConnectionInfo retrieveLeaderConnectionInfo(org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService,java.time.Duration)>"
Incremented the completed number of checkpoints without incrementing the in progress checkpoints before.,warn,<org.apache.flink.runtime.checkpoint.CheckpointStatsCounts: boolean canDecrementOfInProgressCheckpointsNumber()>
Savepoint stored in <*>. Now cancelling <*>.,info,"<org.apache.flink.runtime.scheduler.adaptive.StateWithExecutionGraph: java.lang.String lambda$triggerSavepoint$2(boolean,org.apache.flink.runtime.checkpoint.CheckpointCoordinator,java.lang.String,java.lang.Throwable)>"
"Configuration: , <*>, ",info,"<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void runFlinkZkQuorumPeer(java.lang.String,int)>"
Running distributed ZooKeeper quorum peer (total peers: <*>).,info,"<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void runFlinkZkQuorumPeer(java.lang.String,int)>"
Running standalone ZooKeeper quorum peer.,info,"<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void runFlinkZkQuorumPeer(java.lang.String,int)>"
Shutting down Flink Mini Cluster,info,<org.apache.flink.runtime.minicluster.MiniCluster: java.util.concurrent.CompletableFuture closeAsync()>
Created BLOB server storage directory <*>,info,"<org.apache.flink.runtime.blob.BlobServer: void <init>(org.apache.flink.configuration.Configuration,org.apache.flink.util.Reference,org.apache.flink.runtime.blob.BlobStore)>"
Invalid value for maximum connections in BLOB server: <*>. Using default value of <*>,warn,"<org.apache.flink.runtime.blob.BlobServer: void <init>(org.apache.flink.configuration.Configuration,org.apache.flink.util.Reference,org.apache.flink.runtime.blob.BlobStore)>"
Invalid value for BLOB connection backlog: <*>. Using default value of <*>,warn,"<org.apache.flink.runtime.blob.BlobServer: void <init>(org.apache.flink.configuration.Configuration,org.apache.flink.util.Reference,org.apache.flink.runtime.blob.BlobStore)>"
Started BLOB server at <*>:<*> - max concurrent requests: <*> - max backlog: <*>,info,"<org.apache.flink.runtime.blob.BlobServer: void <init>(org.apache.flink.configuration.Configuration,org.apache.flink.util.Reference,org.apache.flink.runtime.blob.BlobStore)>"
Fatal error occurred while executing the TaskManager. Shutting it down...,error,<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: void onFatalError(java.lang.Throwable)>
Start fetching metrics.,debug,<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void fetchMetrics()>
Exception while fetching metrics.,debug,<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void fetchMetrics()>
Cancelling task code,debug,<org.apache.flink.runtime.operators.BatchTask: void cancel()>
Failed to trigger checkpoint for job <*> since <*>.,info,"<org.apache.flink.runtime.checkpoint.CheckpointFailureManager: void handleCheckpointException(org.apache.flink.runtime.checkpoint.PendingCheckpoint,org.apache.flink.runtime.checkpoint.CheckpointProperties,org.apache.flink.runtime.checkpoint.CheckpointException,org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.checkpoint.PendingCheckpointStats,org.apache.flink.runtime.checkpoint.CheckpointStatsTracker)>"
Failed to trigger or complete checkpoint <*> for job <*>. (<*> consecutive failed attempts so far),warn,"<org.apache.flink.runtime.checkpoint.CheckpointFailureManager: void handleCheckpointException(org.apache.flink.runtime.checkpoint.PendingCheckpoint,org.apache.flink.runtime.checkpoint.CheckpointProperties,org.apache.flink.runtime.checkpoint.CheckpointException,org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.checkpoint.PendingCheckpointStats,org.apache.flink.runtime.checkpoint.CheckpointStatsTracker)>"
Failed to flush the current sort buffer.,error,<org.apache.flink.runtime.io.network.partition.SortMergeResultPartition: void flush(int)>
"Trying to get execution vertices of an uninitialized job vertex , <*>, ",debug,<org.apache.flink.runtime.executiongraph.ExecutionJobVertex: org.apache.flink.runtime.executiongraph.ExecutionVertex[] getTaskVertices()>
Detected excess resources for job <*>: <*>,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker: void findExcessSlots()>
Concurrent canceling/failing of <*> while deployment was in progress.,debug,"<org.apache.flink.runtime.executiongraph.Execution: boolean switchTo(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState)>"
<*>,info,<org.apache.flink.runtime.iterative.task.IterationIntermediateTask: void run()>
<*>,info,<org.apache.flink.runtime.iterative.task.IterationIntermediateTask: void run()>
Received PUT call for BLOB of job <*>.,debug,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putBuffer(org.apache.flink.api.common.JobID,byte[],org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Could not delete the staging file <*> for job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putBuffer(org.apache.flink.api.common.JobID,byte[],org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putBuffer(org.apache.flink.api.common.JobID,byte[],org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.BlobServer: org.apache.flink.runtime.blob.BlobKey putBuffer(org.apache.flink.api.common.JobID,byte[],org.apache.flink.runtime.blob.BlobKey$BlobType)>"
Configured size for \'<*>\' is ignored. Total memory size for TaskManagers are dynamically decided in fine-grained resource management.,warn,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManagerFactory: void logIgnoreTotalMemory(org.apache.flink.configuration.ConfigOption)>
The Off-Heap Memory size (<*>) is derived the configured Total Flink Memory size (<*>) minus the configured JVM Heap Memory size (<*>). The default Off-Heap Memory size (<*>) is ignored.,info,"<org.apache.flink.runtime.util.config.memory.jobmanager.JobManagerFlinkMemoryUtils: org.apache.flink.configuration.MemorySize deriveOffHeapMemory(org.apache.flink.configuration.MemorySize,org.apache.flink.configuration.MemorySize,org.apache.flink.configuration.MemorySize)>"
Revoking leadership of <*>.,info,<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService: java.util.concurrent.CompletableFuture revokeLeadership()>
"GroupReduceDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.GroupReduceDriver: void prepare()>
Cannot create JSON plan for job,warn,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder: org.apache.flink.runtime.executiongraph.DefaultExecutionGraph buildGraph(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.configuration.Configuration,java.util.concurrent.ScheduledExecutorService,java.util.concurrent.Executor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.slf4j.Logger,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory$PartitionLocationConstraint,org.apache.flink.runtime.executiongraph.ExecutionDeploymentListener,org.apache.flink.runtime.executiongraph.ExecutionStateUpdateListener,long,org.apache.flink.runtime.executiongraph.VertexAttemptNumberStore,org.apache.flink.runtime.scheduler.VertexParallelismStore,java.util.function.Supplier,boolean)>"
Running initialization on master for job <*> (<*>).,info,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder: org.apache.flink.runtime.executiongraph.DefaultExecutionGraph buildGraph(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.configuration.Configuration,java.util.concurrent.ScheduledExecutorService,java.util.concurrent.Executor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.slf4j.Logger,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory$PartitionLocationConstraint,org.apache.flink.runtime.executiongraph.ExecutionDeploymentListener,org.apache.flink.runtime.executiongraph.ExecutionStateUpdateListener,long,org.apache.flink.runtime.executiongraph.VertexAttemptNumberStore,org.apache.flink.runtime.scheduler.VertexParallelismStore,java.util.function.Supplier,boolean)>"
Successfully ran initialization on master in <*> ms.,info,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder: org.apache.flink.runtime.executiongraph.DefaultExecutionGraph buildGraph(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.configuration.Configuration,java.util.concurrent.ScheduledExecutorService,java.util.concurrent.Executor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.slf4j.Logger,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory$PartitionLocationConstraint,org.apache.flink.runtime.executiongraph.ExecutionDeploymentListener,org.apache.flink.runtime.executiongraph.ExecutionStateUpdateListener,long,org.apache.flink.runtime.executiongraph.VertexAttemptNumberStore,org.apache.flink.runtime.scheduler.VertexParallelismStore,java.util.function.Supplier,boolean)>"
Adding <*> vertices from job graph <*> (<*>).,debug,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder: org.apache.flink.runtime.executiongraph.DefaultExecutionGraph buildGraph(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.configuration.Configuration,java.util.concurrent.ScheduledExecutorService,java.util.concurrent.Executor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.slf4j.Logger,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory$PartitionLocationConstraint,org.apache.flink.runtime.executiongraph.ExecutionDeploymentListener,org.apache.flink.runtime.executiongraph.ExecutionStateUpdateListener,long,org.apache.flink.runtime.executiongraph.VertexAttemptNumberStore,org.apache.flink.runtime.scheduler.VertexParallelismStore,java.util.function.Supplier,boolean)>"
Successfully created execution graph from job graph <*> (<*>).,debug,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder: org.apache.flink.runtime.executiongraph.DefaultExecutionGraph buildGraph(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.configuration.Configuration,java.util.concurrent.ScheduledExecutorService,java.util.concurrent.Executor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.slf4j.Logger,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory$PartitionLocationConstraint,org.apache.flink.runtime.executiongraph.ExecutionDeploymentListener,org.apache.flink.runtime.executiongraph.ExecutionStateUpdateListener,long,org.apache.flink.runtime.executiongraph.VertexAttemptNumberStore,org.apache.flink.runtime.scheduler.VertexParallelismStore,java.util.function.Supplier,boolean)>"
Skip setting up checkpointing for a job with dynamic graph.,warn,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder: org.apache.flink.runtime.executiongraph.DefaultExecutionGraph buildGraph(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.configuration.Configuration,java.util.concurrent.ScheduledExecutorService,java.util.concurrent.Executor,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CompletedCheckpointStore,org.apache.flink.runtime.checkpoint.CheckpointsCleaner,org.apache.flink.runtime.checkpoint.CheckpointIDCounter,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.slf4j.Logger,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory$PartitionLocationConstraint,org.apache.flink.runtime.executiongraph.ExecutionDeploymentListener,org.apache.flink.runtime.executiongraph.ExecutionStateUpdateListener,long,org.apache.flink.runtime.executiongraph.VertexAttemptNumberStore,org.apache.flink.runtime.scheduler.VertexParallelismStore,java.util.function.Supplier,boolean)>"
Shutting down TaskExecutorLocalStateStoresManager.,info,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: void shutdown()>
Could not delete local state directory <*>.,warn,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: void shutdown()>
Close ResourceManager connection <*>.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void closeResourceManagerConnection(java.lang.Exception)>
Close ResourceManager connection <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void closeResourceManagerConnection(java.lang.Exception)>
Terminating registration attempts towards ResourceManager <*>.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void closeResourceManagerConnection(java.lang.Exception)>
Terminating registration attempts towards ResourceManager <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void closeResourceManagerConnection(java.lang.Exception)>
Error while resetting handler.,debug,<org.apache.flink.runtime.rest.FileUploadHandler: void reset()>
"<*> adding output data, checkpoint <*>, channel: <*>, startSeqNum: <*>, num buffers: <*>",trace,"<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void addOutputData(long,org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo,int,org.apache.flink.runtime.io.network.buffer.Buffer[])>"
Initializing heap keyed state backend with stream factory.,info,"<org.apache.flink.runtime.state.heap.HeapKeyedStateBackend: void <init>(org.apache.flink.runtime.query.TaskKvStateRegistry,org.apache.flink.api.common.typeutils.TypeSerializer,java.lang.ClassLoader,org.apache.flink.api.common.ExecutionConfig,org.apache.flink.runtime.state.ttl.TtlTimeProvider,org.apache.flink.runtime.state.metrics.LatencyTrackingStateConfig,org.apache.flink.core.fs.CloseableRegistry,org.apache.flink.runtime.state.StreamCompressionDecorator,java.util.Map,java.util.Map,org.apache.flink.runtime.state.LocalRecoveryConfig,org.apache.flink.runtime.state.heap.HeapPriorityQueueSetFactory,org.apache.flink.runtime.state.heap.HeapSnapshotStrategy,org.apache.flink.runtime.state.SnapshotExecutionType,org.apache.flink.runtime.state.heap.StateTableFactory,org.apache.flink.runtime.state.heap.InternalKeyContext)>"
<*> (<*>) switched from <*> to <*>.,info,"<org.apache.flink.runtime.taskmanager.Task: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
<*> (<*>) switched from <*> to <*> due to CancelTaskException.,info,"<org.apache.flink.runtime.taskmanager.Task: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
<*> (<*>) switched from <*> to <*> due to CancelTaskException: <*>,debug,"<org.apache.flink.runtime.taskmanager.Task: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
<*> (<*>) switched from <*> to <*> with failure cause: <*>,warn,"<org.apache.flink.runtime.taskmanager.Task: boolean transitionState(org.apache.flink.runtime.execution.ExecutionState,org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
Encountered error while consuming partitions,error,"<org.apache.flink.runtime.io.network.netty.PartitionRequestQueue: void handleException(org.apache.flink.shaded.netty4.io.netty.channel.Channel,java.lang.Throwable)>"
Newer resource requirements found. Stop sending old requirements.,debug,<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclareResourceRequirementServiceConnectionManager: java.util.concurrent.CompletableFuture sendResourceRequirements(org.apache.flink.runtime.slots.ResourceRequirements)>
Stop sending resource requirements to ResourceManager because it is not connected.,debug,<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclareResourceRequirementServiceConnectionManager: java.util.concurrent.CompletableFuture sendResourceRequirements(org.apache.flink.runtime.slots.ResourceRequirements)>
<*> was granted leadership with leaderSessionID=<*>,info,<org.apache.flink.runtime.webmonitor.WebMonitorEndpoint: void grantLeadership(java.util.UUID)>
Starting scheduling with scheduling strategy <*>,info,<org.apache.flink.runtime.scheduler.DefaultScheduler: void startSchedulingInternal()>
"Error while processing , messageType,  message, ",warn,"<org.apache.flink.runtime.scheduler.ExecutionGraphHandler: void lambda$processCheckpointCoordinatorMessage$3(org.apache.flink.util.function.ThrowingConsumer,org.apache.flink.runtime.checkpoint.CheckpointCoordinator,java.lang.String)>"
"Could not allocate <*>. Max total resource limitation <<*>, <*>> is reached.",info,<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager: boolean allocateResource(org.apache.flink.runtime.resourcemanager.slotmanager.PendingTaskManager)>
Ignore result future forwarding because the leader <*> is no longer valid.,trace,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void lambda$forwardResultFuture$11(java.util.UUID,org.apache.flink.runtime.jobmaster.JobManagerRunnerResult,java.lang.Throwable)>"
Sorting buffer <*>.,debug,<org.apache.flink.runtime.operators.sort.SortingThread: void go()>
Sorted buffer <*>.,debug,<org.apache.flink.runtime.operators.sort.SortingThread: void go()>
Sorting thread done.,debug,<org.apache.flink.runtime.operators.sort.SortingThread: void go()>
No checkpoint found during restore.,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.util.OptionalLong restoreLatestCheckpointedStateInternal(java.util.Set,org.apache.flink.runtime.checkpoint.CheckpointCoordinator$OperatorCoordinatorRestoreBehavior,boolean,boolean,boolean)>"
Resetting the master hooks.,debug,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.util.OptionalLong restoreLatestCheckpointedStateInternal(java.util.Set,org.apache.flink.runtime.checkpoint.CheckpointCoordinator$OperatorCoordinatorRestoreBehavior,boolean,boolean,boolean)>"
,reset,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.util.OptionalLong restoreLatestCheckpointedStateInternal(java.util.Set,org.apache.flink.runtime.checkpoint.CheckpointCoordinator$OperatorCoordinatorRestoreBehavior,boolean,boolean,boolean)>"
Resetting the Operator Coordinators to an empty state.,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.util.OptionalLong restoreLatestCheckpointedStateInternal(java.util.Set,org.apache.flink.runtime.checkpoint.CheckpointCoordinator$OperatorCoordinatorRestoreBehavior,boolean,boolean,boolean)>"
Restoring job <*> from <*>.,info,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.util.OptionalLong restoreLatestCheckpointedStateInternal(java.util.Set,org.apache.flink.runtime.checkpoint.CheckpointCoordinator$OperatorCoordinatorRestoreBehavior,boolean,boolean,boolean)>"
"The total number of slots exceeds the max limitation <*>, releasing the excess task executor.",info,"<org.apache.flink.runtime.resourcemanager.slotmanager.TaskExecutorManager: boolean registerTaskManager(org.apache.flink.runtime.resourcemanager.registration.TaskExecutorConnection,org.apache.flink.runtime.taskexecutor.SlotReport,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Ignoring the request to fail job because the job is already failing. The ignored failure cause is,debug,<org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext: void failJob(java.lang.Throwable)>
Could not add job <*> to job leader id service.,error,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture registerJobMaster(org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.String,org.apache.flink.api.common.JobID,org.apache.flink.api.common.time.Time)>"
Registering job manager <*>@<*> for job <*>.,info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture registerJobMaster(org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.String,org.apache.flink.api.common.JobID,org.apache.flink.api.common.time.Time)>"
Could not obtain the job leader id future to verify the correct job leader.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.concurrent.CompletableFuture registerJobMaster(org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.String,org.apache.flink.api.common.JobID,org.apache.flink.api.common.time.Time)>"
Closing TaskExecutor connection <*> because: <*>,info,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.Optional closeTaskManagerConnection(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.Exception)>"
No open TaskExecutor connection <*>. Ignoring close TaskExecutor connection. Closing reason was: <*>,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: java.util.Optional closeTaskManagerConnection(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.Exception)>"
<*>: Requesting LOCAL subpartition <*> of partition <*>. <*>,debug,<org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel: void requestSubpartition()>
Found reporter factory <*> at <*> ,debug,<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Map loadAvailableReporterFactories(org.apache.flink.core.plugin.PluginManager)>
Multiple implementations of the same reporter were found in \'lib\' and/or \'plugins\' directories for <*>. It is recommended to remove redundant reporter JARs to resolve used versions\' ambiguity.,warn,<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Map loadAvailableReporterFactories(org.apache.flink.core.plugin.PluginManager)>
Error while loading reporter factory.,warn,<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Map loadAvailableReporterFactories(org.apache.flink.core.plugin.PluginManager)>
Retrying registration towards <*> was cancelled.,debug,"<org.apache.flink.runtime.registration.RegisteredRpcConnection: void lambda$createNewRegistration$0(org.apache.flink.runtime.registration.RetryingRegistration$RetryingRegistrationResult,java.lang.Throwable)>"
Register handler <*> under <*>@<*>.,debug,"<org.apache.flink.runtime.rest.RestServerEndpoint: void registerHandler(org.apache.flink.runtime.rest.handler.router.Router,org.apache.flink.api.java.tuple.Tuple2,org.slf4j.Logger)>"
Register handler <*> under <*>@<*>.,debug,"<org.apache.flink.runtime.rest.RestServerEndpoint: void registerHandler(org.apache.flink.runtime.rest.handler.router.Router,org.apache.flink.api.java.tuple.Tuple2,org.slf4j.Logger)>"
Final Master Memory configuration:,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
  Total Process Memory: <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
    Total Flink Memory: <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
      JVM Heap:         <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
      Off-heap:         <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
    JVM Metaspace:      <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
    JVM Overhead:       <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logMasterConfiguration(org.apache.flink.runtime.jobmanager.JobManagerProcessSpec)>
Stopping the JobMaster for job \'<*>\' (<*>).,info,<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture onStop()>
Freeing inactive slots for job <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void freeInactiveSlots(org.apache.flink.api.common.JobID,org.apache.flink.api.common.time.Time)>"
"Delimiter for reporter index <*> not found, returning global delimiter.",warn,<org.apache.flink.runtime.metrics.MetricRegistryImpl: char getDelimiter(int)>
Shutdown of MiniCluster failed.,warn,"<org.apache.flink.runtime.minicluster.MiniClusterJobClient: void lambda$shutDownCluster$4(java.lang.Void,java.lang.Throwable)>"
Maximum number of open file descriptors is <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: void main(java.lang.String[])>
Cannot determine the maximum number of open file descriptors,info,<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: void main(java.lang.String[])>
The configuration <*> has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.,debug,"<org.apache.flink.runtime.state.CheckpointStorageLoader: java.util.Optional fromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
Loading state backend via factory \'<*>\',info,"<org.apache.flink.runtime.state.CheckpointStorageLoader: java.util.Optional fromConfig(org.apache.flink.configuration.ReadableConfig,java.lang.ClassLoader,org.slf4j.Logger)>"
Release TaskExecutor <*> because it exceeded the idle timeout.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.TaskExecutorManager: void releaseIdleTaskExecutor(org.apache.flink.runtime.instance.InstanceID)>
New resources are available. Restarting job to scale up.,info,<org.apache.flink.runtime.scheduler.adaptive.Executing: void notifyNewResourcesAvailable()>
Closing <*>,info,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void close()>
"NoOpDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.NoOpDriver: void prepare()>
Thread \'<*>\' produced an uncaught exception. Failing the job.,error,"<org.apache.flink.runtime.source.coordinator.SourceCoordinatorProvider$CoordinatorExecutorThreadFactory: void lambda$new$0(org.apache.flink.runtime.operators.coordination.OperatorCoordinator$Context,java.lang.Thread,java.lang.Throwable)>"
Stop-with-savepoint transitioned from <*> to <*> on savepoint creation handling for job <*>.,debug,<org.apache.flink.runtime.scheduler.stopwithsavepoint.StopWithSavepointTerminationHandlerImpl: void handleSavepointCreationSuccess(org.apache.flink.runtime.checkpoint.CompletedCheckpoint)>
"Failed requesting worker with resource spec <*>, current pending count: <*>",warn,"<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: java.lang.Object lambda$requestNewWorker$1(org.apache.flink.runtime.resourcemanager.WorkerResourceSpec,org.apache.flink.runtime.clusterframework.types.ResourceIDRetrievable,java.lang.Throwable)>"
Requested worker <*> with resource spec <*>.,info,"<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: java.lang.Object lambda$requestNewWorker$1(org.apache.flink.runtime.resourcemanager.WorkerResourceSpec,org.apache.flink.runtime.clusterframework.types.ResourceIDRetrievable,java.lang.Throwable)>"
Request a <*>,debug,<org.apache.flink.runtime.scheduler.SharedSlot: java.util.concurrent.CompletableFuture allocateNonExistentLogicalSlot(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID)>
Matched pending request <*> with slot <*>.,debug,<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: void newSlotsAreAvailable(java.util.Collection)>
"Batch job does not support local recovery. Falling back to use , <*>, ",warn,"<org.apache.flink.runtime.util.SlotSelectionStrategyUtils: org.apache.flink.runtime.jobmaster.slotpool.SlotSelectionStrategy selectSlotSelectionStrategy(org.apache.flink.runtime.jobgraph.JobType,org.apache.flink.configuration.Configuration)>"
"close, dropping checkpoints <*>",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl: void close()>
The job <*> is already marked as clean. No action required.,debug,<org.apache.flink.runtime.highavailability.AbstractThreadsafeJobResultStore: void markResultAsClean(org.apache.flink.api.common.JobID)>
Embedded leader election service encountered a fatal error. Shutting down service.,error,<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService: void fatalError(java.lang.Throwable)>
"Buffer size recalculation: gateIndex=<*>, currentSize=<*>, newSize=<*>, instantThroughput=<*>, desiredBufferSize=<*>, buffersInUse=<*>, estimatedTimeToConsumeBuffers=<*>, announceNewSize=<*>",debug,"<org.apache.flink.runtime.throughput.BufferDebloater: java.util.OptionalInt recalculateBufferSize(long,int)>"
Execution rejected during shutdown,debug,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.lang.Object lambda$startTriggeringCheckpoint$8(java.lang.Throwable)>
Error encountered during shutdown,warn,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: java.lang.Object lambda$startTriggeringCheckpoint$8(java.lang.Throwable)>
Config option <*> will be ignored in standalone mode.,warn,<org.apache.flink.runtime.resourcemanager.StandaloneResourceManagerFactory: org.apache.flink.configuration.Configuration getConfigurationWithoutMaxSlotNumberIfSet(org.apache.flink.configuration.Configuration)>
Shut down complete.,info,"<org.apache.flink.runtime.rest.RestServerEndpoint: void lambda$closeAsync$1(java.lang.Void,java.lang.Throwable)>"
Could not cleanup uploaded files.,warn,<org.apache.flink.runtime.rest.handler.AbstractHandler: void cleanupFileUploads(org.apache.flink.runtime.rest.handler.FileUploads)>
Completing the result for job <*>.,debug,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void onJobCompletion(org.apache.flink.runtime.jobmaster.JobManagerRunnerResult,java.lang.Throwable)>"
Release slot with slot request id <*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: void releaseSlot(org.apache.flink.runtime.jobmaster.SlotRequestId,java.lang.Throwable)>"
Could not find slot which has fulfilled slot request <*>. Ignoring the release operation.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: void releaseSlot(org.apache.flink.runtime.jobmaster.SlotRequestId,java.lang.Throwable)>"
Cleanup for the job \'<*>\' has finished. Job has been marked as clean.,debug,<org.apache.flink.runtime.dispatcher.Dispatcher: void markJobAsClean(org.apache.flink.api.common.JobID)>
Could not properly mark job <*> result as clean.,warn,<org.apache.flink.runtime.dispatcher.Dispatcher: void markJobAsClean(org.apache.flink.api.common.JobID)>
Add pending slot with allocationId <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void addPendingSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.api.common.JobID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Starting DefaultLeaderElectionService with <*>.,info,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void start(org.apache.flink.runtime.leaderelection.LeaderContender)>
Request new allocated slot with slot request id <*> and resource profile <*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: java.util.concurrent.CompletableFuture requestNewAllocatedSlot(org.apache.flink.runtime.jobmaster.SlotRequestId,org.apache.flink.runtime.clusterframework.types.ResourceProfile,java.util.Collection,org.apache.flink.api.common.time.Time)>"
Stopping TaskExecutor <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture onStop()>
"Checkpointing is not enabled for this job (, <*>, )., ",<init>,<org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler: org.apache.flink.runtime.rest.messages.checkpoints.CheckpointConfigInfo createCheckpointConfigInfo(org.apache.flink.runtime.executiongraph.AccessExecutionGraph)>
No allocation files to load.,debug,<org.apache.flink.runtime.taskexecutor.slot.FileSlotAllocationSnapshotPersistenceService: java.util.Collection loadAllocationSnapshots()>
Cannot read the local allocations state file <*>. Deleting it now.,debug,<org.apache.flink.runtime.taskexecutor.slot.FileSlotAllocationSnapshotPersistenceService: java.util.Collection loadAllocationSnapshots()>
"Checkpoint <*> stats for <*>: size=<*>Kb, duration=<*>ms, sync part=<*>ms, async part=<*>ms",trace,"<org.apache.flink.runtime.checkpoint.PendingCheckpoint: org.apache.flink.runtime.checkpoint.PendingCheckpoint$TaskAcknowledgeResult acknowledgeTask(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.runtime.checkpoint.TaskStateSnapshot,org.apache.flink.runtime.checkpoint.CheckpointMetrics)>"
Stopping DefaultLeaderElectionService.,info,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void stop()>
Using directory <*> for file uploads.,info,"<org.apache.flink.runtime.rest.RestServerEndpoint: void checkAndCreateUploadDir(java.nio.file.Path,org.slf4j.Logger)>"
Created directory <*> for file uploads.,info,"<org.apache.flink.runtime.rest.RestServerEndpoint: void checkAndCreateUploadDir(java.nio.file.Path,org.slf4j.Logger)>"
Upload directory <*> cannot be created or is not writable.,warn,"<org.apache.flink.runtime.rest.RestServerEndpoint: void checkAndCreateUploadDir(java.nio.file.Path,org.slf4j.Logger)>"
Uncaught Exception in Source Coordinator Executor,error,"<org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext: java.lang.Object callInCoordinatorThread(java.util.concurrent.Callable,java.lang.String)>"
Failed to serialize counter.,debug,"<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpSerializer: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult serialize(java.util.Map,java.util.Map,java.util.Map,java.util.Map)>"
Failed to serialize gauge.,debug,"<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpSerializer: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult serialize(java.util.Map,java.util.Map,java.util.Map,java.util.Map)>"
Failed to serialize histogram.,debug,"<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpSerializer: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult serialize(java.util.Map,java.util.Map,java.util.Map,java.util.Map)>"
Failed to serialize meter.,debug,"<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpSerializer: org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult serialize(java.util.Map,java.util.Map,java.util.Map,java.util.Map)>"
Load file from TaskManager <*>.,debug,<org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler: java.util.concurrent.CompletableFuture loadTaskManagerFile(org.apache.flink.api.java.tuple.Tuple2)>
Getting user code class loader for task <*> at library cache manager took <*> milliseconds,debug,<org.apache.flink.runtime.taskmanager.Task: org.apache.flink.util.UserCodeClassLoader createUserCodeClassloader()>
"Trying to , <*>, ",debug,"<org.apache.flink.runtime.net.ConnectionUtils: boolean tryToConnect(java.net.InetAddress,java.net.SocketAddress,int,boolean)>"
"Failed to , <*>,  due to: , <*>, ",debug,"<org.apache.flink.runtime.net.ConnectionUtils: boolean tryToConnect(java.net.InetAddress,java.net.SocketAddress,int,boolean)>"
"Failed to , <*>,  due to: , <*>, ",info,"<org.apache.flink.runtime.net.ConnectionUtils: boolean tryToConnect(java.net.InetAddress,java.net.SocketAddress,int,boolean)>"
Marking checkpoint <*> as aborted for source <*>.,info,<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$notifyCheckpointAborted$8(long)>
Periodic checkpoint scheduling could not be started due to the CheckpointCoordinator being shutdown.,info,<org.apache.flink.runtime.scheduler.SchedulerBase: void startCheckpointScheduler()>
"Ignoring slot allocation update from task manager <*> for allocation <*> and job <*>, because the allocation was already completed or cancelled.",debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: java.lang.Object lambda$allocateSlot$0(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,java.util.concurrent.CompletableFuture,java.util.concurrent.CompletableFuture,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
The slot <*> has been removed before. Ignore the future.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: java.lang.Object lambda$allocateSlot$0(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,java.util.concurrent.CompletableFuture,java.util.concurrent.CompletableFuture,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Completed allocation of allocation <*> for job <*>.,trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: java.lang.Object lambda$allocateSlot$0(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,java.util.concurrent.CompletableFuture,java.util.concurrent.CompletableFuture,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Should not get this exception.,error,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: java.lang.Object lambda$allocateSlot$0(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,java.util.concurrent.CompletableFuture,java.util.concurrent.CompletableFuture,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
Slot allocation for allocation <*> for job <*> failed.,warn,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: java.lang.Object lambda$allocateSlot$0(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,java.util.concurrent.CompletableFuture,java.util.concurrent.CompletableFuture,org.apache.flink.runtime.clusterframework.types.ResourceProfile,org.apache.flink.runtime.messages.Acknowledge,java.lang.Throwable)>"
An error occurred while writing checkpoint <*> to the underlying metadata store. Flink was not able to determine whether the metadata was successfully persisted. The corresponding state located at \'<*>\' won\'t be discarded and needs to be cleaned up manually.,warn,"<org.apache.flink.runtime.checkpoint.CheckpointCoordinator: org.apache.flink.runtime.checkpoint.CompletedCheckpoint addCompletedCheckpointToStoreAndSubsumeOldest(long,org.apache.flink.runtime.checkpoint.CompletedCheckpoint,java.util.List)>"
Triggering a manual checkpoint for job <*>.,info,<org.apache.flink.runtime.scheduler.SchedulerBase: java.util.concurrent.CompletableFuture triggerCheckpoint()>
RemoteInputChannel#getNextBuffer,traceInput,<org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel: java.util.Optional getNextBuffer()>
Release shared slot (<*>),debug,<org.apache.flink.runtime.scheduler.adaptive.allocator.SharedSlot: void release(java.lang.Throwable)>
Discarding the results produced by task execution <*>.,info,<org.apache.flink.runtime.executiongraph.Execution: void sendReleaseIntermediateResultPartitionsRpcCall()>
Failed to deserialize counter.,debug,<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpDeserializer: java.util.List deserialize(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Failed to deserialize gauge.,debug,<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpDeserializer: java.util.List deserialize(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Failed to deserialize meter.,debug,<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpDeserializer: java.util.List deserialize(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Failed to deserialize histogram.,debug,<org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricDumpDeserializer: java.util.List deserialize(org.apache.flink.runtime.metrics.dump.MetricDumpSerialization$MetricSerializationResult)>
Encountered fatal error <*> - terminating the JVM,error,<org.apache.flink.runtime.taskmanager.Task: java.lang.Throwable preProcessException(java.lang.Throwable)>
"Failed to release user code class loader for , <*>, ",warn,<org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager$ResolvedClassLoader: void releaseClassLoader()>
 Preconfiguration: ,info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" Starting , componentName,  (Version: , <*>, , Scala: , <*>, , Rev:, <*>, , Date:, <*>, ), ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" OS current user: , <*>, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" Current Hadoop/Kerberos user: , <*>, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" JVM: , <*>, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" Arch: , <*>, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" Maximum heap size: , maxHeapMegabytes,  MiBytes, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" JAVA_HOME: , <*>_, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" Hadoop version: , <*>, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
 No Hadoop Dependency available,info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
 JVM Options: (none),info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
 JVM Options:,info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
"    , s_, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
 Program Arguments: (none),info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
 Program Arguments:,info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
    ****** (sensitive information),info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
"    , s_, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
" Classpath: , <*>, ",info,"<org.apache.flink.runtime.util.EnvironmentInformation: void logEnvironmentInfo(org.slf4j.Logger,java.lang.String,java.lang.String[])>"
Offer reserved slots to the leader of job <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void internalOfferSlotsToJobManager(org.apache.flink.runtime.taskexecutor.JobTable$Connection)>
There are no unassigned slots for the job <*>.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void internalOfferSlotsToJobManager(org.apache.flink.runtime.taskexecutor.JobTable$Connection)>
"Initializing <*>: Storage directory <*>, expiration time <*>, maximum cache size <*> bytes.",info,"<org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore: void <init>(java.io.File,org.apache.flink.api.common.time.Time,int,long,org.apache.flink.util.concurrent.ScheduledExecutor,org.apache.flink.shaded.guava30.com.google.common.base.Ticker)>"
Enabled external resources: <*>,info,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map getExternalResourceConfigurationKeys(org.apache.flink.configuration.Configuration,java.lang.String)>"
Could not find valid <*> for <*>. Will ignore that resource.,warn,"<org.apache.flink.runtime.externalresource.ExternalResourceUtils: java.util.Map getExternalResourceConfigurationKeys(org.apache.flink.configuration.Configuration,java.lang.String)>"
Block Resettable Iterator opened.,debug,<org.apache.flink.runtime.operators.resettable.AbstractBlockResettableIterator: void open()>
Failed to initialize system resource metrics because of missing class definitions. Did you forget to explicitly add the oshi-core optional dependency?,warn,"<org.apache.flink.runtime.metrics.util.SystemResourcesMetricsInitializer: void instantiateSystemMetrics(org.apache.flink.metrics.MetricGroup,org.apache.flink.api.common.time.Time)>"
Executing discard procedure for <*>.,trace,<org.apache.flink.runtime.checkpoint.CompletedCheckpoint$CompletedCheckpointDiscardObject: void discard()>
The execution has no slot assigned. This indicates that the execution is no longer running.,debug,"<org.apache.flink.runtime.executiongraph.Execution: void notifyCheckpointAborted(long,long,long)>"
Leadership runner for job <*> has been terminated.,debug,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void lambda$closeAsync$1(java.lang.Void,java.lang.Throwable)>"
Rejected registration at job manager <*> for job <*>.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection: void lambda$onRegistrationRejection$2(org.apache.flink.runtime.jobmaster.JMTMRegistrationRejection)>
Lookup key-value state for job <*> with registration name <*>.,debug,"<org.apache.flink.runtime.scheduler.KvStateHandler: org.apache.flink.runtime.query.KvStateLocation requestKvStateLocation(org.apache.flink.api.common.JobID,java.lang.String)>"
Request of key-value state location for unknown job <*> received.,debug,"<org.apache.flink.runtime.scheduler.KvStateHandler: org.apache.flink.runtime.query.KvStateLocation requestKvStateLocation(org.apache.flink.api.common.JobID,java.lang.String)>"
<*>: Received release notification for subpartition <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartition: void onConsumedSubpartition(int)>
Could not list local state directory <*>. This entails that some orphaned local state might not be cleaned up properly.,debug,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: java.util.Collection findStoredAllocations()>
Could not list local state directory <*>. This entails that some orphaned local state might not be cleaned up properly.,info,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: java.util.Collection findStoredAllocations()>
"complete input, output completed: <*>",debug,<org.apache.flink.runtime.checkpoint.channel.ChannelStateCheckpointWriter: void completeInput()>
"Failed to locally delete BLOB , key,  at , <*>, ",warn,"<org.apache.flink.runtime.blob.BlobServer: boolean deleteInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.TransientBlobKey)>"
Release shared slot externally (<*>),debug,<org.apache.flink.runtime.scheduler.adaptive.allocator.SharedSlot: void tryReleaseExternally()>
BLOB server stopped working. Shutting down,error,<org.apache.flink.runtime.blob.BlobServer: void run()>
Could not properly close the BlobServer.,error,<org.apache.flink.runtime.blob.BlobServer: void run()>
Discarding local task state snapshot of checkpoint <*> for subtask (<*> - <*> - <*>).,trace,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void discardLocalStateForCheckpoint(long,java.util.Optional)>"
Discarding local task state snapshot <*> of checkpoint <*> for subtask (<*> - <*> - <*>).,debug,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void discardLocalStateForCheckpoint(long,java.util.Optional)>"
Deleting local state directory <*> of checkpoint <*> for subtask (<*> - <*> - <*>).,debug,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void discardLocalStateForCheckpoint(long,java.util.Optional)>"
Exception while deleting local state directory of checkpoint <*> in subtask (<*> - <*> - <*>).,warn,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void discardLocalStateForCheckpoint(long,java.util.Optional)>"
,checkAndDeleteCorruptedBlobs,<org.apache.flink.runtime.blob.AbstractBlobCache: void checkStoredBlobsForCorruption()>
Asynchronous savepoint performed on empty keyed state at <*>. Returning null.,debug,"<org.apache.flink.runtime.state.SavepointSnapshotStrategy: org.apache.flink.runtime.state.SnapshotStrategy$SnapshotResultSupplier asyncSnapshot(org.apache.flink.runtime.state.FullSnapshotResources,long,long,org.apache.flink.runtime.state.CheckpointStreamFactory,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
<*> was granted leadership with leader id <*>. Creating new <*>.,info,<org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner: void lambda$grantLeadership$0(java.util.UUID)>
"Getting Broadcast Variable (, <*>, ) - First access, materializing., ",debug,"<org.apache.flink.runtime.broadcast.BroadcastVariableMaterialization: void materializeVariable(org.apache.flink.runtime.io.network.api.reader.MutableReader,org.apache.flink.api.common.typeutils.TypeSerializerFactory,org.apache.flink.runtime.operators.BatchTask)>"
"Materialization of Broadcast Variable (, <*>, ) finished., ",debug,"<org.apache.flink.runtime.broadcast.BroadcastVariableMaterialization: void materializeVariable(org.apache.flink.runtime.io.network.api.reader.MutableReader,org.apache.flink.api.common.typeutils.TypeSerializerFactory,org.apache.flink.runtime.operators.BatchTask)>"
"Getting Broadcast Variable (, <*>, ) - shared access., ",debug,"<org.apache.flink.runtime.broadcast.BroadcastVariableMaterialization: void materializeVariable(org.apache.flink.runtime.io.network.api.reader.MutableReader,org.apache.flink.api.common.typeutils.TypeSerializerFactory,org.apache.flink.runtime.operators.BatchTask)>"
<*>: Creating read view for subpartition <*> of partition <*>.,debug,<org.apache.flink.runtime.io.network.partition.PipelinedApproximateSubpartition: org.apache.flink.runtime.io.network.partition.PipelinedSubpartitionView createReadView(org.apache.flink.runtime.io.network.partition.BufferAvailabilityListener)>
"Sending out cancel request, to remove task execution from TaskManager.",debug,"<org.apache.flink.runtime.executiongraph.Execution: void maybeReleasePartitionsAndSendCancelRpcCall(org.apache.flink.runtime.execution.ExecutionState,boolean,boolean)>"
Error triggering cancel call while marking task <*> as failed.,error,"<org.apache.flink.runtime.executiongraph.Execution: void maybeReleasePartitionsAndSendCancelRpcCall(org.apache.flink.runtime.execution.ExecutionState,boolean,boolean)>"
Releasing local state under allocation id <*>.,debug,<org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager: void releaseLocalStateForAllocationId(org.apache.flink.runtime.clusterframework.types.AllocationID)>
Received heartbeat from <*>.,debug,"<org.apache.flink.runtime.heartbeat.HeartbeatManagerImpl: java.util.concurrent.CompletableFuture receiveHeartbeat(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.Object)>"
Could not fulfill resource requirements of job <*>. Free slots: <*>,warn,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: org.apache.flink.runtime.util.ResourceCounter tryFulfillRequirementsWithPendingSlots(org.apache.flink.api.common.JobID,java.util.Collection,org.apache.flink.runtime.util.ResourceCounter)>"
"Messages have a max timeout of , <*>, ",debug,"<org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration: org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration fromConfiguration(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec,java.lang.String,java.io.File)>"
Invalid format for parameter <*>. Set the timeout to be infinite.,warn,"<org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration: org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration fromConfiguration(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec,java.lang.String,java.io.File)>"
Starting the network environment and its components.,info,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: int start()>
Starting network connection manager,debug,<org.apache.flink.runtime.io.network.NettyShuffleEnvironment: int start()>
Processing cluster partition report from task executor <*>: <*>.,debug,"<org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl: void processTaskExecutorClusterPartitionReport(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.taskexecutor.partition.ClusterPartitionReport)>"
"AllGroupReduceDriver object reuse: , <*>_, ., ",debug,<org.apache.flink.runtime.operators.AllGroupReduceDriver: void prepare()>
Parallelism of JobVertex: <*> (<*>) is decided to be <*> according to forward group\'s parallelism.,info,<org.apache.flink.runtime.scheduler.adaptivebatch.AdaptiveBatchScheduler: void maybeSetParallelism(org.apache.flink.runtime.executiongraph.ExecutionJobVertex)>
Parallelism of JobVertex: <*> (<*>) is decided to be <*>.,info,<org.apache.flink.runtime.scheduler.adaptivebatch.AdaptiveBatchScheduler: void maybeSetParallelism(org.apache.flink.runtime.executiongraph.ExecutionJobVertex)>
"Error running ZooKeeper quorum peer: , <*>, ",error,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void main(java.lang.String[])>
unable to fail write channel state writer,warn,<org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcherImpl: void fail(java.lang.Throwable)>
Error while discarding operator states.,warn,<org.apache.flink.runtime.checkpoint.OperatorSubtaskState: void discardState()>
Freeing slot <*>.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: void freeSlot(org.apache.flink.runtime.clusterframework.types.AllocationID)>
Try to free unknown slot <*>.,warn,<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: void freeSlot(org.apache.flink.runtime.clusterframework.types.AllocationID)>
"Rejecting the task submission because the job manager leader id , jobMasterId,  does not match the expected job manager leader id , <*>, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture submitTask(org.apache.flink.runtime.deployment.TaskDeploymentDescriptor,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.api.common.time.Time)>"
"No task slot allocated for job ID , <*>,  and allocation ID , <*>, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture submitTask(org.apache.flink.runtime.deployment.TaskDeploymentDescriptor,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.api.common.time.Time)>"
,<init>,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture submitTask(org.apache.flink.runtime.deployment.TaskDeploymentDescriptor,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.api.common.time.Time)>"
"Received task <*> (<*>), deploy into slot with allocation id <*>.",info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture submitTask(org.apache.flink.runtime.deployment.TaskDeploymentDescriptor,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.api.common.time.Time)>"
"TaskManager already contains a task for id , <*>, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture submitTask(org.apache.flink.runtime.deployment.TaskDeploymentDescriptor,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.api.common.time.Time)>"
Combining buffer <*>.,debug,"<org.apache.flink.runtime.operators.sort.CombiningSpillingBehaviour: void spillBuffer(org.apache.flink.runtime.operators.sort.CircularElement,org.apache.flink.runtime.io.disk.iomanager.ChannelWriterOutputView,org.apache.flink.runtime.operators.sort.LargeRecordHandler)>"
Combined and spilled buffer <*>.,debug,"<org.apache.flink.runtime.operators.sort.CombiningSpillingBehaviour: void spillBuffer(org.apache.flink.runtime.operators.sort.CircularElement,org.apache.flink.runtime.io.disk.iomanager.ChannelWriterOutputView,org.apache.flink.runtime.operators.sort.LargeRecordHandler)>"
Starting TaskManager with ResourceID: <*>,info,"<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: org.apache.flink.runtime.taskexecutor.TaskExecutor startTaskManager(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.heartbeat.HeartbeatServices,org.apache.flink.runtime.metrics.MetricRegistry,org.apache.flink.runtime.blob.TaskExecutorBlobService,boolean,org.apache.flink.runtime.externalresource.ExternalResourceInfoProvider,org.apache.flink.runtime.entrypoint.WorkingDirectory,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Encountered obsolete JobManager registration rejection <*> from <*> with leader session ID <*>.,debug,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection: void lambda$onRegistrationRejection$3(org.apache.flink.runtime.jobmaster.JMTMRegistrationRejection)>
An exception occurred during the metrics setup.,warn,<org.apache.flink.runtime.operators.DataSinkTask: void invoke()>
Error closing local strategy,error,<org.apache.flink.runtime.operators.DataSinkTask: void invoke()>
Error closing local strategy,error,<org.apache.flink.runtime.operators.DataSinkTask: void invoke()>
Cleanup on error failed.,error,<org.apache.flink.runtime.operators.DataSinkTask: void invoke()>
Error closing local strategy,error,<org.apache.flink.runtime.operators.DataSinkTask: void invoke()>
Error closing local strategy,error,<org.apache.flink.runtime.operators.DataSinkTask: void invoke()>
Discard state created before checkpoint <*> and not used afterwards,debug,<org.apache.flink.runtime.state.SharedStateRegistryImpl: void unregisterUnusedState(long)>
Discard <*> state asynchronously,trace,<org.apache.flink.runtime.state.SharedStateRegistryImpl: void unregisterUnusedState(long)>
<*>: Retriggering partition request <*>:<*>.,debug,"<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: void retriggerPartitionRequest(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID,int)>"
Reading thread done.,debug,<org.apache.flink.runtime.operators.sort.SorterInputGateway: void finishReading()>
"Could not resolve <*> address <*>, retrying in <*> ms.",debug,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$startRegistration$1(java.lang.Void,java.lang.Throwable)>"
"Could not resolve <*> address <*>, retrying in <*> ms: <*>",info,"<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$startRegistration$1(java.lang.Void,java.lang.Throwable)>"
Could not close and delete the temp file for the current spilled partition probe side.,warn,<org.apache.flink.runtime.operators.hash.MutableHashTable: void close()>
Could not match offer <*> to any outstanding requirement.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: java.util.Collection internalOfferSlots(java.util.Collection,org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,long,java.util.function.Function)>"
Acquired new resources; new total acquired resources: <*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: java.util.Collection internalOfferSlots(java.util.Collection,org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,long,java.util.function.Function)>"
Removing job graph <*> from <*>.,debug,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void lambda$globalCleanupAsync$0(org.apache.flink.api.common.JobID)>
Removed job graph <*> from <*>.,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void lambda$globalCleanupAsync$0(org.apache.flink.api.common.JobID)>
ExecutionGraph <*> reached terminal state <*>.,debug,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void onTerminalState(org.apache.flink.api.common.JobStatus)>
Error while cleaning up after execution,error,<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void onTerminalState(org.apache.flink.api.common.JobStatus)>
,<init>,<org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler: org.apache.flink.runtime.rest.messages.LogInfo lambda$handleRequest$0(java.io.File)>
Clearing resource requirements of job <*>,info,<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void processResourceRequirements(org.apache.flink.runtime.slots.ResourceRequirements)>
Received resource requirements from job <*>: <*>,info,<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void processResourceRequirements(org.apache.flink.runtime.slots.ResourceRequirements)>
Archive global failure.,debug,"<org.apache.flink.runtime.scheduler.SchedulerBase: void archiveGlobalFailure(java.lang.Throwable,long,java.lang.Iterable)>"
Could not parse checkpoint id from <*>. This indicates that the checkpoint id to path conversion has changed.,warn,<org.apache.flink.runtime.checkpoint.ZooKeeperCheckpointStoreUtil: long nameToCheckpointID(java.lang.String)>
"Cannot register metric, because the MetricRegistry has already been shut down.",warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void register(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Error while registering metric: <*>.,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void register(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Error while registering metric: <*>.,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void register(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Error while registering metric: <*>.,warn,"<org.apache.flink.runtime.metrics.MetricRegistryImpl: void register(org.apache.flink.metrics.Metric,java.lang.String,org.apache.flink.runtime.metrics.groups.AbstractMetricGroup)>"
Failed to delete locally cached BLOB <*> at <*>,warn,"<org.apache.flink.runtime.blob.TransientBlobCache: boolean deleteInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.TransientBlobKey)>"
Aborting InPlaceMutableHashTable.,debug,<org.apache.flink.runtime.operators.hash.InPlaceMutableHashTable: void abort()>
Stored local state for checkpoint <*> in subtask (<*> - <*> - <*>) : <*>.,trace,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void storeLocalState(long,org.apache.flink.runtime.checkpoint.TaskStateSnapshot)>"
Stored local state for checkpoint <*> in subtask (<*> - <*> - <*>),debug,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void storeLocalState(long,org.apache.flink.runtime.checkpoint.TaskStateSnapshot)>"
New reported watermark=<*> from subTaskId=<*>,debug,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void handleReportedWatermark(int,org.apache.flink.api.common.eventtime.Watermark)>"
Exception while disposing state changelog storage <*>.,warn,<org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager: void doRelease(org.apache.flink.runtime.state.changelog.StateChangelogStorage)>
Received response was neither of the expected type (<*>) nor an error. Response=<*>,error,"<org.apache.flink.runtime.rest.RestClient: java.util.concurrent.CompletableFuture parseResponse(org.apache.flink.runtime.rest.RestClient$JsonResponse,org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.JavaType)>"
"Failed to parse scope format, using default scope formats",warn,"<org.apache.flink.runtime.metrics.MetricRegistryConfiguration: org.apache.flink.runtime.metrics.MetricRegistryConfiguration fromConfiguration(org.apache.flink.configuration.Configuration,long)>"
"Failed to parse delimiter, using default delimiter.",warn,"<org.apache.flink.runtime.metrics.MetricRegistryConfiguration: org.apache.flink.runtime.metrics.MetricRegistryConfiguration fromConfiguration(org.apache.flink.configuration.Configuration,long)>"
Invalid registration id for slot available message. This indicates an outdated request.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void notifySlotAvailable(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID)>"
Could not find registration for resource id <*>. Discarding the slot availablemessage <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void notifySlotAvailable(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID)>"
Job <*> reached terminal state <*>.\n<*>,info,<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture jobReachedTerminalState(org.apache.flink.runtime.scheduler.ExecutionGraphInfo)>
Job <*> reached terminal state <*>.,info,<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture jobReachedTerminalState(org.apache.flink.runtime.scheduler.ExecutionGraphInfo)>
Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.,warn,"<org.apache.flink.runtime.rest.handler.util.HandlerRequestUtils: java.lang.Object fromRequestBodyOrQueryParameter(java.lang.Object,org.apache.flink.util.function.SupplierWithException,java.lang.Object,org.slf4j.Logger)>"
", ",decreaseBuffersInBacklogUnsafe,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: org.apache.flink.runtime.io.network.partition.ResultSubpartition$BufferAndBacklog pollBuffer()>
PipelinedSubpartition#pollBuffer,traceOutput,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: org.apache.flink.runtime.io.network.partition.ResultSubpartition$BufferAndBacklog pollBuffer()>
found barrier,logEvent,<org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister: java.util.OptionalLong checkForBarrier(org.apache.flink.runtime.io.network.buffer.Buffer)>
ignoring barrier,logEvent,<org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister: java.util.OptionalLong checkForBarrier(org.apache.flink.runtime.io.network.buffer.Buffer)>
found announcement for barrier,logEvent,<org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister: java.util.OptionalLong checkForBarrier(org.apache.flink.runtime.io.network.buffer.Buffer)>
Failed to release result partition for task <*>.,error,<org.apache.flink.runtime.taskmanager.Task: void closeAllResultPartitions()>
Using job/cluster config to configure application-defined state backend: <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadFromApplicationOrConfigOrDefaultInternal(org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Using application-defined state backend: <*>,info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadFromApplicationOrConfigOrDefaultInternal(org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
"No state backend has been configured, using default (HashMap) <*>",info,"<org.apache.flink.runtime.state.StateBackendLoader: org.apache.flink.runtime.state.StateBackend loadFromApplicationOrConfigOrDefaultInternal(org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Add job <*> for job leader monitoring.,info,"<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService: void addJob(org.apache.flink.api.common.JobID,java.lang.String)>"
Ignore \'<*>\' because the leadership runner is no longer running.,trace,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: java.util.Optional callIfRunning(java.util.function.Supplier,java.lang.String)>"
Error in MiniCluster. Shutting the MiniCluster down.,warn,<org.apache.flink.runtime.minicluster.MiniCluster$ShutDownFatalErrorHandler: void onFatalError(java.lang.Throwable)>
"Reducing maximal merge fan-in to , <*>,  due to limited memory availability during merge, ",debug,<org.apache.flink.runtime.operators.sort.ExternalSorterBuilder: org.apache.flink.runtime.operators.sort.ExternalSorter doBuild(org.apache.flink.runtime.operators.sort.ExternalSorterBuilder$ReadingStageFactory)>
Could not retrieve the state handle from node <*>.,warn,<org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore: boolean releaseAndTryRemove(java.lang.String)>
Could not delete znode <*> because it is still locked.,debug,<org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore: boolean releaseAndTryRemove(java.lang.String)>
Task <*> is already in state <*>,info,"<org.apache.flink.runtime.taskmanager.Task: void cancelOrFailAndCancelInvokableInternal(org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
Triggering cancellation of task code <*> (<*>).,info,"<org.apache.flink.runtime.taskmanager.Task: void cancelOrFailAndCancelInvokableInternal(org.apache.flink.runtime.execution.ExecutionState,java.lang.Throwable)>"
Terminating cluster entrypoint process <*> with exit code <*>.,info,<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: void runClusterEntrypoint(org.apache.flink.runtime.entrypoint.ClusterEntrypoint)>
registering <*>,debug,<org.apache.flink.runtime.io.network.TaskEventDispatcher: void registerPartition(org.apache.flink.runtime.io.network.partition.ResultPartitionID)>
FileChannelManager uses directory <*> for spill files.,debug,"<org.apache.flink.runtime.io.disk.FileChannelManagerImpl: java.io.File[] createFiles(java.lang.String[],java.lang.String)>"
Could not cleanup uploaded files.,warn,<org.apache.flink.runtime.rest.FileUploadHandler: void deleteUploadedFiles()>
"Received confirmation of leadership for leader <*> , session=<*>",info,"<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService: void confirmLeader(org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$EmbeddedLeaderElectionService,java.util.UUID,java.lang.String)>"
Received confirmation of leadership for a stale leadership grant. Ignoring.,debug,"<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService: void confirmLeader(org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$EmbeddedLeaderElectionService,java.util.UUID,java.lang.String)>"
Using legacy state backend <*> as Job checkpoint storage,info,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage load(org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.core.fs.Path,org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Checkpoint storage passed via StreamExecutionEnvironment is ignored because legacy state backend \'<*>\' is used. <*>,warn,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage load(org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.core.fs.Path,org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Config option \'<*>\' is ignored because legacy state backend \'<*>\' is used. <*>,warn,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage load(org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.core.fs.Path,org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Using job/cluster config to configure application-defined checkpoint storage: <*>,info,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage load(org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.core.fs.Path,org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Config option \'<*>\' is ignored because the checkpoint storage passed via StreamExecutionEnvironment takes precedence.,warn,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage load(org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.core.fs.Path,org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Using application defined checkpoint storage: <*>,info,"<org.apache.flink.runtime.state.CheckpointStorageLoader: org.apache.flink.runtime.state.CheckpointStorage load(org.apache.flink.runtime.state.CheckpointStorage,org.apache.flink.core.fs.Path,org.apache.flink.runtime.state.StateBackend,org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
"Cannot find task to stop for execution , executionAttemptID, , ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: java.util.concurrent.CompletableFuture cancelTask(org.apache.flink.runtime.executiongraph.ExecutionAttemptID,org.apache.flink.api.common.time.Time)>"
Attaching <*> topologically sorted vertices to existing job graph with <*> vertices and <*> intermediate results.,debug,"<org.apache.flink.runtime.executiongraph.DefaultExecutionGraph: void attachJobGraph(java.util.List,java.util.List)>"
Starting allocation of slot <*> from <*> for job <*> with resource profile <*>.,info,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: java.util.concurrent.CompletableFuture allocateSlot(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.api.common.JobID,java.lang.String,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Discarding late registered partitions for <*> task <*>.,info,"<org.apache.flink.runtime.executiongraph.Execution: java.lang.Void lambda$registerProducedPartitions$0(org.apache.flink.runtime.taskmanager.TaskManagerLocation,java.util.Map)>"
Cancelling request <*>,info,"<org.apache.flink.runtime.webmonitor.stats.TaskStatsRequestCoordinator: void handleFailedResponse(int,java.lang.Throwable)>"
RemoteInputChannel#onBuffer,traceInput,"<org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel: void onBuffer(org.apache.flink.runtime.io.network.buffer.Buffer,int,int)>"
<*>: Creating read view for subpartition <*> of partition <*>.,debug,<org.apache.flink.runtime.io.network.partition.PipelinedSubpartition: org.apache.flink.runtime.io.network.partition.PipelinedSubpartitionView createReadView(org.apache.flink.runtime.io.network.partition.BufferAvailabilityListener)>
Combiner starting.,debug,<org.apache.flink.runtime.operators.GroupReduceCombineDriver: void run()>
Starting the slot manager.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void start(org.apache.flink.runtime.resourcemanager.ResourceManagerId,java.util.concurrent.Executor,org.apache.flink.runtime.resourcemanager.slotmanager.ResourceActions)>"
Proposing leadership to contender <*>,info,<org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService: java.util.concurrent.CompletableFuture updateLeader()>
Received notification for job <*> having lost resource <*>.,trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker: void notifyLostResource(org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
"Received notification for job <*> having lost resource <*>, but no such job was tracked.",trace,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker: void notifyLostResource(org.apache.flink.api.common.JobID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Ignore leader action \'<*>\' because the leadership runner is no longer the valid leader for <*>.,trace,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void runIfValidLeader(java.util.UUID,java.lang.Runnable,java.lang.String)>"
Calculating tasks to restart to recover the failed task <*>.,info,"<org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy: java.util.Set getTasksNeedingRestart(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,java.lang.Throwable)>"
<*> tasks should be restarted to recover the failed task <*>. ,info,"<org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy: java.util.Set getTasksNeedingRestart(org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID,java.lang.Throwable)>"
The reporter factory (<*>) could not be found for reporter <*>. Available factories: <*>.,warn,"<org.apache.flink.runtime.metrics.ReporterSetup: java.util.Optional loadViaFactory(java.lang.String,java.lang.String,org.apache.flink.configuration.Configuration,java.util.Map)>"
Starting the kvState service and its components.,info,<org.apache.flink.runtime.taskexecutor.KvStateService: void start()>
Failed to start the Queryable State Data Server.,error,<org.apache.flink.runtime.taskexecutor.KvStateService: void start()>
Failed to start the Queryable State Client Proxy.,error,<org.apache.flink.runtime.taskexecutor.KvStateService: void start()>
"Failed to cleanly close a checkpoint master hook (, <*>, ), ",warn,"<org.apache.flink.runtime.checkpoint.hooks.MasterHooks: void close(java.util.Collection,org.slf4j.Logger)>"
Recovering checkpoints from <*>.,info,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStoreUtils: java.util.Collection retrieveCompletedCheckpoints(org.apache.flink.runtime.persistence.StateHandleStore,org.apache.flink.runtime.checkpoint.CheckpointStoreUtil)>"
Found <*> checkpoints in <*>.,info,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStoreUtils: java.util.Collection retrieveCompletedCheckpoints(org.apache.flink.runtime.persistence.StateHandleStore,org.apache.flink.runtime.checkpoint.CheckpointStoreUtil)>"
Trying to fetch <*> checkpoints from storage.,info,"<org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStoreUtils: java.util.Collection retrieveCompletedCheckpoints(org.apache.flink.runtime.persistence.StateHandleStore,org.apache.flink.runtime.checkpoint.CheckpointStoreUtil)>"
Connected to ZooKeeper quorum. Leader election can start.,debug,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
"Connection to ZooKeeper suspended, waiting for reconnection.",warn,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
Connection to ZooKeeper was reconnected. Leader election can be restarted.,info,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
"Connection to ZooKeeper lost. The contender , <*>,  no longer participates in the leader election., ",warn,<org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
<*> <*> <*> @ <*>,trace,"<org.apache.flink.runtime.io.network.logger.NetworkActionsLogger: void traceOutput(java.lang.String,org.apache.flink.runtime.io.network.buffer.Buffer,java.lang.String,org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo)>"
Adding job graph <*> to <*>.,debug,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void putJobGraph(org.apache.flink.runtime.jobgraph.JobGraph)>
Updated <*> in <*>.,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void putJobGraph(org.apache.flink.runtime.jobgraph.JobGraph)>
Added <*> to <*>.,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: void putJobGraph(org.apache.flink.runtime.jobgraph.JobGraph)>
Free allocated slot with allocationId <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker: void freeSlot(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.clusterframework.types.AllocationID)>"
Error while requesting next input split,warn,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture requestNextInputSplit(org.apache.flink.runtime.jobgraph.JobVertexID,org.apache.flink.runtime.executiongraph.ExecutionAttemptID)>"
Key value state unregistered for job <*> under name <*>.,debug,"<org.apache.flink.runtime.scheduler.KvStateHandler: void notifyKvStateUnregistered(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobgraph.JobVertexID,org.apache.flink.runtime.state.KeyGroupRange,java.lang.String)>"
Matched slot offer <*> to requirement <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: java.util.Optional matchOfferWithOutstandingRequirements(org.apache.flink.runtime.taskexecutor.slot.SlotOffer,org.apache.flink.runtime.taskmanager.TaskManagerLocation,org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway,java.util.function.Function)>"
"<*>,  was interrupted without shutdown., ",warn,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$ReaderThread: void run()>
"I/O reading thread encountered an error, <*>_, ",error,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$ReaderThread: void run()>
"The handler of the request-complete-callback threw an exception, <*>_, ",error,<org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync$ReaderThread: void run()>
Close JobManager connection for job <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void disconnectJobManagerConnection(org.apache.flink.runtime.taskexecutor.JobTable$Connection,java.lang.Exception)>"
Close JobManager connection for job <*>.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void disconnectJobManagerConnection(org.apache.flink.runtime.taskexecutor.JobTable$Connection,java.lang.Exception)>"
Could not mark the slot <*> inactive.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void disconnectJobManagerConnection(org.apache.flink.runtime.taskexecutor.JobTable$Connection,java.lang.Exception)>"
Could not properly disassociate from JobManager <*>.,warn,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void disconnectJobManagerConnection(org.apache.flink.runtime.taskexecutor.JobTable$Connection,java.lang.Exception)>"
Received PUT request for BLOB of job <*> with from <*>.,debug,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
"Cannot delete BLOB server staging file , <*>, ",warn,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
Socket connection closed,debug,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
"Cannot delete BLOB server staging file , <*>, ",warn,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
PUT operation failed,error,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
"Cannot delete BLOB server staging file , <*>, ",warn,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
"Cannot delete BLOB server staging file , <*>, ",warn,"<org.apache.flink.runtime.blob.BlobServerConnection: void put(java.io.InputStream,java.io.OutputStream,byte[])>"
<*>: Updated unknown input channel to <*>.,debug,"<org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate: void updateInputChannel(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.shuffle.NettyShuffleDescriptor)>"
Read channel on <*>: <*>.,debug,"<org.apache.flink.runtime.io.network.netty.PartitionRequestServerHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.io.network.netty.NettyMessage)>"
Received unexpected client request: <*>,warn,"<org.apache.flink.runtime.io.network.netty.PartitionRequestServerHandler: void channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext,org.apache.flink.runtime.io.network.netty.NettyMessage)>"
<*>,info,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void run()>
<*>,info,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void run()>
<*>,info,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void run()>
<*>,info,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void run()>
<*>,info,<org.apache.flink.runtime.iterative.task.IterationHeadTask: void run()>
Remove <*>,debug,<org.apache.flink.runtime.scheduler.SharedSlot: void removeLogicalSlotRequest(org.apache.flink.runtime.jobmaster.SlotRequestId)>
The target with resource ID <*> is already been monitored.,debug,"<org.apache.flink.runtime.heartbeat.HeartbeatManagerImpl: void monitorTarget(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.heartbeat.HeartbeatTarget)>"
Cannot close the large records spill file.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
Cannot close the large records key spill file.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
Cannot close the large records reader.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
Cannot close the large records key reader.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
Cannot delete the large records spill file.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
Cannot delete the large records key spill file.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
Cannot properly dispose the key sorter and clean up its temporary files.,error,<org.apache.flink.runtime.operators.sort.LargeRecordHandler: void close()>
"Error during release of result subpartition: , <*>, ",error,<org.apache.flink.runtime.io.network.partition.BufferWritingResultPartition: void releaseInternal()>
"StateChangelogStorageLoader found duplicated factory, using <*> instead of <*> for name <*>.",warn,<org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader: void lambda$initialize$0(org.apache.flink.runtime.state.changelog.StateChangelogStorageFactory)>
Created a new <*> for storing result partitions of BLOCKING shuffles. Used directories:\n\t<*>,info,"<org.apache.flink.runtime.io.network.NettyShuffleServiceFactory: org.apache.flink.runtime.io.network.NettyShuffleEnvironment createNettyShuffleEnvironment(org.apache.flink.runtime.taskmanager.NettyShuffleEnvironmentConfiguration,org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.io.network.TaskEventPublisher,org.apache.flink.runtime.io.network.partition.ResultPartitionManager,org.apache.flink.runtime.io.network.ConnectionManager,org.apache.flink.metrics.MetricGroup,java.util.concurrent.Executor)>"
Discard slot offer response since there is a newer offer for the job <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$handleAcceptedSlotOffers$17(java.util.UUID,org.apache.flink.api.common.JobID,java.util.Collection,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.jobmaster.JobMasterGateway,java.lang.Iterable,java.lang.Throwable)>"
Slot offering to JobManager did not finish in time. Retrying the slot offering.,info,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$handleAcceptedSlotOffers$17(java.util.UUID,org.apache.flink.api.common.JobID,java.util.Collection,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.jobmaster.JobMasterGateway,java.lang.Iterable,java.lang.Throwable)>"
Slot offering to JobManager failed. Freeing the slots and returning them to the ResourceManager.,warn,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$handleAcceptedSlotOffers$17(java.util.UUID,org.apache.flink.api.common.JobID,java.util.Collection,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.jobmaster.JobMasterGateway,java.lang.Iterable,java.lang.Throwable)>"
"Could not mark slot , <*>,  active., ",debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$handleAcceptedSlotOffers$17(java.util.UUID,org.apache.flink.api.common.JobID,java.util.Collection,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.jobmaster.JobMasterGateway,java.lang.Iterable,java.lang.Throwable)>"
Discard slot offer response since there is a new leader for the job <*>.,debug,"<org.apache.flink.runtime.taskexecutor.TaskExecutor: void lambda$handleAcceptedSlotOffers$17(java.util.UUID,org.apache.flink.api.common.JobID,java.util.Collection,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.jobmaster.JobMasterGateway,java.lang.Iterable,java.lang.Throwable)>"
Returning logical slot to shared slot (<*>),debug,<org.apache.flink.runtime.scheduler.adaptive.allocator.SharedSlot: void returnLogicalSlot(org.apache.flink.runtime.jobmaster.LogicalSlot)>
An exception occurred while handling another exception.,warn,"<org.apache.flink.runtime.rest.handler.AbstractHandler: void lambda$respondAsLeader$1(org.apache.flink.runtime.rest.handler.FileUploads,java.lang.Void,java.lang.Throwable)>"
Disconnect TaskExecutor <*> because: <*>,debug,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture disconnectTaskManager(org.apache.flink.runtime.clusterframework.types.ResourceID,java.lang.Exception)>"
Leader node has changed.,debug,<org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver: void retrieveLeaderInformationFromZooKeeper()>
Shutting down.,info,<org.apache.flink.runtime.checkpoint.ZooKeeperCheckpointIDCounter: java.util.concurrent.CompletableFuture shutdown(org.apache.flink.api.common.JobStatus)>
Removing <*> from ZooKeeper,info,<org.apache.flink.runtime.checkpoint.ZooKeeperCheckpointIDCounter: java.util.concurrent.CompletableFuture shutdown(org.apache.flink.api.common.JobStatus)>
Using working directory: <*>,info,<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: void startTaskManagerRunnerServices()>
Job <*> has been archived at <*>.,info,"<org.apache.flink.runtime.history.FsJobArchivist: org.apache.flink.core.fs.Path archiveJob(org.apache.flink.core.fs.Path,org.apache.flink.api.common.JobID,java.util.Collection)>"
Failed to archive job.,error,"<org.apache.flink.runtime.history.FsJobArchivist: org.apache.flink.core.fs.Path archiveJob(org.apache.flink.core.fs.Path,org.apache.flink.api.common.JobID,java.util.Collection)>"
Initializing job \'<*>\' (<*>).,info,"<org.apache.flink.runtime.jobmaster.JobMaster: void <init>(org.apache.flink.runtime.rpc.RpcService,org.apache.flink.runtime.jobmaster.JobMasterId,org.apache.flink.runtime.jobmaster.JobMasterConfiguration,org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.jobmaster.SlotPoolServiceSchedulerFactory,org.apache.flink.runtime.jobmaster.JobManagerSharedServices,org.apache.flink.runtime.heartbeat.HeartbeatServices,org.apache.flink.runtime.jobmaster.factories.JobManagerJobMetricGroupFactory,org.apache.flink.runtime.jobmanager.OnCompletionActions,org.apache.flink.runtime.rpc.FatalErrorHandler,java.lang.ClassLoader,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.PartitionTrackerFactory,org.apache.flink.runtime.jobmaster.ExecutionDeploymentTracker,org.apache.flink.runtime.jobmaster.ExecutionDeploymentReconciler$Factory,long)>"
Release shared slot (<*>),debug,<org.apache.flink.runtime.scheduler.SharedSlot: void release(java.lang.Throwable)>
Release <*>,debug,<org.apache.flink.runtime.scheduler.SharedSlot: void release(java.lang.Throwable)>
,checkState,<org.apache.flink.runtime.scheduler.SharedSlot: void release(java.lang.Throwable)>
Allocating <*> task executors for redundancy.,debug,<org.apache.flink.runtime.resourcemanager.slotmanager.TaskExecutorManager: void allocateRedundantTaskManagers(int)>
Expect to allocate <*> taskManagers. Actually allocate <*> taskManagers.,warn,<org.apache.flink.runtime.resourcemanager.slotmanager.TaskExecutorManager: void allocateRedundantTaskManagers(int)>
Attempting to load configured checkpoint storage for savepoint disposal,info,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.CheckpointStorage loadCheckpointStorage(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Could not load configured state backend.,info,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.CheckpointStorage loadCheckpointStorage(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
Detailed exception:,debug,"<org.apache.flink.runtime.checkpoint.Checkpoints: org.apache.flink.runtime.state.CheckpointStorage loadCheckpointStorage(org.apache.flink.configuration.Configuration,java.lang.ClassLoader,org.slf4j.Logger)>"
"Cannot instantiate security context with: , contextFactoryClass, ",error,<org.apache.flink.runtime.security.SecurityUtils: void installContext(org.apache.flink.runtime.security.SecurityConfiguration)>
"Error occur when instantiate security context with: , contextFactoryClass, ",error,<org.apache.flink.runtime.security.SecurityUtils: void installContext(org.apache.flink.runtime.security.SecurityConfiguration)>
Unable to install security context factory <*>,debug,<org.apache.flink.runtime.security.SecurityUtils: void installContext(org.apache.flink.runtime.security.SecurityConfiguration)>
Unable to instantiate security context factory <*>,warn,<org.apache.flink.runtime.security.SecurityUtils: void installContext(org.apache.flink.runtime.security.SecurityConfiguration)>
Unable to install a valid security context factory!,error,<org.apache.flink.runtime.security.SecurityUtils: void installContext(org.apache.flink.runtime.security.SecurityConfiguration)>
Received slot report for unknown task manager with instance id <*>. Ignoring this report.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Received slot report from instance <*>: <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Freeing slot <*> by slot report.,info,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer: boolean reportSlotStatus(org.apache.flink.runtime.instance.InstanceID,org.apache.flink.runtime.taskexecutor.SlotReport)>"
Retrieve metric query service gateway for <*>,debug,<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void retrieveAndQueryMetrics(java.lang.String)>
Add job <*> to job leader id monitoring.,debug,<org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService: void addJob(org.apache.flink.api.common.JobID)>
Free slot <*>.,debug,"<org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl: java.util.concurrent.CompletableFuture freeSlotInternal(org.apache.flink.runtime.taskexecutor.slot.TaskSlot,java.lang.Throwable)>"
Free slot <*>.,info,"<org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl: java.util.concurrent.CompletableFuture freeSlotInternal(org.apache.flink.runtime.taskexecutor.slot.TaskSlot,java.lang.Throwable)>"
Going to disk-based merge because of large records.,debug,<org.apache.flink.runtime.operators.sort.SpillingThread: void go()>
"Sorting large records, to add them to in-memory merge.",debug,<org.apache.flink.runtime.operators.sort.SpillingThread: void go()>
"Failed to locally delete job directory , <*>, ",warn,<org.apache.flink.runtime.blob.PermanentBlobCache$PermanentBlobCleanupTask: void run()>
Job <*> under leader id <*> failed.,debug,<org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess: void jobMasterFailed(java.lang.Throwable)>
There are <*> excess resources for job <*> before re-assignment.,trace,<org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker: void tryAssigningExcessSlots()>
There are <*> excess resources for job <*> after re-assignment.,trace,<org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker: void tryAssigningExcessSlots()>
Removing <*> from ZooKeeper,info,<org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore: void clearEntries()>
<*> will not be reported as the metric dump would exceed the maximum size of <*> bytes.,debug,"<org.apache.flink.runtime.metrics.dump.MetricQueryService: void logDumpSizeWouldExceedLimit(java.lang.String,boolean)>"
<*> will not be reported as the metric dump would exceed the maximum size of <*> bytes.,info,"<org.apache.flink.runtime.metrics.dump.MetricQueryService: void logDumpSizeWouldExceedLimit(java.lang.String,boolean)>"
Received slot request <*> with resource requirements: <*>,debug,<org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl: java.util.concurrent.CompletableFuture allocatePhysicalSlot(org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotRequest)>
Cannot run \'<*>\' because the actual state is <*> and not <*>.,debug,"<org.apache.flink.runtime.scheduler.adaptive.State: void tryRun(java.lang.Class,org.apache.flink.util.function.ThrowingConsumer,java.lang.String)>"
Received consume notification from <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: void onConsumedPartition(org.apache.flink.runtime.io.network.partition.ResultPartition)>
Released partition <*> produced by <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResultPartitionManager: void onConsumedPartition(org.apache.flink.runtime.io.network.partition.ResultPartition)>
Rest endpoint shutdown complete.,debug,<org.apache.flink.runtime.rest.RestClient: void shutdown(org.apache.flink.api.common.time.Time)>
Rest endpoint shutdown failed.,warn,<org.apache.flink.runtime.rest.RestClient: void shutdown(org.apache.flink.api.common.time.Time)>
LOG,<init>,<org.apache.flink.runtime.rest.handler.RestHandlerException$LoggingBehavior: void <clinit>()>
IGNORE,<init>,<org.apache.flink.runtime.rest.handler.RestHandlerException$LoggingBehavior: void <clinit>()>
Received slot report from TaskManager <*> which is no longer registered.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager$TaskManagerHeartbeatListener: void reportPayload(org.apache.flink.runtime.clusterframework.types.ResourceID,org.apache.flink.runtime.taskexecutor.TaskExecutorHeartbeatPayload)>"
Cannot access com.sun.management.OperatingSystemMXBean.getProcessCpuLoad() - CPU load metrics will not be available.,warn,<org.apache.flink.runtime.metrics.util.MetricUtils: void instantiateCPUMetrics(org.apache.flink.metrics.MetricGroup)>
Cannot persist the slot allocation snapshot <*>.,debug,<org.apache.flink.runtime.taskexecutor.TaskExecutor: void tryPersistAllocationSnapshot(org.apache.flink.runtime.taskexecutor.slot.SlotAllocationSnapshot)>
Grant leadership to contender <*> with session ID <*>.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onGrantLeadership(java.util.UUID)>
Ignoring the grant leadership notification since the <*> has already been closed.,debug,<org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService: void onGrantLeadership(java.util.UUID)>
"<*> <*> <*>, checkpoint <*> @ <*>",trace,"<org.apache.flink.runtime.io.network.logger.NetworkActionsLogger: void tracePersist(java.lang.String,org.apache.flink.runtime.io.network.buffer.Buffer,java.lang.String,java.lang.Object,long)>"
Received GET request for BLOB <*>/<*> from <*>.,debug,"<org.apache.flink.runtime.blob.BlobServerConnection: void get(java.io.InputStream,java.io.OutputStream,byte[])>"
GET operation from <*> failed.,error,"<org.apache.flink.runtime.blob.BlobServerConnection: void get(java.io.InputStream,java.io.OutputStream,byte[])>"
GET operation failed for BLOB <*>/<*> from <*>.,error,"<org.apache.flink.runtime.blob.BlobServerConnection: void get(java.io.InputStream,java.io.OutputStream,byte[])>"
DELETE operation failed for BLOB <*>/<*> from <*>.,warn,"<org.apache.flink.runtime.blob.BlobServerConnection: void get(java.io.InputStream,java.io.OutputStream,byte[])>"
Socket connection closed,debug,"<org.apache.flink.runtime.blob.BlobServerConnection: void get(java.io.InputStream,java.io.OutputStream,byte[])>"
GET operation failed,error,"<org.apache.flink.runtime.blob.BlobServerConnection: void get(java.io.InputStream,java.io.OutputStream,byte[])>"
Using a local buffer pool with <*>-<*> buffers,debug,"<org.apache.flink.runtime.io.network.buffer.LocalBufferPool: void <init>(org.apache.flink.runtime.io.network.buffer.NetworkBufferPool,int,int,int,int)>"
Shutting <*> down with application status <*>. Diagnostics <*>.,info,"<org.apache.flink.runtime.entrypoint.ClusterEntrypoint: java.util.concurrent.CompletableFuture shutDownAsync(org.apache.flink.runtime.clusterframework.ApplicationStatus,org.apache.flink.runtime.entrypoint.ClusterEntrypoint$ShutdownBehaviour,java.lang.String,boolean)>"
"Discarding job leader lost leadership, because a new job leader was found for job <*>. ",debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void jobLeaderLostLeadership(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.JobMasterId)>"
Discard job leader lost leadership for outdated leader <*> for job <*>.,debug,"<org.apache.flink.runtime.resourcemanager.ResourceManager: void jobLeaderLostLeadership(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.JobMasterId)>"
"Recover all persisted job graphs that are not finished, yet.",info,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: java.util.Collection recoverJobs(java.util.Set)>
Successfully recovered <*> persisted job graphs.,info,<org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess: java.util.Collection recoverJobs(java.util.Set)>
Recovering subtask <*> to checkpoint <*> for source <*> to checkpoint.,info,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$subtaskReset$4(int,long)>"
Adding splits back to the split enumerator of source <*>: <*>,debug,"<org.apache.flink.runtime.source.coordinator.SourceCoordinator: void lambda$subtaskReset$4(int,long)>"
"Resolved <*> address, beginning registration",info,<org.apache.flink.runtime.registration.RetryingRegistration: void lambda$startRegistration$0(org.apache.flink.runtime.rpc.RpcGateway)>
TaskManager will use hostname/address \'<*>\' (<*>) for communication.,info,"<org.apache.flink.runtime.taskexecutor.TaskManagerRunner: java.lang.String determineTaskManagerBindAddressByConnectingToResourceManager(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.highavailability.HighAvailabilityServices,org.apache.flink.runtime.rpc.RpcSystemUtils)>"
Stop current JobMasterServiceProcess because the leadership has been revoked.,debug,<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: java.util.concurrent.CompletableFuture stopJobMasterServiceProcess()>
Failed to release input gate for task <*>.,error,<org.apache.flink.runtime.taskmanager.Task: void closeAllInputGates()>
Using the request slot matching strategy: <*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge: void <init>(org.apache.flink.api.common.JobID,org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolFactory,org.apache.flink.util.clock.Clock,org.apache.flink.api.common.time.Time,org.apache.flink.api.common.time.Time,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.jobmaster.slotpool.RequestSlotMatchingStrategy)>"
Recovering job graph <*> from <*>.,debug,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: org.apache.flink.runtime.jobgraph.JobGraph recoverJobGraph(org.apache.flink.api.common.JobID)>
Recovered <*>.,info,<org.apache.flink.runtime.jobmanager.DefaultJobGraphStore: org.apache.flink.runtime.jobgraph.JobGraph recoverJobGraph(org.apache.flink.api.common.JobID)>
Successful registration at job manager <*> for job <*>.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection: void lambda$onRegistrationSuccess$0(org.apache.flink.runtime.jobmaster.JMTMRegistrationSuccess)>
Could not close user classloader,warn,<org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders$SafetyNetWrapperClassLoader: void close()>
Requesting subpartition <*> of partition <*> with <*> ms delay.,debug,"<org.apache.flink.runtime.io.network.netty.NettyPartitionRequestClient: void requestSubpartition(org.apache.flink.runtime.io.network.partition.ResultPartitionID,int,org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel,int)>"
Exception while discarding local task state snapshot of checkpoint <*> in subtask (<*> - <*> - <*>).,warn,"<org.apache.flink.runtime.state.TaskLocalStateStoreImpl: void lambda$discardLocalStateForCheckpoint$5(long,org.apache.flink.runtime.checkpoint.TaskStateSnapshot)>"
"Failed to locally delete BLOB , key,  at , <*>, ",warn,"<org.apache.flink.runtime.blob.BlobServer: boolean deleteInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.PermanentBlobKey)>"
<*>,tryAssignResource,"<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: org.apache.flink.runtime.executiongraph.ExecutionGraph assignSlotsToExecutionGraph(org.apache.flink.runtime.executiongraph.ExecutionGraph,org.apache.flink.runtime.scheduler.adaptive.allocator.ReservedSlots)>"
Requesting TaskManager\'s path for query services failed.,debug,"<org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl: void lambda$fetchMetrics$3(java.util.Collection,java.lang.Throwable)>"
Error while attempting to deserialize user AggregateFunction.,error,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture updateGlobalAggregate(java.lang.String,java.lang.Object,byte[])>"
Failed to register at resource manager <*>.,info,<org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection: void onRegistrationFailure(java.lang.Throwable)>
Received JobGraph submission \'<*>\' (<*>).,info,"<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture submitJob(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.api.common.time.Time)>"
Ignoring JobGraph submission \'<*>\' (<*>) because the job already reached a globally-terminal state (i.e. <*>) in a previous execution.,warn,"<org.apache.flink.runtime.dispatcher.Dispatcher: java.util.concurrent.CompletableFuture submitJob(org.apache.flink.runtime.jobgraph.JobGraph,org.apache.flink.api.common.time.Time)>"
We could not delete the storage location: <*> in CLAIM restore mode. It is most probably because of shared files still being used by newer checkpoints,debug,<org.apache.flink.runtime.checkpoint.Checkpoints$ClaimModeCompletedStorageLocation: void disposeStorageLocation()>
Connected to ZooKeeper quorum. Leader retrieval can start.,debug,<org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
"Connection to ZooKeeper suspended, waiting for reconnection.",warn,<org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
Connection to ZooKeeper was reconnected. Leader retrieval can be restarted.,info,<org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
Connection to ZooKeeper lost. Can no longer retrieve the leader from ZooKeeper.,warn,<org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver: void handleStateChange(org.apache.flink.shaded.curator5.org.apache.curator.framework.state.ConnectionState)>
Checkpoint <*> of job <*> expired before completing.,info,<org.apache.flink.runtime.checkpoint.CheckpointCoordinator$CheckpointCanceller: void run()>
No master state to restore,info,"<org.apache.flink.runtime.checkpoint.hooks.MasterHooks: void restoreMasterHooks(java.util.Map,java.util.Collection,long,boolean,org.slf4j.Logger)>"
Calling master restore hooks,info,"<org.apache.flink.runtime.checkpoint.hooks.MasterHooks: void restoreMasterHooks(java.util.Map,java.util.Collection,long,boolean,org.slf4j.Logger)>"
Found state to restore for hook \'<*>\',debug,"<org.apache.flink.runtime.checkpoint.hooks.MasterHooks: void restoreMasterHooks(java.util.Map,java.util.Collection,long,boolean,org.slf4j.Logger)>"
Dropping unmatched state from \'<*>\',info,"<org.apache.flink.runtime.checkpoint.hooks.MasterHooks: void restoreMasterHooks(java.util.Map,java.util.Collection,long,boolean,org.slf4j.Logger)>"
Transition from state <*> to <*>.,debug,<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: org.apache.flink.runtime.scheduler.adaptive.State transitionToState(org.apache.flink.runtime.scheduler.adaptive.StateFactory)>
Maximum capacity of ^ in StateMap reached. Cannot increase hash map size. This can lead to more collisions and lower performance. Please consider scaling-out your job or using a different keyed state backend implementation!,warn,<org.apache.flink.runtime.state.heap.CopyOnWriteStateMap: org.apache.flink.runtime.state.heap.CopyOnWriteStateMap$StateMapEntry[] makeTable(int)>
"Failed to stringify accumulator , name, , ",error,"<org.apache.flink.runtime.accumulators.StringifiedAccumulatorResult: org.apache.flink.runtime.accumulators.StringifiedAccumulatorResult stringifyAccumulatorResult(java.lang.String,org.apache.flink.util.OptionalFailure)>"
Using restart back off time strategy <*> for <*> (<*>).,info,"<org.apache.flink.runtime.scheduler.DefaultSchedulerFactory: org.apache.flink.runtime.scheduler.SchedulerNG createInstance(org.slf4j.Logger,org.apache.flink.runtime.jobgraph.JobGraph,java.util.concurrent.Executor,org.apache.flink.configuration.Configuration,org.apache.flink.runtime.jobmaster.slotpool.SlotPoolService,java.util.concurrent.ScheduledExecutorService,java.lang.ClassLoader,org.apache.flink.runtime.checkpoint.CheckpointRecoveryFactory,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.blob.BlobWriter,org.apache.flink.runtime.metrics.groups.JobManagerJobMetricGroup,org.apache.flink.api.common.time.Time,org.apache.flink.runtime.shuffle.ShuffleMaster,org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker,org.apache.flink.runtime.jobmaster.ExecutionDeploymentTracker,long,org.apache.flink.runtime.concurrent.ComponentMainThreadExecutor,org.apache.flink.runtime.rpc.FatalErrorHandler,org.apache.flink.runtime.executiongraph.JobStatusListener)>"
Could not properly close incremental snapshot streams.,warn,<org.apache.flink.runtime.state.AsyncSnapshotCallable: void closeSnapshotIO()>
Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.,info,<org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory: boolean isCompatibleWith(org.apache.flink.runtime.security.SecurityConfiguration)>
Stopping tracking of resources for job <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker: void checkWhetherTrackerCanBeRemoved(org.apache.flink.api.common.JobID,org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker)>"
Error while canceling the task <*>.,error,<org.apache.flink.runtime.taskmanager.Task$TaskCanceler: void run()>
Error in the task canceler for task <*>.,error,<org.apache.flink.runtime.taskmanager.Task$TaskCanceler: void run()>
Closing components.,info,<org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent: java.util.concurrent.CompletableFuture closeAsyncInternal()>
Error while requesting partition state,info,"<org.apache.flink.runtime.jobmaster.JobMaster: java.util.concurrent.CompletableFuture requestPartitionState(org.apache.flink.runtime.jobgraph.IntermediateDataSetID,org.apache.flink.runtime.io.network.partition.ResultPartitionID)>"
Cannot run \'<*>\' because the actual state is <*> and not <*>.,debug,"<org.apache.flink.runtime.scheduler.adaptive.State: java.util.Optional tryCall(java.lang.Class,org.apache.flink.util.function.FunctionWithException,java.lang.String)>"
Stopping resource manager service.,info,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: java.util.concurrent.CompletableFuture closeAsync()>
Resource manager service is not running.,debug,<org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl: java.util.concurrent.CompletableFuture closeAsync()>
Allocating logical slot from shared slot (<*>),debug,<org.apache.flink.runtime.scheduler.adaptive.allocator.SharedSlot: org.apache.flink.runtime.jobmaster.LogicalSlot allocateLogicalSlot()>
Re-matched slot offer <*> to requirement <*>.,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlot reserveFreeSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
Adjusting requirements because a slot was reserved for a different requirement than initially assumed. Slot=<*> assumedRequirement=<*> actualRequirement=<*>,debug,"<org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool: org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlot reserveFreeSlot(org.apache.flink.runtime.clusterframework.types.AllocationID,org.apache.flink.runtime.clusterframework.types.ResourceProfile)>"
"Created BLOB cache storage directory , storageDir, ",info,"<org.apache.flink.runtime.blob.AbstractBlobCache: void <init>(org.apache.flink.configuration.Configuration,org.apache.flink.util.Reference,org.apache.flink.runtime.blob.BlobView,org.slf4j.Logger,java.net.InetSocketAddress)>"
Invalid value for <*>. System will attempt no retries on failed fetch operations of BLOBs.,warn,"<org.apache.flink.runtime.blob.AbstractBlobCache: void <init>(org.apache.flink.configuration.Configuration,org.apache.flink.util.Reference,org.apache.flink.runtime.blob.BlobView,org.slf4j.Logger,java.net.InetSocketAddress)>"
Confirm leadership <*>.,debug,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void lambda$confirmLeadership$10(java.util.UUID,java.lang.String)>"
Ignore confirming leadership because the leader <*> is no longer valid.,trace,"<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void lambda$confirmLeadership$10(java.util.UUID,java.lang.String)>"
Stop job leader service.,info,<org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService: void stop()>
Coordinator checkpoint <*> for coordinator <*> is awaiting <*> pending events,info,"<org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder: void completeCheckpointOnceEventsAreDone(long,java.util.concurrent.CompletableFuture,byte[])>"
Start leadership runner for job <*>.,debug,<org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner: void start()>
Closing the AdaptiveScheduler. Trying to suspend the current job execution.,debug,<org.apache.flink.runtime.scheduler.adaptive.AdaptiveScheduler: java.util.concurrent.CompletableFuture closeAsync()>
Scheduled delete of state handle <*>.,trace,<org.apache.flink.runtime.state.SharedStateRegistryImpl: void scheduleAsyncDelete(org.apache.flink.runtime.state.StreamStateHandle)>
No \'clientPort\' configured. Set to \'<*>\'.,warn,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void setRequiredProperties(java.util.Properties)>
No \'initLimit\' configured. Set to \'<*>\'.,warn,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void setRequiredProperties(java.util.Properties)>
No \'syncLimit\' configured. Set to \'<*>\'.,warn,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void setRequiredProperties(java.util.Properties)>
No \'dataDir\' configured. Set to \'<*>\'.,warn,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void setRequiredProperties(java.util.Properties)>
Set peer and leader port of \'<*>\': \'<*>\' => \'<*>\'.,info,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void setRequiredProperties(java.util.Properties)>
Set peer port of \'<*>\': \'<*>\' => \'<*>\'.,info,<org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer: void setRequiredProperties(java.util.Properties)>
Could not load archived execution graph information for job id <*>.,debug,<org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore: org.apache.flink.runtime.scheduler.ExecutionGraphInfo get(org.apache.flink.api.common.JobID)>
Failed to request buffers for data reading.,error,<org.apache.flink.runtime.io.network.partition.SortMergeResultPartitionReadScheduler: java.util.Queue allocateBuffers(java.util.Queue)>
Final TaskExecutor Memory configuration:,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
  Total Process Memory:          <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
    Total Flink Memory:          <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
      Total JVM Heap Memory:     <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
        Framework:               <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
        Task:                    <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
      Total Off-heap Memory:     <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
        Managed:                 <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
        Total JVM Direct Memory: <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
          Framework:             <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
          Task:                  <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
          Network:               <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
    JVM Metaspace:               <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
    JVM Overhead:                <*>,info,<org.apache.flink.runtime.util.bash.BashJavaUtils: void logTaskExecutorConfiguration(org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec)>
Ignore unrecognized worker <*>.,debug,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: boolean clearStateForWorker(org.apache.flink.runtime.clusterframework.types.ResourceID)>
Worker <*> with resource spec <*> was requested in current attempt and has not registered. Current pending count after removing: <*>.,info,<org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager: boolean clearStateForWorker(org.apache.flink.runtime.clusterframework.types.ResourceID)>
Copying from <*> to <*>.,debug,"<org.apache.flink.runtime.blob.FileSystemBlobStore: boolean get(java.lang.String,java.io.File,org.apache.flink.runtime.blob.BlobKey)>"
,moveTempFileToStore,"<org.apache.flink.runtime.blob.AbstractBlobCache: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.AbstractBlobCache: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Failed to copy from blob store. Downloading from BLOB server instead.,info,"<org.apache.flink.runtime.blob.AbstractBlobCache: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
,moveTempFileToStore,"<org.apache.flink.runtime.blob.AbstractBlobCache: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.AbstractBlobCache: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Could not delete the staging file <*> for blob key <*> and job <*>.,warn,"<org.apache.flink.runtime.blob.AbstractBlobCache: java.io.File getFileInternal(org.apache.flink.api.common.JobID,org.apache.flink.runtime.blob.BlobKey)>"
Freeing slot <*>.,debug,"<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void freeSlot(org.apache.flink.runtime.clusterframework.types.SlotID,org.apache.flink.runtime.clusterframework.types.AllocationID)>"
Could not load web content handler.,warn,<org.apache.flink.runtime.webmonitor.WebMonitorEndpoint: java.util.List initializeHandlers(java.util.concurrent.CompletableFuture)>
Cannot instantiate HadoopSecurityContext.,error,<org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory: org.apache.flink.runtime.security.contexts.SecurityContext createContext(org.apache.flink.runtime.security.SecurityConfiguration)>
"Cannot set ACL role to , <*>,   since SASL authentication is disabled through the , <*>,  property, ",warn,"<org.apache.flink.runtime.util.ZooKeeperUtils: org.apache.flink.runtime.highavailability.zookeeper.CuratorFrameworkWithUnhandledErrorListener startCuratorFramework(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Enforcing creator for ZK connections,info,"<org.apache.flink.runtime.util.ZooKeeperUtils: org.apache.flink.runtime.highavailability.zookeeper.CuratorFrameworkWithUnhandledErrorListener startCuratorFramework(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Enforcing default ACL for ZK connections,info,"<org.apache.flink.runtime.util.ZooKeeperUtils: org.apache.flink.runtime.highavailability.zookeeper.CuratorFrameworkWithUnhandledErrorListener startCuratorFramework(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Using \'<*>\' as Zookeeper namespace.,info,"<org.apache.flink.runtime.util.ZooKeeperUtils: org.apache.flink.runtime.highavailability.zookeeper.CuratorFrameworkWithUnhandledErrorListener startCuratorFramework(org.apache.flink.configuration.Configuration,org.apache.flink.runtime.rpc.FatalErrorHandler)>"
Processing shutdown of task executor <*>.,debug,<org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl: void processTaskExecutorShutdown(org.apache.flink.runtime.clusterframework.types.ResourceID)>
Suspending the slot manager.,info,<org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager: void suspend()>
Stopped dispatcher <*>.,info,<org.apache.flink.runtime.dispatcher.Dispatcher: void lambda$onStop$1()>
<*> lost the leadership.,debug,<org.apache.flink.runtime.leaderelection.ZooKeeperMultipleComponentLeaderElectionDriver: void notLeader()>
Using ssl connection to the blob server,info,"<org.apache.flink.runtime.blob.BlobClient: void <init>(java.net.InetSocketAddress,org.apache.flink.configuration.Configuration)>"
"Invalid timeout value for filesystem stream opening: , <*>, . Using default value of , , ",error,<org.apache.flink.api.common.io.FileInputFormat: void initDefaultsFromConfiguration(org.apache.flink.configuration.Configuration)>
"Class , <*>,  is not public so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on \Data Types & Serialization\ for details of the effect on performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"No fields were detected for , <*>,  so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on \Data Types & Serialization\ for details of the effect on performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"Class , <*>,  cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on \Data Types & Serialization\ for details of the effect on performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"Class , <*>,  contains custom serialization methods we do not call, so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on \Data Types & Serialization\ for details of the effect on performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"<*>,  is abstract or an interface, having a concrete type can increase performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"<*>,  is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on \Data Types & Serialization\ for details of the effect on performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"The default constructor of , <*>,  is not Public so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on \Data Types & Serialization\ for details of the effect on performance., ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation analyzePojo(java.lang.reflect.Type,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
"Cannot find registered Kryo serializer class for class , registeredClassname,  in classpath; using a dummy Kryo serializer that should be replaced as soon as a new Kryo serializer for the class is present, ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshotData$KryoRegistrationUtil: org.apache.flink.api.java.typeutils.runtime.KryoRegistration tryReadWithSerializerInstance(org.apache.flink.core.memory.DataInputView,java.lang.ClassLoader,java.lang.String,java.lang.Class)>"
"The registered Kryo serializer class for class , registeredClassname,  has changed and is no longer valid; using a dummy Kryo serializer that should be replaced as soon as a new Kryo serializer for the class is present., ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshotData$KryoRegistrationUtil: org.apache.flink.api.java.typeutils.runtime.KryoRegistration tryReadWithSerializerInstance(org.apache.flink.core.memory.DataInputView,java.lang.ClassLoader,java.lang.String,java.lang.Class)>"
Kryo serializer scala extensions are not available.,info,<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer: com.esotericsoftware.kryo.Kryo getKryoInstance()>
Kryo serializer scala extensions are not available.,info,<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer: com.esotericsoftware.kryo.Kryo getKryoInstance()>
"XCertificate: Alg:<*>, Serial:<*>, Subject:<*>, Issuer:<*>, Key type:<*>, Length:<*>, Cert Id:<*>, Valid from:<*>, Valid until:<*>",fine,"<jdk.internal.event.EventHelper: void logX509CertificateEvent(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,long,long,long)>"
"Ignoring serialVersionUID mismatch for class <*>; was <*>, now <*>.",warn,<org.apache.flink.util.InstantiationUtil$FailureTolerantObjectInputStream: java.io.ObjectStreamClass readClassDescriptor()>
No Flink runtime dependency present. The extended set of supported File Systems via Hadoop is not available.,info,<org.apache.flink.core.fs.FileSystem: org.apache.flink.core.fs.FileSystemFactory loadHadoopFsFactory()>
Flink\'s Hadoop file system factory could not be loaded,warn,<org.apache.flink.core.fs.FileSystem: org.apache.flink.core.fs.FileSystemFactory loadHadoopFsFactory()>
Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.,info,<org.apache.flink.core.fs.FileSystem: org.apache.flink.core.fs.FileSystemFactory loadHadoopFsFactory()>
Flink\'s Hadoop file system factory could not be created,warn,<org.apache.flink.core.fs.FileSystem: org.apache.flink.core.fs.FileSystemFactory loadHadoopFsFactory()>
"Assigning split , next,  to , host, ",debug,"<org.apache.flink.api.common.io.DefaultInputSplitAssigner: org.apache.flink.core.io.InputSplit getNextInputSplit(java.lang.String,int)>"
"Cannot extract type of Row field, because of Row field, infos#,  is null. Should define RowTypeInfo explicitly., ",warn,<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation privateGetForObject(java.lang.Object)>
"Termination criterion stats in iteration , iteration, : , <*>, ",info,"<org.apache.flink.api.common.operators.base.BulkIterationBase$TerminationCriterionAggregationConvergence: boolean isConverged(int,org.apache.flink.types.LongValue)>"
Dig to clean the <*>,debug,"<org.apache.flink.api.java.ClosureCleaner: void clean(java.lang.Object,org.apache.flink.api.common.ExecutionConfig$ClosureCleanerLevel,boolean,java.util.Set)>"
"Unable to handle type , clazz,  as POJO. Message: , <*>, ",debug,"<org.apache.flink.api.java.typeutils.TypeExtractor: org.apache.flink.api.common.typeinfo.TypeInformation privateGetForClass(java.lang.Class,java.util.List,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)>"
Assigning split to null host (random assignment).,info,"<org.apache.flink.api.common.io.LocatableInputSplitAssigner: org.apache.flink.core.io.LocatableInputSplit getNextInputSplit(java.lang.String,int)>"
"Assigning local split to host , <*>, ",info,"<org.apache.flink.api.common.io.LocatableInputSplitAssigner: org.apache.flink.core.io.LocatableInputSplit getNextInputSplit(java.lang.String,int)>"
"Assigning remote split to host , <*>, ",info,"<org.apache.flink.api.common.io.LocatableInputSplitAssigner: org.apache.flink.core.io.LocatableInputSplit getNextInputSplit(java.lang.String,int)>"
"In file \, <*>, \ (split start: , <*>, ) , <*>,  invalid line(s) were skipped., ",warn,<org.apache.flink.api.common.io.GenericCsvInputFormat: void close()>
"In file \, <*>, \ (split start: , <*>, ) , <*>,  comment line(s) were skipped., ",info,<org.apache.flink.api.common.io.GenericCsvInputFormat: void close()>
Bug in splitting logic. To much rounding loss.,<init>,<org.apache.flink.util.NumberSequenceIterator: org.apache.flink.util.NumberSequenceIterator[] split(int)>
Bug in splitting logic.,<init>,<org.apache.flink.util.NumberSequenceIterator: org.apache.flink.util.NumberSequenceIterator[] split(int)>
"Cannot find registered class , <*>,  for Kryo serialization in classpath., ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshotData$ClassResolverByName: java.lang.Class apply(org.apache.flink.core.memory.DataInputView,java.lang.String)>"
ExecutorService did not terminate in time. Shutting it down now.,warn,"<org.apache.flink.util.ExecutorUtils: void gracefulShutdown(long,java.util.concurrent.TimeUnit,java.util.concurrent.ExecutorService[])>"
Interrupted while shutting down executor services. Shutting all remaining ExecutorServices down now.,warn,"<org.apache.flink.util.ExecutorUtils: void gracefulShutdown(long,java.util.concurrent.TimeUnit,java.util.concurrent.ExecutorService[])>"
"The Kryo registration for a previously registered class <*> does not have a proper serializer, because its previous serializer cannot be loaded or is no longer valid but a new serializer is not available",warn,<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot: void lambda$logMissingKeys$0(java.lang.String)>
Error while closing resource via safety-net,debug,<org.apache.flink.core.fs.SafetyNetCloseableRegistry$CloseableReaperThread: void run()>
Overwriting an existing decompression algorithm for \<*>\ files.,warn,"<org.apache.flink.api.common.io.FileInputFormat: void registerInflaterInputStreamFactory(java.lang.String,org.apache.flink.api.common.io.compression.InflaterInputStreamFactory)>"
Loading extension file systems via services,debug,<org.apache.flink.core.fs.FileSystem: java.util.List loadFileSystemFactories(java.util.Collection)>
Failed to load additional file systems via services,error,<org.apache.flink.core.fs.FileSystem: java.util.List loadFileSystemFactories(java.util.Collection)>
Error during shutdown of <*> via JVM shutdown hook.,error,"<org.apache.flink.util.ShutdownHookUtil: void lambda$addShutdownHook$0(java.lang.AutoCloseable,org.slf4j.Logger,java.lang.String)>"
"Unexpected error while handling accumulator , name, , ",error,"<org.apache.flink.api.common.accumulators.AccumulatorHelper: java.lang.Object lambda$wrapUnchecked$3(java.util.function.Supplier,java.lang.String)>"
"ValidationChain: <*>, <*>",fine,"<jdk.internal.event.EventHelper: void logX509ValidationEvent(int,int[])>"
LOG,<init>,<org.apache.flink.configuration.ClusterOptions$UserSystemExitMode: void <clinit>()>
"clazz,  does not contain a getter for field , <*>, ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: boolean isValidPojoField(java.lang.reflect.Field,java.lang.Class,java.util.List)>"
"clazz,  does not contain a setter for field , <*>, ",info,"<org.apache.flink.api.java.typeutils.TypeExtractor: boolean isValidPojoField(java.lang.reflect.Field,java.lang.Class,java.util.List)>"
"Could not start JMX server on any configured port(s) in: , portsConfig, ",error,<org.apache.flink.management.jmx.JMXService: void startInstance(java.lang.String)>
"JVM-wide JMXServer already started at port: , <*>, ",warn,<org.apache.flink.management.jmx.JMXService: void startInstance(java.lang.String)>
"KRYO , category,  , message, ",error,"<org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder: void log(int,java.lang.String,java.lang.String,java.lang.Throwable)>"
"KRYO , category,  , message, ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder: void log(int,java.lang.String,java.lang.String,java.lang.Throwable)>"
"KRYO , category,  , message, ",info,"<org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder: void log(int,java.lang.String,java.lang.String,java.lang.Throwable)>"
"KRYO , category,  , message, ",debug,"<org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder: void log(int,java.lang.String,java.lang.String,java.lang.Throwable)>"
"KRYO , category,  , message, ",trace,"<org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder: void log(int,java.lang.String,java.lang.String,java.lang.Throwable)>"
"Could not determine statistics for paths \', <*>, \' due to an io error: , <*>, ",warn,<org.apache.flink.api.common.io.FileInputFormat: org.apache.flink.api.common.io.FileInputFormat$FileBaseStatistics getStatistics(org.apache.flink.api.common.io.statistics.BaseStatistics)>
"Unexpected problem while getting the file statistics for paths \', <*>, \': , <*>, ",error,<org.apache.flink.api.common.io.FileInputFormat: org.apache.flink.api.common.io.FileInputFormat$FileBaseStatistics getStatistics(org.apache.flink.api.common.io.statistics.BaseStatistics)>
"Opening input split , <*>,  , <*>, ,, <*>, , ",debug,<org.apache.flink.api.common.io.FileInputFormat: void open(org.apache.flink.core.fs.FileInputSplit)>
Added file system <*>:<*>,debug,"<org.apache.flink.core.fs.FileSystem: void addAllFactoriesToList(java.util.Iterator,java.util.List)>"
Failed to load a file system via services,error,"<org.apache.flink.core.fs.FileSystem: void addAllFactoriesToList(java.util.Iterator,java.util.List)>"
Trying to open socket on port <*>,debug,"<org.apache.flink.util.NetUtils: java.net.ServerSocket createSocketFromPorts(java.util.Iterator,org.apache.flink.util.NetUtils$SocketFactory)>"
Unable to allocate socket on port,debug,"<org.apache.flink.util.NetUtils: java.net.ServerSocket createSocketFromPorts(java.util.Iterator,org.apache.flink.util.NetUtils$SocketFactory)>"
"Unable to allocate on port <*>, due to error: <*>",info,"<org.apache.flink.util.NetUtils: java.net.ServerSocket createSocketFromPorts(java.util.Iterator,org.apache.flink.util.NetUtils$SocketFactory)>"
FATAL: Thread \'<*>\' produced an uncaught exception. Stopping the process...,error,"<org.apache.flink.util.FatalExitExceptionHandler: void uncaughtException(java.lang.Thread,java.lang.Throwable)>"
"Unable to remove shutdown hook for <*>, shutdown already in progress",debug,"<org.apache.flink.util.ShutdownHookUtil: void removeShutdownHook(java.lang.Thread,java.lang.String,org.slf4j.Logger)>"
Exception while un-registering <*>\'s shutdown hook.,warn,"<org.apache.flink.util.ShutdownHookUtil: void removeShutdownHook(java.lang.Thread,java.lang.String,org.slf4j.Logger)>"
Could not properly close FileOutputFormat.,error,<org.apache.flink.api.common.io.FileOutputFormat: void tryCleanupOnError()>
"Could not remove the incomplete file , <*>, , ",error,<org.apache.flink.api.common.io.FileOutputFormat: void tryCleanupOnError()>
"Cannot find registered class , <*>,  for Kryo serialization in classpath; using a dummy class as a placeholder., ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshotData$KryoRegistrationUtil: org.apache.flink.api.java.typeutils.runtime.KryoRegistration tryReadKryoRegistration(org.apache.flink.core.memory.DataInputView,java.lang.ClassLoader)>"
JMXServer is already running.,debug,<org.apache.flink.management.jmx.JMXServer: void start(int)>
Exiting JVM with status <*> is monitored: The system will exit due to this call.,warn,<org.apache.flink.core.security.FlinkSecurityManager: void checkExit(int)>
No valid check exit mode configured: <*>,warn,<org.apache.flink.core.security.FlinkSecurityManager: void checkExit(int)>
"SecurityPropertyModification: key:<*>, value:<*>",fine,"<jdk.internal.event.EventHelper: void logSecurityPropertyEvent(java.lang.String,java.lang.String)>"
FlinkSecurityManager is created with <*> user system exit mode and <*> exit,info,<org.apache.flink.core.security.FlinkSecurityManager: org.apache.flink.core.security.FlinkSecurityManager fromConfiguration(org.apache.flink.configuration.Configuration)>
Could not load factory due to missing dependencies.,info,<org.apache.flink.core.execution.DefaultExecutorServiceLoader: org.apache.flink.core.execution.PipelineExecutorFactory getExecutorFactory(org.apache.flink.configuration.Configuration)>
Bug in splitting logic. To much rounding loss.,<init>,<org.apache.flink.util.LongValueSequenceIterator: org.apache.flink.util.LongValueSequenceIterator[] split(int)>
Bug in splitting logic.,<init>,<org.apache.flink.util.LongValueSequenceIterator: org.apache.flink.util.LongValueSequenceIterator[] split(int)>
"<*>,  TLSHandshake: <*>:<*>, <*>, <*>, <*>, ",fine,"<jdk.internal.event.EventHelper: void logTLSHandshakeEvent(java.time.Instant,java.lang.String,int,java.lang.String,java.lang.String,long)>"
Logarithm of zero is undefined.,<init>,<org.apache.flink.util.MathUtils: int log2floor(int)>
Could not check for stream progress to determine inactivity,debug,"<org.apache.flink.core.fs.LimitedConnectionsFileSystem: boolean closeInactiveStream(java.util.HashSet,long)>"
"thisName,  is accessed: , <*>, ",debug,"<org.apache.flink.api.java.ClosureCleaner: boolean cleanThis0(java.lang.Object,java.lang.Class,java.lang.String)>"
LOG,<init>,<org.apache.flink.configuration.ClusterOptions$UncaughtExceptionHandleMode: void <clinit>()>
"Opening stream for output (, <*>, /, numTasks, ). WriteMode=, <*>, , OutputDirectoryMode=, <*>, ",debug,"<org.apache.flink.api.common.io.FileOutputFormat: void open(int,int)>"
An error occurred while closing the classloader for plugin <*>.,warn,<org.apache.flink.core.plugin.PluginLoader: void close()>
Cannot allocate direct memory segment,error,<org.apache.flink.core.memory.MemorySegmentFactory: java.nio.ByteBuffer allocateDirectMemory(int)>
The plugins directory <*> does not exist.,warn,<org.apache.flink.core.plugin.PluginConfig: java.util.Optional getPluginsDir()>
Exception while reading serializer snapshot.,warn,"<org.apache.flink.api.java.typeutils.runtime.PojoSerializerSnapshotData: org.apache.flink.api.common.typeutils.TypeSerializerSnapshot lambda$snapshotReader$3(java.lang.ClassLoader,org.apache.flink.core.memory.DataInputView,java.lang.String)>"
"Cannot find registered Kryo serializer class for class , registeredClassname,  in classpath; using a dummy Kryo serializer that should be replaced as soon as a new Kryo serializer for the class is present, ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshotData$KryoRegistrationUtil: org.apache.flink.api.java.typeutils.runtime.KryoRegistration tryReadWithSerializerClass(org.apache.flink.core.memory.DataInputView,java.lang.ClassLoader,java.lang.String,java.lang.Class)>"
"Invalid value for number of samples to take: , <*>, . Skipping sampling., ",warn,<org.apache.flink.api.common.io.DelimitedInputFormat: void configure(org.apache.flink.configuration.Configuration)>
"Minimal split size of , <*>,  is larger than the block size of , <*>, . Decreasing minimal split size to block size., ",warn,<org.apache.flink.api.common.io.FileInputFormat: org.apache.flink.core.fs.FileInputSplit[] createInputSplits(int)>
"Error while trying to split key and value in configuration file , file, :, lineNo, : \, <*>, \, ",warn,<org.apache.flink.configuration.GlobalConfiguration: org.apache.flink.configuration.Configuration loadYAMLResource(java.io.File)>
"Error after splitting key and value in configuration file , file, :, lineNo, : \, <*>, \, ",warn,<org.apache.flink.configuration.GlobalConfiguration: org.apache.flink.configuration.Configuration loadYAMLResource(java.io.File)>
"Loading configuration property: <*>, <*>",info,<org.apache.flink.configuration.GlobalConfiguration: org.apache.flink.configuration.Configuration loadYAMLResource(java.io.File)>
Config uses deprecated configuration key \'<*>\' instead of proper key \'<*>\',warn,"<org.apache.flink.configuration.Configuration: void loggingFallback(org.apache.flink.configuration.FallbackKey,org.apache.flink.configuration.ConfigOption)>"
Config uses fallback configuration key \'<*>\' instead of key \'<*>\',info,"<org.apache.flink.configuration.Configuration: void loggingFallback(org.apache.flink.configuration.FallbackKey,org.apache.flink.configuration.ConfigOption)>"
"Cannot find registered class , <*>,  for Kryo serialization in classpath; using a dummy class as a placeholder., ",warn,<org.apache.flink.api.java.typeutils.runtime.KryoRegistrationSerializerConfigSnapshot$KryoRegistrationSerializationProxy: void read(org.apache.flink.core.memory.DataInputView)>
"Cannot find registered Kryo serializer class for class , <*>,  in classpath; using a dummy Kryo serializer that should be replaced as soon as a new Kryo serializer for the class is present, ",warn,<org.apache.flink.api.java.typeutils.runtime.KryoRegistrationSerializerConfigSnapshot$KryoRegistrationSerializationProxy: void read(org.apache.flink.core.memory.DataInputView)>
"Cannot find registered Kryo serializer class for class , <*>,  in classpath; using a dummy Kryo serializer that should be replaced as soon as a new Kryo serializer for the class is present, ",warn,<org.apache.flink.api.java.typeutils.runtime.KryoRegistrationSerializerConfigSnapshot$KryoRegistrationSerializationProxy: void read(org.apache.flink.core.memory.DataInputView)>
"The registered Kryo serializer class for class , <*>,  has changed and is no longer valid; using a dummy Kryo serializer that should be replaced as soon as a new Kryo serializer for the class is present., ",warn,<org.apache.flink.api.java.typeutils.runtime.KryoRegistrationSerializerConfigSnapshot$KryoRegistrationSerializationProxy: void read(org.apache.flink.core.memory.DataInputView)>
Someone else beat us at initializing the serializer.,debug,<org.apache.flink.api.common.state.StateDescriptor: void initializeSerializerUnlessSet(org.apache.flink.api.common.ExecutionConfig)>
Could not read a requested serializer. Replaced with a UnloadableDummyTypeSerializer.,warn,"<org.apache.flink.api.common.typeutils.TypeSerializerSerializationUtil: org.apache.flink.api.common.typeutils.TypeSerializer tryReadSerializer(org.apache.flink.core.memory.DataInputView,java.lang.ClassLoader,boolean)>"
,warn,"<org.apache.flink.util.PropertiesUtil: long getLong(java.util.Properties,java.lang.String,long,org.slf4j.Logger)>"
Cannot register shutdown hook that cleanly terminates <*>.,error,"<org.apache.flink.util.ShutdownHookUtil: boolean addShutdownHookThread(java.lang.Thread,java.lang.String,org.slf4j.Logger)>"
"Could not determine statistics for files \', <*>, \' due to an io error: , <*>, ",warn,<org.apache.flink.api.common.io.DelimitedInputFormat: org.apache.flink.api.common.io.FileInputFormat$FileBaseStatistics getStatistics(org.apache.flink.api.common.io.statistics.BaseStatistics)>
"Unexpected problem while getting the file statistics for files \', <*>, \': , <*>, ",error,<org.apache.flink.api.common.io.DelimitedInputFormat: org.apache.flink.api.common.io.FileInputFormat$FileBaseStatistics getStatistics(org.apache.flink.api.common.io.statistics.BaseStatistics)>
"Cannot deserialize a previously serialized kryo serializer for the type , className, ",warn,"<org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshotData$SerializeableSerializerResolver: org.apache.flink.api.common.ExecutionConfig$SerializableSerializer apply(org.apache.flink.core.memory.DataInputView,java.lang.String)>"
"Directory , <*>,  did not pass the file-filter and is excluded., ",debug,"<org.apache.flink.api.common.io.FileInputFormat: long addFilesInDir(org.apache.flink.core.fs.Path,java.util.List,boolean)>"
"Directory , <*>,  did not pass the file-filter and is excluded., ",debug,"<org.apache.flink.api.common.io.FileInputFormat: long addFilesInDir(org.apache.flink.core.fs.Path,java.util.List,boolean)>"
"Exception in closing , c, ",debug,"<org.apache.flink.util.IOUtils: void cleanup(org.slf4j.Logger,java.lang.AutoCloseable[])>"
Closing unclosed resource via safety-net: <*>,warn,<org.apache.flink.core.fs.SafetyNetCloseableRegistry$PhantomDelegatingCloseableRef: void close()>
Logarithm of zero is undefined.,<init>,<org.apache.flink.util.MathUtils: int log2strict(int)>
"Started JMX server on port , <*>, ., ",info,<org.apache.flink.management.jmx.JMXService: org.apache.flink.management.jmx.JMXServer startJMXServerWithPortRanges(java.util.Iterator)>
"Could not start JMX server on port , <*>, ., ",debug,<org.apache.flink.management.jmx.JMXService: org.apache.flink.management.jmx.JMXServer startJMXServerWithPortRanges(java.util.Iterator)>
Could not stop JMX server.,debug,<org.apache.flink.management.jmx.JMXService: org.apache.flink.management.jmx.JMXServer startJMXServerWithPortRanges(java.util.Iterator)>
"Invalid default maximum number of line samples: , <*>, . Using default value of , <*>, ",error,<org.apache.flink.api.common.io.DelimitedInputFormat: void loadConfigParameters(org.apache.flink.configuration.Configuration)>
"Invalid default minimum number of line samples: , <*>, . Using default value of , <*>, ",error,<org.apache.flink.api.common.io.DelimitedInputFormat: void loadConfigParameters(org.apache.flink.configuration.Configuration)>
"Default minimum number of line samples cannot be greater the default maximum number of line samples: min=, minSamples, , max=, maxSamples, . Defaulting minimum to maximum., ",error,<org.apache.flink.api.common.io.DelimitedInputFormat: void loadConfigParameters(org.apache.flink.configuration.Configuration)>
"Invalid value for the maximum sample record length. Using default value of , <*>, , ",error,<org.apache.flink.api.common.io.DelimitedInputFormat: void loadConfigParameters(org.apache.flink.configuration.Configuration)>
"Increasing maximum sample record length to size of the read buffer (, , )., ",warn,<org.apache.flink.api.common.io.DelimitedInputFormat: void loadConfigParameters(org.apache.flink.configuration.Configuration)>
finishing,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void finish()>
"operator is already closed, doing nothing",warn,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void finish()>
unable to emit watermark while closing,warn,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void finish()>
Received barrier for checkpoint <*> from channel <*>,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.CheckpointBarrierTracker: void processBarrier(org.apache.flink.runtime.io.network.api.CheckpointBarrier,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo,boolean)>"
onEventTime @ <*>,trace,<org.apache.flink.streaming.api.operators.co.IntervalJoinOperator: void onEventTime(org.apache.flink.streaming.api.operators.InternalTimer)>
Removing from left buffer @ <*>,trace,<org.apache.flink.streaming.api.operators.co.IntervalJoinOperator: void onEventTime(org.apache.flink.streaming.api.operators.InternalTimer)>
Removing from right buffer @ <*>,trace,<org.apache.flink.streaming.api.operators.co.IntervalJoinOperator: void onEventTime(org.apache.flink.streaming.api.operators.InternalTimer)>
Applying sorting/pass-through input requirements for operator <*>.,debug,"<org.apache.flink.streaming.runtime.translators.BatchExecutionUtils: void applyBatchExecutionSettings(int,org.apache.flink.streaming.api.graph.TransformationTranslator$Context,org.apache.flink.streaming.api.graph.StreamConfig$InputRequirement[])>"
<*>: Received checkpoint barrier for checkpoint <*> before completing current checkpoint <*>. Skipping current checkpoint.,warn,<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void cancelSubsumedCheckpoint(long)>
Subtask <*> checkpointing for checkpoint with id=<*> (max part counter=<*>).,info,"<org.apache.flink.streaming.api.functions.sink.filesystem.Buckets: void snapshotState(long,org.apache.flink.api.common.state.ListState,org.apache.flink.api.common.state.ListState)>"
Created demultiplexer for input <*> from <*>,info,"<org.apache.flink.streaming.runtime.io.recovery.RescalingStreamTaskNetworkInput: void <init>(org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate,org.apache.flink.api.common.typeutils.TypeSerializer,org.apache.flink.runtime.io.disk.iomanager.IOManager,org.apache.flink.streaming.runtime.watermarkstatus.StatusWatermarkValve,int,org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor,java.util.function.Function,org.apache.flink.api.common.TaskInfo)>"
Error occurs when closing client connections in CollectSinkFunction,warn,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void closeCurrentConnection()>
Timer service is shutting down.,info,<org.apache.flink.streaming.runtime.tasks.StreamTask: void finalize()>
System timer service is shutting down.,info,<org.apache.flink.streaming.runtime.tasks.StreamTask: void finalize()>
CO-TASK: <*>,debug,"<org.apache.flink.streaming.api.graph.StreamGraph: void addCoOperator(java.lang.Integer,java.lang.String,java.lang.String,org.apache.flink.streaming.api.operators.StreamOperatorFactory,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation,java.lang.String)>"
Legacy source <*> skip execution since the task is finished on restore,debug,<org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread: void run()>
load split: <*>,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void loadSplit(org.apache.flink.streaming.api.functions.source.TimestampedInputSplit)>
Operator <*> was cancelled while performing checkpoint <*>.,info,"<org.apache.flink.streaming.runtime.tasks.StreamTask: void triggerCheckpointOnBarrier(org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointOptions,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder)>"
"<*>,  TLSHandshake: <*>:<*>, <*>, <*>, <*>, ",fine,"<jdk.internal.event.EventHelper: void logTLSHandshakeEvent(java.time.Instant,java.lang.String,int,java.lang.String,java.lang.String,long)>"
Could not perform checkpoint <*> for operator <*> while the invokable was not in state running.,debug,"<org.apache.flink.streaming.runtime.tasks.StreamTask: boolean triggerCheckpointAsyncInMailbox(org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointOptions)>"
"Forwarding split: , split, ",info,"<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void monitorDirAndForwardSplits(org.apache.flink.core.fs.FileSystem,org.apache.flink.streaming.api.functions.source.SourceFunction$SourceContext)>"
Parallelism set: <*> for <*>,debug,"<org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator: org.apache.flink.streaming.api.graph.StreamConfig createJobVertex(java.lang.Integer,org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator$OperatorChainInfo)>"
Subtask <*> checkpointing: <*>,debug,"<org.apache.flink.streaming.api.functions.sink.filesystem.Buckets: void snapshotActiveBuckets(long,org.apache.flink.api.common.state.ListState)>"
Error occurs when closing server in CollectSinkFunction,warn,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void closeServerSocket()>
"Connecting to server socket , <*>, , <*>, ",info,<org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction: void run(org.apache.flink.streaming.api.functions.source.SourceFunction$SourceContext)>
"Lost connection to server socket. Retrying in , <*>,  msecs..., ",warn,<org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction: void run(org.apache.flink.streaming.api.functions.source.SourceFunction$SourceContext)>
"Failed to send message \', value, \' to socket server at , <*>, :, <*>, . Trying to reconnect..., ",error,<org.apache.flink.streaming.api.functions.sink.SocketClientSink: void invoke(java.lang.Object)>
Could not close output stream from failed write attempt,error,<org.apache.flink.streaming.api.functions.sink.SocketClientSink: void invoke(java.lang.Object)>
Could not close socket from failed write attempt,error,<org.apache.flink.streaming.api.functions.sink.SocketClientSink: void invoke(java.lang.Object)>
"Re-connect to socket server and send message failed. Retry time(s): , <*>, ",error,<org.apache.flink.streaming.api.functions.sink.SocketClientSink: void invoke(java.lang.Object)>
Could not serialize change log state backend enable flag.,<init>,<org.apache.flink.streaming.api.graph.StreamConfig: void setChangelogStateBackendEnabled(org.apache.flink.util.TernaryBoolean)>
Ignoring notification of checkpoint <*> <*> for not-running task <*>,debug,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void notifyCheckpoint(long,org.apache.flink.streaming.runtime.tasks.OperatorChain,java.util.function.Supplier,org.apache.flink.runtime.taskmanager.Task$NotifyCheckpointOperation)>"
Notification of checkpoint <*> <*> for task <*>,debug,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void notifyCheckpoint(long,org.apache.flink.streaming.runtime.tasks.OperatorChain,java.util.function.Supplier,org.apache.flink.runtime.taskmanager.Task$NotifyCheckpointOperation)>"
Unaligned checkpoints can only be used with checkpointing mode EXACTLY_ONCE,warn,<org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator: void preValidate()>
Unexpected record after finish() received.,debug,<org.apache.flink.streaming.runtime.io.FinishedDataOutput: void emitRecord(org.apache.flink.streaming.runtime.streamrecord.StreamRecord)>
Subtask <*> opening new part file \<*>\ for bucket id=<*>.,debug,<org.apache.flink.streaming.api.functions.sink.filesystem.Bucket: org.apache.flink.streaming.api.functions.sink.filesystem.InProgressFileWriter rollPartFile(long)>
"Cannot register Closeable, this subtaskCheckpointCoordinator is already closed. Closing argument.",debug,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void registerAsyncCheckpointRunnable(long,org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable)>"
Interrupted when sleeping before a retry,warn,<org.apache.flink.streaming.api.operators.collect.CollectResultFetcher: void sleepBeforeRetry()>
Put element into unordered stream element queue. New filling degree (<*>/<*>).,debug,<org.apache.flink.streaming.api.operators.async.queue.UnorderedStreamElementQueue: java.util.Optional tryPut(org.apache.flink.streaming.runtime.streamrecord.StreamElement)>
Failed to put element into unordered stream element queue because it was full (<*>/<*>).,debug,<org.apache.flink.streaming.api.operators.async.queue.UnorderedStreamElementQueue: java.util.Optional tryPut(org.apache.flink.streaming.runtime.streamrecord.StreamElement)>
Unexpected watermark status after finish() received.,debug,<org.apache.flink.streaming.runtime.io.FinishedDataOutput: void emitWatermarkStatus(org.apache.flink.streaming.runtime.watermarkstatus.WatermarkStatus)>
<*>: Received barrier from channel <*> @ <*>.,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void processBarrier(org.apache.flink.runtime.io.network.api.CheckpointBarrier,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo,boolean)>"
Path does not exist: <*>,warn,<org.apache.flink.streaming.api.functions.source.FileMonitoringFunction: java.util.List listNewFiles(org.apache.flink.core.fs.FileSystem)>
Cleanup AsyncCheckpointRunnable for checkpoint <*> of <*>.,debug,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: org.apache.flink.api.java.tuple.Tuple2 cleanup()>
Creating <*> with empty state.,debug,<org.apache.flink.streaming.api.operators.BackendRestorerProcedure: java.io.Closeable createAndRestore(java.util.List)>
Creating <*> and restoring with state <*> from alternative (<*>/<*>).,trace,<org.apache.flink.streaming.api.operators.BackendRestorerProcedure: java.io.Closeable createAndRestore(java.util.List)>
Creating <*> and restoring with state from alternative (<*>/<*>).,debug,<org.apache.flink.streaming.api.operators.BackendRestorerProcedure: java.io.Closeable createAndRestore(java.util.List)>
"Exception while restoring <*> from alternative (<*>/<*>), will retry while more alternatives are available.",warn,<org.apache.flink.streaming.api.operators.BackendRestorerProcedure: java.io.Closeable createAndRestore(java.util.List)>
"Async runnable for checkpoint , <*>,  throws exception and exit, ",debug,<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void lambda$waitForPendingCheckpoints$1(org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable)>
An exception occurred during the metrics setup.,warn,<org.apache.flink.streaming.runtime.tasks.StreamTask: org.apache.flink.metrics.Counter setupNumRecordsInCounter(org.apache.flink.streaming.api.operators.StreamOperator)>
Put element into ordered stream element queue. New filling degree (<*>/<*>).,debug,<org.apache.flink.streaming.api.operators.async.queue.OrderedStreamElementQueue: java.util.Optional tryPut(org.apache.flink.streaming.runtime.streamrecord.StreamElement)>
Failed to put element into ordered stream element queue because it was full (<*>/<*>).,debug,<org.apache.flink.streaming.api.operators.async.queue.OrderedStreamElementQueue: java.util.Optional tryPut(org.apache.flink.streaming.runtime.streamrecord.StreamElement)>
<*> checkpointed <*>.,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void snapshotState(org.apache.flink.runtime.state.FunctionSnapshotContext)>
"Ignoring , filePath, , with mod time= , modificationTime,  and global mod time= , <*>, ",debug,"<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: boolean shouldIgnore(org.apache.flink.core.fs.Path,long)>"
Re-restore attempt rejected.,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void restoreInternal()>
Initializing <*>.,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void restoreInternal()>
Invoking <*>,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void restoreInternal()>
"Initializing collect sink state with offset = , <*>, , buffered results bytes = , <*>, ",info,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
Unable to load Scala API extension.,debug,<org.apache.flink.streaming.util.typeutils.ScalaProductFieldAccessorFactory: org.apache.flink.streaming.util.typeutils.ScalaProductFieldAccessorFactory load(org.slf4j.Logger)>
Opened <*> (taskIdx= <*>) for path: <*>,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void open(org.apache.flink.configuration.Configuration)>
Finished task <*>,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void afterInvoke()>
Waiting for all the records processed by the downstream tasks.,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void afterInvoke()>
Finished operators for task <*>,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void afterInvoke()>
All pending checkpoints are finished,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void afterInvoke()>
"cleanup, state=<*>",debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void cleanUp()>
Acknowledging ids for checkpoint <*>,debug,"<org.apache.flink.streaming.api.functions.source.MultipleIdsMessageAcknowledgingSourceBase: void acknowledgeIDs(long,java.util.Set)>"
Iteration tail <*> trying to acquire feedback queue under <*>,info,<org.apache.flink.streaming.runtime.tasks.StreamIterationTail: void init()>
Iteration tail <*> acquired feedback queue <*>,info,<org.apache.flink.streaming.runtime.tasks.StreamIterationTail: void init()>
Restoring state for the <*>.,info,<org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
No state to restore for the <*>.,info,<org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
"Setting chaining strategy to HEAD for operator <*>, because of the BATCH execution mode.",debug,<org.apache.flink.streaming.runtime.translators.BatchExecutionUtils: void adjustChainingStrategy(org.apache.flink.streaming.api.graph.StreamNode)>
An error occurred while instantiating task metrics.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2: void <init>(org.apache.flink.streaming.api.operators.StreamOperatorParameters,int)>"
Could not instantiate change log state backend enable flag.,<init>,<org.apache.flink.streaming.api.graph.StreamConfig: org.apache.flink.util.TernaryBoolean isChangelogStateBackendEnabled(java.lang.ClassLoader)>
<*> (taskIdx= <*>) checkpointed <*>.,debug,<org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink: void snapshotState(org.apache.flink.runtime.state.StateSnapshotContext)>
<*> has been set to a value equal or below : <*>. Using default.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2: org.apache.flink.streaming.util.LatencyStats createLatencyStats(org.apache.flink.configuration.Configuration,int)>"
Configured value <*> option for <*> is invalid. Defaulting to <*>.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2: org.apache.flink.streaming.util.LatencyStats createLatencyStats(org.apache.flink.configuration.Configuration,int)>"
An error occurred while instantiating latency metrics.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2: org.apache.flink.streaming.util.LatencyStats createLatencyStats(org.apache.flink.configuration.Configuration,int)>"
Subtask <*> initializing its state (max part counter=<*>).,info,"<org.apache.flink.streaming.api.functions.sink.filesystem.Buckets: void initializeState(org.apache.flink.api.common.state.ListState,org.apache.flink.api.common.state.ListState)>"
"Checkpoint begin with checkpointId = , <*>, , lastCheckpointedOffset = , <*>, , buffered results bytes = , <*>, ",debug,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction: void snapshotState(org.apache.flink.runtime.state.FunctionSnapshotContext)>
not processing any records while closed,warn,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator$ReaderState$6: boolean prepareToProcessRecord(org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator)>
Timer service is quiesced. Processing time timer for timestamp \'<*>\' will be ignored.,warn,"<org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionInternalTimeService: void registerProcessingTimeTimer(java.lang.Object,long)>"
"Since tolerableCheckpointFailureNumber has been configured as <*>, deprecated #setFailOnCheckpointingErrors(boolean) method would not take any effect and please use #setTolerableCheckpointFailureNumber(int) method to determine your expected behaviour when checkpoint errors on task side.",warn,<org.apache.flink.streaming.api.environment.CheckpointConfig: void setFailOnCheckpointingErrors(boolean)>
Disabled Checkpointing. Checkpointing is not supported and not needed when executing jobs in BATCH mode.,info,<org.apache.flink.streaming.api.graph.StreamGraphGenerator: void configureStreamGraphBatch(org.apache.flink.streaming.api.graph.StreamGraph)>
Using partitioner <*> for output <*> of task <*>,debug,"<org.apache.flink.streaming.runtime.tasks.StreamTask: org.apache.flink.runtime.io.network.api.writer.RecordWriter createRecordWriter(org.apache.flink.streaming.api.graph.StreamEdge,int,org.apache.flink.runtime.execution.Environment,java.lang.String,long)>"
Returning an empty stream in BATCH execution mode in getKeys().,debug,"<org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionKeyedStateBackend: java.util.stream.Stream getKeys(java.lang.String,java.lang.Object)>"
Attempt to complete element is ignored since the mailbox rejected the execution.,debug,<org.apache.flink.streaming.api.operators.async.AsyncWaitOperator: void outputCompletedElement()>
Starting checkpoint <*> <*> on task <*>,debug,"<org.apache.flink.streaming.runtime.tasks.StreamTask: boolean performCheckpoint(org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointOptions,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder)>"
"<*> - checkpoint <*> triggered, flushing transaction \'<*>\'",debug,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void snapshotState(org.apache.flink.runtime.state.FunctionSnapshotContext)>
<*> - stored pending transactions <*>,debug,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void snapshotState(org.apache.flink.runtime.state.FunctionSnapshotContext)>
<*> - started new transaction \'<*>\',debug,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void snapshotState(org.apache.flink.runtime.state.FunctionSnapshotContext)>
Path does not exist: <*>,warn,"<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: java.util.Map listEligibleFiles(org.apache.flink.core.fs.FileSystem,org.apache.flink.core.fs.Path)>"
Error while committing transaction <*>. Transaction has been open for longer than the transaction timeout (<*>).Commit will not be attempted again. Data loss might have occurred.,error,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void recoverAndCommitInternal(org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction$TransactionHolder)>
generated <*> rows,info,<org.apache.flink.streaming.api.functions.source.datagen.DataGeneratorSource: void close()>
Using BATCH execution state backend and timer service.,debug,<org.apache.flink.streaming.api.graph.StreamGraphGenerator: void setBatchStateBackendAndTimerService(org.apache.flink.streaming.api.graph.StreamGraph)>
<*> - restoring state,info,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
<*> committed recovered transaction <*>,info,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
<*> aborted recovered transaction <*>,info,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
<*> - no state to restore,info,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
<*> - started new transaction \'<*>\',debug,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
Received cancellation barrier for checkpoint <*>,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.CheckpointBarrierTracker: void processCancellationBarrier(org.apache.flink.runtime.io.network.api.CancelCheckpointMarker,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo)>"
Closing the mailbox dropped mails <*>.,debug,<org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor: void close()>
"Cleanup StreamTask (operators closed: <*>, cancelled: <*>)",debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void cleanUp(java.lang.Throwable)>
"Subtask <*> closing in-progress part file for bucket id=<*> due to processing time rolling policy (in-progress file created @ <*>, last updated @ <*> and current time is <*>).",debug,<org.apache.flink.streaming.api.functions.sink.filesystem.Bucket: void onProcessingTime(long)>
Ignored RejectedExecutionException in CheckpointedInputGate.waitForPriorityEvents,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate: void lambda$waitForPriorityEvents$0(org.apache.flink.api.common.operators.MailboxExecutor,org.apache.flink.runtime.io.network.partition.consumer.InputGate)>"
Could not commit checkpoint.,error,<org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink: void notifyCheckpointComplete(long)>
<*>: Triggering checkpoint <*> on the barrier announcement at <*>.,debug,<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void triggerCheckpoint(org.apache.flink.runtime.io.network.api.CheckpointBarrier)>
Subtask <*> received completion notification for checkpoint with id=<*>.,info,<org.apache.flink.streaming.api.functions.sink.filesystem.Buckets: void commitUpToCheckpoint(long)>
"Transforming , transform, ",debug,<org.apache.flink.streaming.api.graph.StreamGraphGenerator: java.util.Collection transform(org.apache.flink.api.dag.Transformation)>
"ValidationChain: <*>, <*>",fine,"<jdk.internal.event.EventHelper: void logX509ValidationEvent(int,int[])>"
No state to restore for the <*> (taskIdx=<*>).,info,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void initializeState(org.apache.flink.runtime.state.StateInitializationContext)>
Restoring state for the <*> (taskIdx=<*>).,info,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void initializeState(org.apache.flink.runtime.state.StateInitializationContext)>
<*> (taskIdx=<*>) restored <*>.,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void initializeState(org.apache.flink.runtime.state.StateInitializationContext)>
,setChangelogStateBackendEnabled,"<org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator: void setVertexConfig(java.lang.Integer,org.apache.flink.streaming.api.graph.StreamConfig,java.util.List,java.util.List,java.util.Map)>"
<*>: All the channels are aligned for checkpoint <*>.,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void markCheckpointAlignedAndTransformState(org.apache.flink.runtime.checkpoint.channel.InputChannelInfo,org.apache.flink.runtime.io.network.api.CheckpointBarrier,org.apache.flink.util.function.FunctionWithException)>"
Sink connection established,info,"<org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator: void handleRequestImpl(org.apache.flink.streaming.api.operators.collect.CollectCoordinationRequest,java.util.concurrent.CompletableFuture,java.net.InetSocketAddress)>"
Forwarding request to sink socket server,debug,"<org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator: void handleRequestImpl(org.apache.flink.streaming.api.operators.collect.CollectCoordinationRequest,java.util.concurrent.CompletableFuture,java.net.InetSocketAddress)>"
Fetching serialized result from sink socket server,debug,"<org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator: void handleRequestImpl(org.apache.flink.streaming.api.operators.collect.CollectCoordinationRequest,java.util.concurrent.CompletableFuture,java.net.InetSocketAddress)>"
Collect sink coordinator encounters an exception,debug,"<org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator: void handleRequestImpl(org.apache.flink.streaming.api.operators.collect.CollectCoordinationRequest,java.util.concurrent.CompletableFuture,java.net.InetSocketAddress)>"
"Sending back , <*>,  results, ",debug,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void sendBackResults(java.util.List)>
All the channels are aligned for checkpoint <*>,debug,<org.apache.flink.streaming.runtime.io.checkpointing.CheckpointBarrierTracker: void triggerCheckpointOnAligned(org.apache.flink.streaming.runtime.io.checkpointing.CheckpointBarrierTracker$CheckpointBarrierCount)>
Iteration head <*> removed feedback queue under <*>,info,<org.apache.flink.streaming.runtime.tasks.StreamIterationHead: void cleanUpInternal()>
No operators defined in streaming topology. Cannot execute.,<init>,<org.apache.flink.streaming.api.environment.StreamExecutionEnvironment: org.apache.flink.streaming.api.graph.StreamGraphGenerator getStreamGraphGenerator(java.util.List)>
Timer service shutdown exceeded time limit of <*> ms while waiting for pending timers. Will continue with shutdown procedure.,warn,"<org.apache.flink.streaming.runtime.tasks.StreamTask: void tryShutdownTimerService(long,org.apache.flink.streaming.runtime.tasks.TimerService)>"
Notify checkpoint <*> complete on task <*>,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void notifyCheckpointComplete(long)>
An error occurred while instantiating task metrics.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperator: void setup(org.apache.flink.streaming.runtime.tasks.StreamTask,org.apache.flink.streaming.api.graph.StreamConfig,org.apache.flink.streaming.api.operators.Output)>"
<*> has been set to a value equal or below : <*>. Using default.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperator: void setup(org.apache.flink.streaming.runtime.tasks.StreamTask,org.apache.flink.streaming.api.graph.StreamConfig,org.apache.flink.streaming.api.operators.Output)>"
Configured value <*> option for <*> is invalid. Defaulting to <*>.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperator: void setup(org.apache.flink.streaming.runtime.tasks.StreamTask,org.apache.flink.streaming.api.graph.StreamConfig,org.apache.flink.streaming.api.operators.Output)>"
An error occurred while instantiating latency metrics.,warn,"<org.apache.flink.streaming.api.operators.AbstractStreamOperator: void setup(org.apache.flink.streaming.runtime.tasks.StreamTask,org.apache.flink.streaming.api.graph.StreamConfig,org.apache.flink.streaming.api.operators.Output)>"
Out of order checkpoint barrier (aborted previously?): <*> >= <*>,info,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void checkpointState(org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointOptions,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder,org.apache.flink.streaming.runtime.tasks.OperatorChain,boolean,java.util.function.Supplier)>"
"Checkpoint <*> has been notified as aborted, would not trigger any checkpoint.",info,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void checkpointState(org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointOptions,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder,org.apache.flink.streaming.runtime.tasks.OperatorChain,boolean,java.util.function.Supplier)>"
Timer service is quiesced. Event time timer for timestamp \'<*>\' will be ignored.,warn,"<org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionInternalTimeService: void registerEventTimeTimer(java.lang.Object,long)>"
Taking a snapshot for checkpoint <*>,debug,<org.apache.flink.streaming.api.operators.SourceOperator: void snapshotState(org.apache.flink.runtime.state.StateSnapshotContext)>
Could not close raw keyed operator state stream for <*>. This might have prevented deleting some state data.,warn,"<org.apache.flink.streaming.api.operators.InternalTimeServiceManagerImpl: void snapshotToRawKeyedState(org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream,java.lang.String)>"
Could not close raw keyed operator state stream for <*>. This might have prevented deleting some state data.,warn,"<org.apache.flink.streaming.api.operators.InternalTimeServiceManagerImpl: void snapshotToRawKeyedState(org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream,java.lang.String)>"
<*> (taskIdx=<*>) checkpointed <*> splits: <*>.,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void snapshotState(org.apache.flink.runtime.state.StateSnapshotContext)>
Subtask <*> restoring: <*>,debug,<org.apache.flink.streaming.api.functions.sink.filesystem.Buckets: void handleRestoredBucketState(org.apache.flink.streaming.api.functions.sink.filesystem.BucketState)>
"Checkpoint complete with checkpointId = , checkpointId, , lastCheckpointedOffset = , <*>, ",debug,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction: void notifyCheckpointComplete(long)>
Iteration head <*> added feedback queue under <*>,info,<org.apache.flink.streaming.runtime.tasks.StreamIterationHead: void init()>
"File processed: <*>, <*>, <*>",info,<org.apache.flink.streaming.api.functions.source.FileMonitoringFunction: void run(org.apache.flink.streaming.api.functions.source.SourceFunction$SourceContext)>
switch state: <*> -> <*>,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void switchState(org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator$ReaderState)>
Subtask <*> merging buckets for bucket id=<*>,debug,<org.apache.flink.streaming.api.functions.sink.filesystem.Bucket: void merge(org.apache.flink.streaming.api.functions.sink.filesystem.Bucket)>
<*> - finished asynchronous part of checkpoint <*>. Asynchronous duration: <*> ms,debug,"<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void reportCompletedSnapshotStates(org.apache.flink.runtime.checkpoint.TaskStateSnapshot,org.apache.flink.runtime.checkpoint.TaskStateSnapshot,long)>"
<*> - reported the following states in snapshot for checkpoint <*>: <*>.,trace,"<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void reportCompletedSnapshotStates(org.apache.flink.runtime.checkpoint.TaskStateSnapshot,org.apache.flink.runtime.checkpoint.TaskStateSnapshot,long)>"
CO-TASK: <*>,debug,"<org.apache.flink.streaming.api.graph.StreamGraph: void addMultipleInputOperator(java.lang.Integer,java.lang.String,java.lang.String,org.apache.flink.streaming.api.operators.StreamOperatorFactory,java.util.List,org.apache.flink.api.common.typeinfo.TypeInformation,java.lang.String)>"
Could not properly clean up the async checkpoint runnable.,warn,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void close()>
Merging <*> into <*>,debug,"<org.apache.flink.streaming.runtime.operators.windowing.MergingWindowSet$1: void merge(java.util.Collection,org.apache.flink.streaming.api.windowing.windows.Window)>"
Failed to get job status so we assume that the job has terminated. Some data might be lost.,warn,<org.apache.flink.streaming.api.operators.collect.CollectResultFetcher: boolean isJobTerminated()>
The job execution has not started yet; cannot fetch results.,debug,<org.apache.flink.streaming.api.operators.collect.CollectResultFetcher: java.lang.Object next()>
The job cannot be found. It is very likely that the job is not in a RUNNING state.,debug,<org.apache.flink.streaming.api.operators.collect.CollectResultFetcher: java.lang.Object next()>
An exception occurred when fetching query results,warn,<org.apache.flink.streaming.api.operators.collect.CollectResultFetcher: java.lang.Object next()>
"<*> - asynchronous checkpointing operation for checkpoint <*> has already been completed. Thus, the state handles are not cleaned up.",debug,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void logFailedCleanupAttempt()>
Coordinator connection received,info,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void run()>
"Request received, version = , <*>, , offset = , <*>, ",debug,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void run()>
"Expecting version = , <*>, , offset = , <*>, ",debug,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void run()>
"Invalid request. Received version = , <*>, , offset = , <*>, , while expected version = , <*>, , offset = , <*>, ",info,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void run()>
Collect sink server encounters an exception,debug,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction$ServerThread: void run()>
<*>: Received EndOfPartition(-) before completing current checkpoint <*>. Skipping current checkpoint.,warn,<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void processEndOfPartition(org.apache.flink.runtime.checkpoint.channel.InputChannelInfo)>
Cleanup on error failed.,error,<org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction: void cleanup()>
Restoring during invoke will be called.,debug,<org.apache.flink.streaming.runtime.tasks.StreamTask: void invoke()>
,info,"<org.apache.flink.streaming.runtime.tasks.RegularOperatorChain: org.apache.flink.streaming.api.operators.OperatorSnapshotFutures checkpointStreamOperator(org.apache.flink.streaming.api.operators.StreamOperator,org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointOptions,org.apache.flink.runtime.state.CheckpointStreamFactory,java.util.function.Supplier)>"
<*>: Aborting checkpoint <*> after exception <*>.,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void abortInternal(long,org.apache.flink.runtime.checkpoint.CheckpointException)>"
Restoring state for the GenericWriteAheadSink (taskIdx=<*>).,info,<org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink: void initializeState(org.apache.flink.runtime.state.StateInitializationContext)>
GenericWriteAheadSink idx <*> restored <*>.,debug,<org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink: void initializeState(org.apache.flink.runtime.state.StateInitializationContext)>
No state to restore for the GenericWriteAheadSink (taskIdx=<*>).,info,<org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink: void initializeState(org.apache.flink.runtime.state.StateInitializationContext)>
"Generated hash \', <*>, \' for node \', <*>, \' {id: , <*>, , parallelism: , <*>, , user function: , outEdge#, }, ",debug,"<org.apache.flink.streaming.api.graph.StreamGraphHasherV2: byte[] generateDeterministicHash(org.apache.flink.streaming.api.graph.StreamNode,org.apache.flink.shaded.guava30.com.google.common.hash.Hasher,java.util.Map,boolean,org.apache.flink.streaming.api.graph.StreamGraph)>"
split <*> processed: <*>,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator: void onSplitProcessed()>
Returning an empty stream in BATCH execution mode in getKeysAndNamespaces().,debug,<org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionKeyedStateBackend: java.util.stream.Stream getKeysAndNamespaces(java.lang.String)>
Intercepted attempt to interrupt timer service shutdown.,trace,<org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService: boolean shutdownServiceUninterruptible(long)>
Failed to close sink socket server connection,warn,<org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator: void closeConnection()>
<*>: Received cancellation <*>.,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void processCancellationBarrier(org.apache.flink.runtime.io.network.api.CancelCheckpointMarker,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo)>"
Committing Messages externally for checkpoint <*>,debug,<org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase: void notifyCheckpointComplete(long)>
Committing Messages with following IDs <*>,trace,<org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase: void notifyCheckpointComplete(long)>
Subtask <*> closing in-progress part file for bucket id=<*> on checkpoint.,debug,<org.apache.flink.streaming.api.functions.sink.filesystem.Bucket: void prepareBucketForCheckpointing(long)>
Error while emitting latency marker.,warn,<org.apache.flink.streaming.api.operators.LatencyMarkerEmitter$1: void onProcessingTime(long)>
Vertex: <*>,debug,"<org.apache.flink.streaming.api.graph.StreamGraph: void addOperator(java.lang.Integer,java.lang.String,java.lang.String,org.apache.flink.streaming.api.operators.StreamOperatorFactory,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation,java.lang.String,java.lang.Class)>"
Subtask <*> successfully deleted incomplete part for bucket id=<*>.,debug,<org.apache.flink.streaming.api.functions.sink.filesystem.Bucket: void cleanupInProgressFileRecoverables(long)>
"Checkpointing: Messages: <*>, checkpoint id: <*>, timestamp: <*>",debug,<org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase: void snapshotState(org.apache.flink.runtime.state.FunctionSnapshotContext)>
Unexpected latency marker after finish() received.,debug,<org.apache.flink.streaming.runtime.io.FinishedDataOutput: void emitLatencyMarker(org.apache.flink.streaming.runtime.streamrecord.LatencyMarker)>
Aborting checkpoint via cancel-barrier <*> for task <*>,debug,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void abortCheckpointOnBarrier(long,org.apache.flink.runtime.checkpoint.CheckpointException,org.apache.flink.streaming.runtime.tasks.OperatorChain)>"
"XCertificate: Alg:<*>, Serial:<*>, Subject:<*>, Issuer:<*>, Key type:<*>, Length:<*>, Cert Id:<*>, Valid from:<*>, Valid until:<*>",fine,"<jdk.internal.event.EventHelper: void logX509CertificateEvent(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,long,long,long)>"
Subtask <*> closing in-progress part file for bucket id=<*> due to element <*>.,debug,"<org.apache.flink.streaming.api.functions.sink.filesystem.Bucket: void write(java.lang.Object,long)>"
Restoring state for the <*>.,info,<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
<*> retrieved a global mod time of <*>.,debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
No state to restore for the <*>.,info,<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void initializeState(org.apache.flink.runtime.state.FunctionInitializationContext)>
"Collect sink server established, address = , <*>, ",info,<org.apache.flink.streaming.api.operators.collect.CollectSinkFunction: void open(org.apache.flink.configuration.Configuration)>
"<*> - finished synchronous part of checkpoint <*>. Alignment duration: <*> ms, snapshot duration <*> ms, is unaligned checkpoint : <*>",debug,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: boolean takeSnapshotSync(java.util.Map,org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder,org.apache.flink.runtime.checkpoint.CheckpointOptions,org.apache.flink.streaming.runtime.tasks.OperatorChain,java.util.function.Supplier)>"
"<*> - checkpoint <*> complete, committing transaction <*> from checkpoint <*>",info,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void notifyCheckpointComplete(long)>
<*> - committed checkpoint transaction <*>,debug,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void notifyCheckpointComplete(long)>
"Committing one of transactions failed, logging first encountered failure",<init>,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void notifyCheckpointComplete(long)>
"Received sink socket server address: , <*>, ",info,"<org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator: void handleEventFromOperator(int,org.apache.flink.runtime.operators.coordination.OperatorEvent)>"
<*> - started executing asynchronous part of checkpoint <*>. Asynchronous start delay: <*> ms,debug,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void run()>
<*> - asynchronous part of checkpoint <*> could not be completed because it was closed before.,debug,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void run()>
<*> - asynchronous part of checkpoint <*> could not be completed.,info,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void run()>
<*>: Obsolete announcement of checkpoint <*> for channel <*>.,debug,"<org.apache.flink.streaming.runtime.io.checkpointing.SingleCheckpointBarrierHandler: void processBarrierAnnouncement(org.apache.flink.runtime.io.network.api.CheckpointBarrier,int,org.apache.flink.runtime.checkpoint.channel.InputChannelInfo)>"
"SecurityPropertyModification: key:<*>, value:<*>",fine,"<jdk.internal.event.EventHelper: void logSecurityPropertyEvent(java.lang.String,java.lang.String)>"
Not iterating over all keyed in BATCH execution mode in applyToAllKeys().,debug,"<org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionKeyedStateBackend: void applyToAllKeys(java.lang.Object,org.apache.flink.api.common.typeutils.TypeSerializer,org.apache.flink.api.common.state.StateDescriptor,org.apache.flink.runtime.state.KeyedStateFunction)>"
Could not properly cancel an operator snapshot result.,warn,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void cleanup(java.util.Map,org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder,java.lang.Exception)>"
"<*> - did NOT finish synchronous part of checkpoint <*>. Alignment duration: <*> ms, snapshot duration <*> ms",debug,"<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void cleanup(java.util.Map,org.apache.flink.runtime.checkpoint.CheckpointMetaData,org.apache.flink.runtime.checkpoint.CheckpointMetricsBuilder,java.lang.Exception)>"
"Closed File Monitoring Source for path: , <*>, ., ",debug,<org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction: void close()>
CONNECTED: <*> - <*> -> <*>,debug,"<org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator: void connect(java.lang.Integer,org.apache.flink.streaming.api.graph.StreamEdge)>"
Unexpected watermark after finish() received.,debug,<org.apache.flink.streaming.runtime.io.FinishedDataOutput: void emitWatermark(org.apache.flink.streaming.api.watermark.Watermark)>
Transaction <*> has been open for <*> ms. This is close to or even exceeding the transaction timeout of <*> ms.,warn,<org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction: void logWarningIfTimeoutAlmostReached(org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction$TransactionHolder)>
An exception occurred during the metrics setup.,warn,"<org.apache.flink.streaming.runtime.tasks.ChainingOutput: void <init>(org.apache.flink.streaming.api.operators.Input,org.apache.flink.metrics.groups.OperatorMetricGroup,org.apache.flink.util.OutputTag)>"
<*> - report failed checkpoint stats: <*> <*>,trace,"<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void reportAbortedSnapshotStats(long,long)>"
Ignore decline of checkpoint <*> as task is not running anymore.,info,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void handleExecutionException(java.lang.Exception)>
Caught followup exception from a failed checkpoint thread. This can be ignored.,trace,<org.apache.flink.streaming.runtime.tasks.AsyncCheckpointRunnable: void handleExecutionException(java.lang.Exception)>
Time from receiving all checkpoint barriers/RPC to executing it exceeded threshold: <*>ms,warn,<org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl: void logCheckpointProcessingDelay(org.apache.flink.runtime.checkpoint.CheckpointMetaData)>
Timestamp monotony violated: <*> < <*>,warn,"<org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor$LoggingHandler: void handleViolation(long,long)>"